<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Now is better than never. </title>
    <link>http://tma15.github.io/tags/nlp/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2017</rights>
    <updated>2016-01-31 19:17:31 &#43;0900 JST</updated>

    
      
        <item>
          <title>N-best解の探索</title>
          <link>http://tma15.github.io/blog/2016/01/31/</link>
          <pubDate>Sun, 31 Jan 2016 19:17:31 JST</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2016/01/31/</guid>
          <description>

&lt;p&gt;系列ラベリングなどで最適なパスを探索する方法はビタビアルゴリズムで効率的に求められる。
上位N個のパスを探索する方法はビタビアルゴリズムと、A*アルゴリズムで効率的に求められる。
&lt;a href=&#34;http://www.amazon.co.jp/%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%85%A5%E5%8A%9B%E3%82%92%E6%94%AF%E3%81%88%E3%82%8B%E6%8A%80%E8%A1%93-%EF%BD%9E%E5%A4%89%E3%82%8F%E3%82%8A%E7%B6%9A%E3%81%91%E3%82%8B%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%A8%E8%A8%80%E8%91%89%E3%81%AE%E4%B8%96%E7%95%8C-WEB-DB-PRESS-plus/dp/4774149934&#34;&gt;日本語入力を支える技術　～変わり続けるコンピュータと言葉の世界 (WEB+DB PRESS plus)&lt;/a&gt;
の説明が分かりやすい。理解するために実装してみた。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/tma15/4c6f133c0d40dbd4a606.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;ラティスの構造は以下のとおり。パスの重みは上記コードを参照。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#0       n1 --- n3
        /   \ /   \
       bos   x     eos
        \   / \   /
#1       n2 --- n4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビタビアルゴリズムを適用後、バックトラックで最適なパスを選んだ場合の解と、
ビタビアルゴリズムを適用後、A*アルゴリズムで後ろ向きに最適なパスを順に選んだ場合の1-best解が一致している。
2-best以降もラティスの情報から、あっていることを確認。&lt;/p&gt;

&lt;p&gt;下記の###以降はこのエントリ用に付け足した文字列。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$go test
Backtrack ### ビタビアルゴリズムで求めたパス
1 ### n2を通って、
0 ### n3を通る
1-best: 1 ### n2を通って、
1-best: 0 ### n3を通る

2-best: 1 ### n2を通って、
2-best: 1 ### n4を通る

3-best: 0 ### n1を通って、
3-best: 0 ### n3を通る

4-best: 0 ### n1を通って、
4-best: 1 ### n4を通る
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;goで優先度付きキューを実装するには、&lt;a href=&#34;https://golang.org/pkg/container/heap/&#34;&gt;heap - The Go Programming Language&lt;/a&gt;のExample (PriorityQueue) が参考になる。&lt;/p&gt;

&lt;p&gt;少し話はそれるが、機械翻訳において、n-best解は似通ったものが選ばれてしまう問題があるので、多様性を考慮するモデルを提案している話があって、これも気になるのでメモ。&lt;/p&gt;

&lt;p&gt;Kevin Gimpel, Dhruv Batra, Chris Dyer, and Gregory Shakhnarovich. &amp;ldquo;A Systematic Exploration of Diversity in Machine Translation&amp;rdquo;, EMNLP, 2013. &lt;a href=&#34;http://ttic.uchicago.edu/~gregory/papers/emnlp2013diversity.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://d.hatena.ne.jp/jetbead/20160119/1453139047&#34;&gt;ラティスのNbestを求める - Negative/Positive Thinking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CYKアルゴリズムで係り受け解析</title>
          <link>http://tma15.github.io/blog/2015/01/cykfordependencyparsing/</link>
          <pubDate>Wed, 14 Jan 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2015/01/cykfordependencyparsing/</guid>
          <description>

&lt;p&gt;CYKアルゴリズムは文脈自由文法を解析するためのものであるので、係り受け解析に適用するには、係り受け解析結果を文脈自由文法のような木で表現する。
具体的には参考資料の23ページにあるような変換をする。
例えば「私は / ピザを / 食べる」という文節で(&amp;ldquo;/&amp;ldquo;を堺に)区切られた文があって、「私は」が「食べる」、「ピザを」が「食べる」をそれぞれ修飾しているとき、「食べる」=&amp;gt;「私は」「食べる」のような導出に変換してやることで係り受け関係を木で表現できる。
一番良い木を推定するには、テーブルTの各セルに係り受けのスコアの最大値を記憶しておいて、T[0, N]からバックトラックする (Nは文節の数)。
ただしこの解析ではO(n^5)の時間がかかる。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://stp.lingfil.uu.se/~nivre/docs/ACLslides.pdf&#34;&gt;Dependency Parsing Tutorial at COLING-ACL 2006&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>CYKアルゴリズム</title>
          <link>http://tma15.github.io/blog/2015/01/cykmemo/</link>
          <pubDate>Sat, 10 Jan 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2015/01/cykmemo/</guid>
          <description>

&lt;p&gt;明けましておめでとうございます。&lt;/p&gt;

&lt;p&gt;確率的言語モデルを読んで文脈自由文法に対する構文解析手法であるCYKアルゴリズムのところを読んだ (&lt;a href=&#34;https://github.com/tma15/nlppractice/blob/master/cyk.py&#34;&gt;ソースコード&lt;/a&gt;)。
動的計画法。
表TのT[0, N-1]に&amp;rdquo;S&amp;rdquo;があれば与えられた文法からこの文は導出可能。
文&amp;rdquo;I eat pizza with Maria&amp;rdquo; を文脈自由文法で表すと、曖昧性があるため二つの木が導出できる。&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #ffffff&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #996633&#34;&gt;$python&lt;/span&gt; cyk.py
I eat pizza with Maria
   N |    S |    S |      |    S
     |    V |  S,V |      |  S,V
     |      |    N |      |    N
     |      |      |    P |   PP
     |      |      |      |    N
	--l &amp;lt;N&amp;gt; -- I &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;
	--r &amp;lt;V&amp;gt; 
		--l &amp;lt;V&amp;gt; -- eat &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;1&lt;/span&gt;
		--r &amp;lt;N&amp;gt; 
			--l &amp;lt;N&amp;gt; -- pizza &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;2&lt;/span&gt;
			--r &amp;lt;PP&amp;gt; 
				--l &amp;lt;P&amp;gt; -- with &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;3&lt;/span&gt;
				--r &amp;lt;N&amp;gt; -- Maria &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;4&lt;/span&gt;
--
	--l &amp;lt;S&amp;gt; 
		--l &amp;lt;N&amp;gt; -- I &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;
		--r &amp;lt;V&amp;gt; 
			--l &amp;lt;V&amp;gt; -- eat &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;1&lt;/span&gt;
			--r &amp;lt;N&amp;gt; -- pizza &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;2&lt;/span&gt;
	--r &amp;lt;PP&amp;gt; 
		--l &amp;lt;P&amp;gt; -- with &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;3&lt;/span&gt;
		--r &amp;lt;N&amp;gt; -- Maria &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;4&lt;/span&gt;
--
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;div align=&#34;center&#34;&gt;
&lt;iframe src=&#34;http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=FFFFFF&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=takuya6315-22&amp;o=9&amp;p=8&amp;l=as1&amp;m=amazon&amp;f=ifr&amp;ref=qf_sp_asin_til&amp;asins=4130654047&#34; style=&#34;width:120px;height:240px;&#34; scrolling=&#34;no&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Question Answering Using Enhanced Lexical Semantic Models (ACL2013) を読んだ</title>
          <link>http://tma15.github.io/blog/2014/12/read-question-answering-using-enhanced-lexical-semantic-models/</link>
          <pubDate>Wed, 03 Dec 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2014/12/read-question-answering-using-enhanced-lexical-semantic-models/</guid>
          <description>

&lt;p&gt;Question Answering Using Enhanced Lexical Semantic Models (&lt;a href=&#34;http://www.aclweb.org/anthology/P13-1171&#34;&gt;pdf&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Wen-tau Yih, Ming-Wei Chang, Christopher Meek and Andrzej Pastusiak, Microsoft Research, ACL 2013&lt;/p&gt;

&lt;h2 id=&#34;導入&#34;&gt;導入&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;自然文の質問文を入力として受け付けて、解答として適切な文の選択(answer sentence selection)をして出力する

&lt;ul&gt;
&lt;li&gt;単に名詞を解答として選択して出力するよりも、文脈が付いていたほうが根拠が分かるし、ユーザにとっては価値があるから&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;answer sentence selectionは質問文と文書中の文とのマッチングの問題と考えられる

&lt;ul&gt;
&lt;li&gt;単語の表層形のマッチングを単純な方法だと精度はそんなに上がらない&lt;/li&gt;
&lt;li&gt;深い意味解析をしたり構文木の編集距離 (Tree Edit Distance)をしている研究もあるが、計算コストが高い&lt;/li&gt;
&lt;li&gt;なのでこの研究では浅い意味解析を頑張ってanswer sentence selectionの性能を上げることに焦点を当てる

&lt;ul&gt;
&lt;li&gt;浅い意味解析は上位下位語や同義語などを識別するlexical sematics&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;この論文ではlatent word-alignment structureとしてanswer sentence selectionを定式化する&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;この論文の貢献&#34;&gt;この論文の貢献&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;色々なlexical semanticを組み合わせれば、学習アルゴリズムなどに関係なくanswer sentence selectionシステムの性能を上げられる&lt;/li&gt;
&lt;li&gt;lexical word-alignment structureは、非構造なモデルよりも高い性能を出せるが、両方のモデルにlexical semanticsを入れた場合、性能の差は小さくなる

&lt;ul&gt;
&lt;li&gt;計算コストを下げたいなら、lexical semanticsを使ってシンプルなモデルを使うこともできる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;問題設定&#34;&gt;問題設定&lt;/h2&gt;

&lt;p&gt;教師あり学習でanswer sentence selectionに取り組む。学習時は質問文qと、それに関連するラベル付きの文(yi, si)のリストが与えられるので、それを学習データとしてパラメータを学習。yiは1であればsiは正解の文、0であれば不正解の文を表す。予測時は未知の文に対し、文が正解である確率を予測し、yiとする。&lt;/p&gt;

&lt;p&gt;実際には文が正解であるかどうかではなく、文が質問文と意味的にマッチするかどうかを学習する。この論文では質問文と文の間には隠れ構造hが存在すると仮定する。隠れ構造hは質問文の単語と文の単語が対応するかどうかを表したバイナリのベクトル。&lt;/p&gt;

&lt;p&gt;文を構文木で表現する先行研究もあるが、導入部分での理由から、この論文では浅い意味解析により文を表現する。&lt;/p&gt;

&lt;h2 id=&#34;lexical-semantic-models&#34;&gt;lexical semantic models&lt;/h2&gt;

&lt;p&gt;表層系のみのマッチングでは微妙なので言語資源を作成する。&lt;/p&gt;

&lt;h3 id=&#34;類義語と反義語&#34;&gt;類義語と反義語&lt;/h3&gt;

&lt;p&gt;Polarity-Inducing latent semantic analysis (PILSA) modelを使う。シソーラス(文書と単語のtfidf行列?)を入力として、SVDでd行n列の行列を構築する。dは類義語や反義語のクラスタの数を表す。nは語彙の数。二つの単語を表す列のコサインが正であれば、その単語は類義語、負であれば反義語とみなす。&lt;/p&gt;

&lt;h3 id=&#34;上位語下位語&#34;&gt;上位語下位語&lt;/h3&gt;

&lt;p&gt;WordNetはカバレッジが低いので、&lt;a href=&#34;http://research.microsoft.com/en-us/projects/probase/&#34;&gt;Probase&lt;/a&gt;を使う。ある単語が別の単語の下位語である確率を保持している。&lt;/p&gt;

&lt;h3 id=&#34;意味的な単語の類似度&#34;&gt;意味的な単語の類似度&lt;/h3&gt;

&lt;p&gt;商用のサーチエンジンのクリックデータを使ってSiamese newural networkモデルを学習。入力はクエリとクリックしたページのタイトルの対の集合。ある文字列（クエリ）がどの文字列(クリックされたページのタイトル)と対応するかを表す行列を学習する。ページのタイトルを表す行ベクトルは密になるように圧縮されている。&lt;/p&gt;

&lt;h2 id=&#34;分類器の学習&#34;&gt;分類器の学習&lt;/h2&gt;

&lt;h3 id=&#34;bag-of-wordsモデル&#34;&gt;Bag-of-Wordsモデル&lt;/h3&gt;

&lt;p&gt;logistic regressionとboosted decision treeを用いる。&lt;/p&gt;

&lt;h3 id=&#34;隠れ構造モデル&#34;&gt;隠れ構造モデル&lt;/h3&gt;

&lt;p&gt;構造的なモデルではLatent-SVMの一種であるLCLRを用いる。目的関数 (単語間の意味的類似度) を最大化する隠れ構造hを選択して、損失項を最小化するように重みを更新するのを繰り返す。隠れ構造hがどの単語とどの単語の対応を見るかを制御している。隠れ構造は、「文のある単語は少なくとも質問文中の1つ以上の単語と対応していなければならない」、「質問文中の単語は文中のいずれかの単語と対応していなければならない」、というような制約を付与して整数計画法により選択する。&lt;/p&gt;

&lt;h3 id=&#34;素性&#34;&gt;素性&lt;/h3&gt;

&lt;p&gt;すべての素性は単語のIDFで重み付け&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;表層的な単語のマッチング&lt;/li&gt;
&lt;li&gt;WordNet: 同じsynsetに属する、上位語下位語、反義語関係にある&lt;/li&gt;
&lt;li&gt;lexical semantics: 上記実数値&lt;/li&gt;
&lt;li&gt;NE: 単語が同じタイプの固有表現の一部である&lt;/li&gt;
&lt;li&gt;answer type checking: 質問文がWHを接頭辞とする単語から始まる場合のルール。Whoで始まれば、PersonなNEと対応するみたいなもの。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;リッチな言語資源を使うほど、どの分類器でもMRR、MAPが向上。&lt;/p&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;複雑なアルゴリズムでやるよりも言語資源をリッチにして計算コストを減らすのは良さそうと思ったので、LCLRとlogistic regressionでどれくらい差が出るのか気になった。文間の単語の対応くらいだと問題はそれほど大きくないかもしれないけど、整数計画法のソルバーは早いものが有償だったりするので、そういったことを考えると分類器で複雑なことをするよりも言語資源を前処理でガッと作っておくほうが現実的な気がした。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>HMMを実装した</title>
          <link>http://tma15.github.io/blog/2014/10/hmm/</link>
          <pubDate>Sat, 25 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2014/10/hmm/</guid>
          <description>

&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;p&gt;勉強のためにGrahamさんが公開されている&lt;a href=&#34;http://www.phontron.com/teaching.php&#34;&gt;資料&lt;/a&gt;を参考に隠れマルコフモデルを実装した (このエントリでいう隠れマルコフモデルは、単語の品詞を推定するような教師あり学習)。
また、実験用のデータ、評価スクリプトも使用させて頂いている。&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #ffffff&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$./hmm train -i ../nlp-programming/data/wiki-en-train.norm_pos
$./hmm &lt;span style=&#34;color: #007020&#34;&gt;test&lt;/span&gt; -i ../nlp-programming/data/wiki-en-test.norm &amp;gt; my_answer.pos
$./nlp-programming/script/gradepos.pl ../nlp-programming/data/wiki-en-test.pos my_answer.pos
Accuracy: &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;75&lt;/span&gt;.83% &lt;span style=&#34;color: #333333&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;3460&lt;/span&gt;/4563&lt;span style=&#34;color: #333333&#34;&gt;)&lt;/span&gt;

Most common mistakes:
NNS --&amp;gt; NN      &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;49&lt;/span&gt;
RB --&amp;gt; NN       &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;35&lt;/span&gt;
JJ --&amp;gt; DT       &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;30&lt;/span&gt;
RB --&amp;gt; IN       &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;29&lt;/span&gt;
NN --&amp;gt; JJ       &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;28&lt;/span&gt;
NN --&amp;gt; IN       &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;25&lt;/span&gt;
JJ --&amp;gt; NN       &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;24&lt;/span&gt;
NN --&amp;gt; DT       &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;24&lt;/span&gt;
NNP --&amp;gt; NN      &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;22&lt;/span&gt;
VBN --&amp;gt; NN      &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;22&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;特に工夫はしていないのでこんなものかという感じ。
コードは&lt;a href=&#34;https://github.com/tma15/hmm&#34;&gt;こちら&lt;/a&gt;。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Goで日本語の文書を前処理して分類器を学習するところまでやってみる</title>
          <link>http://tma15.github.io/blog/2014/10/document-classification/</link>
          <pubDate>Mon, 20 Oct 2014 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2014/10/document-classification/</guid>
          <description>

&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;p&gt;日本語の文書を単純な方法で分類器を学習するところまでの一連の処理をGoでやってみる。
分類器は何でも良いのだけど、先日書いた&lt;a href=&#34;https://github.com/tma15/goAdaGrad&#34;&gt;AdaGrad+RDA&lt;/a&gt;を使う。&lt;/p&gt;

&lt;p&gt;ラベルが付いた日本語のデータがあるという前提で、以下の流れで進める。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文書を文に分割する。今回は「。」で区切る。&lt;/li&gt;
&lt;li&gt;文を形態素解析して名詞や動詞(表層形)を取り出し、文書をある単語を含む、含まないの二値で表現した素性ベクトルに変換する。&lt;/li&gt;
&lt;li&gt;訓練データを使って分類器を学習して、できたモデルの中身を見てみる。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;データ&#34;&gt;データ&lt;/h2&gt;

&lt;p&gt;下記URLから得られるテキストの一部を使って、ラベルをそれぞれ、「スポーツ」、「政治」、「Go言語」とラベルを付与し、第一カラムをラベル、第二カラムを文書としたCSVに保存しておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mainichi.jp/sponichi/news/20141020spn00m050016000c.html&#34;&gt;本田圭佑:セリエＡ日本人４人目マルチ!惨敗ブラジル戦憂さ晴らし&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yomiuri.co.jp/politics/20141020-OYT1T50026.html&#34;&gt;観劇収支ズレどう説明、公私混同疑いも…小渕氏&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ascii.jp/elem/000/000/935/935886/&#34;&gt;古いプログラミング言語がなくならない理由&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #ffffff&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #996633&#34;&gt;$cat&lt;/span&gt; data.csv
スポーツ,ＡＣミランＦＷ本田圭佑（２８）が１９日のアウェー、ベローナ戦で...
政治,渕経済産業相が関連する政治団体の資金処理問題で、最も不透明と指摘されて...
Go言語,編集者とこの本を5000部売れたらなという話をしたのをなんとなく覚えている。...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&amp;hellip;以降は省略している。&lt;/p&gt;

&lt;h2 id=&#34;ソースコード&#34;&gt;ソースコード&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/tma15/094abc128ad62e16cfed#file-mecab-go&#34;&gt;mecab.go&lt;/a&gt; (gist)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/tma15/094abc128ad62e16cfed#file-text-go&#34;&gt;text.go&lt;/a&gt; (gist)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;動かしてみる&#34;&gt;動かしてみる&lt;/h2&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #ffffff&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$./text data.csv &amp;gt; data
&lt;span style=&#34;color: #996633&#34;&gt;$cat&lt;/span&gt; data
スポーツ &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;２&lt;/span&gt;:1.000000 スルー:1.000000 本田:1.000000 セリエＡ:1.000000 アルゼンチン:1.000000... 
政治 円:1.000000 なる:1.000000 者:1.000000 向け:1.000000 会:1.000000 収支:1.000000...
Go言語 処理:1.000000 ため:1.000000 Go:1.000000 編集:1.000000 &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;5000&lt;/span&gt;:1.000000...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&amp;hellip;以降は省略している。これで、dataファイルに素性ベクトルが書き込まれる。
次に分類器を学習する。&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #ffffff&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$./adagrad -f data -m learn -w model
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;できあがったモデルの中身を見てみる。&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #ffffff&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #996633&#34;&gt;$cat&lt;/span&gt; model|grep &lt;span style=&#34;background-color: #fff0f0&#34;&gt;&amp;quot;^スポーツ&amp;quot;&lt;/span&gt;|sort -k3 -nr|head
スポーツ        カルロス・テベス        &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        モチベーション  &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        アルゼンチン    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        ＡＣミラン      &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        ユベントス      &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        抜け出し        &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        ベローナ        &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        ブラジル        &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        セリエＡ        &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
スポーツ        アウェー        &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.600000
&lt;span style=&#34;color: #996633&#34;&gt;$cat&lt;/span&gt; model|grep &lt;span style=&#34;background-color: #fff0f0&#34;&gt;&amp;quot;^政治&amp;quot;&lt;/span&gt;|sort -k3 -nr|head
政治    不透明  &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    上回っ  &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    関連    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    資金    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    説明    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    観劇    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    経済    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    産業    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    生じ    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
政治    焦点    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.800000
&lt;span style=&#34;color: #996633&#34;&gt;$cat&lt;/span&gt; model|grep &lt;span style=&#34;background-color: #fff0f0&#34;&gt;&amp;quot;^Go言語&amp;quot;&lt;/span&gt;|sort -k3 -nr|head
Go言語  インタビュー    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  カーニハン      &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  グーグル        &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  代わる  &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  それら  &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  いくら  &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  言語    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  解決    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  覚え    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
Go言語  考え    &lt;span style=&#34;color: #6600EE; font-weight: bold&#34;&gt;0&lt;/span&gt;.700000
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;一行が素性の重みを表していて、タブ区切りで左から順に、ラベル、素性、素性の重みとなっている。
たとえば、「カルロス・テベス」という素性の重みは、「スポーツ」というラベルで0.6の重みを持つことを表している。
このモデルでラベルが未知の文書を分類するとき、「カルロス・テベス」が出現しているほどその文書のラベルは「スポーツ」になりやすいし、「不透明」が出現しているほどラベルは「政治」になりやすい。&lt;/p&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;自然言語処理でよく使う単純な前処理をGoで書いた。
あとは、文字の半角、全角の統一とか色々とよくありそうな前処理あたりをもっと調べたい。&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>エッセイ Towards the Machine Comprehension of Text のメモ</title>
          <link>http://tma15.github.io/blog/2013/12/mct/</link>
          <pubDate>Fri, 27 Dec 2013 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2013/12/mct/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://research.microsoft.com/apps/pubs/default.aspx?id=206771&#34;&gt;エッセイ&lt;/a&gt;の一部をメモ。&lt;/p&gt;

&lt;p&gt;主張をまとめると「自然言語の機械的な理解には、大規模なデータ、性能の良い機械学習も重要だけど、言語の構造をしっかり考えることも大事」。&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Machine Comprehension of Text (MCT) (テキストの機械的理解) は人工知能のゴールである&lt;/li&gt;
&lt;li&gt;このゴールを達成したかどうかを確かめるために、研究者はよくチューリングテストを思い浮かべるが、Levesque (2013)が指摘するように、これは機械を知的に向かわせる、というよりは人間の知能を下げるほうに作業者を差し向けてしまう

&lt;ul&gt;
&lt;li&gt;※  チューリングテストとは、ある人間から見て、二人の対話のどちらが人間かどうか判別するテスト&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Levesqueはまた、チューリングテストよりも、世界知識を必要とするような選択肢が複数ある問題のほうが適しているとも主張している&lt;/li&gt;
&lt;li&gt;このエッセイでは、MCTは、&amp;rdquo;ネイティブスピーカーの大半が正しく答えられる質問に対して機械が答えた回答が、ネイティブスピーカーが納得できるものであり、かつ関連していない情報を含んでいなければ、その機械はテキストを理解しているもの&amp;rdquo;とする (つまり質問応答)&lt;/li&gt;
&lt;li&gt;このエッセイのゴールは、テキストの機械的理解という問題に何が必要なのかを観察することである&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;how-to-measure-progress&#34;&gt;How To Measure Progress&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;複数の選択肢がある質問応答のデータセットをクラウドソーシングを利用して作った

&lt;ul&gt;
&lt;li&gt;7歳の子供が読めるレベルのフィクションの短いストーリー&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Winograd Schema Test proposal (Levesque, 2013) は、質問と回答のペアは世界知識を要求するように注意深く設計されているので、生成には専門知識を要する質問を使うことを提案している

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;それは紙で出来ているので、ボールはテーブルから落ちた&amp;rdquo;の&amp;rdquo;それ&amp;rdquo;は何を指しているか？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;クラウドソーシングなのでスケーラビリティもある&lt;/li&gt;
&lt;li&gt;進捗が早ければ、問題の難易度を上げることもできる

&lt;ul&gt;
&lt;li&gt;語彙数を現状の8000から増やす&lt;/li&gt;
&lt;li&gt;ノンフィクションなストーリーを混ぜる&lt;/li&gt;
&lt;li&gt;タスクの定義を変える

&lt;ul&gt;
&lt;li&gt;正解が1つ以上、あるいは正解が1つもない問題など&lt;/li&gt;
&lt;li&gt;回答の根拠を出力するようにする&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;興味深いことは、ランダムな回答をするベースラインでは25%が正しい回答を得られる一方で、単純な単語ベースな手法が60%で、最近のモダンな含意認識システムを使っても60%くらいであることである&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;desiderata-and-some-recent-work&#34;&gt;Desiderata and some Recent Work&lt;/h2&gt;

&lt;p&gt;machine comprehensionに必要なものは、興味深い未解決な問題と通じている&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;意味の表現は二つの意味でスケーラブルであるべきである、すなわち (1) 複数ソースのノイジーなデータから教師なし学習で学習できて、 (2) 任意のドメインの問題に適用できるべきである&lt;/li&gt;
&lt;li&gt;モデルが巨大で複雑になっても、推論はリアリタイムでおこなえるべきである&lt;/li&gt;
&lt;li&gt;構築、デバッグの簡易化のためにシステムはモジュール化すべきである

&lt;ul&gt;
&lt;li&gt;モジュラ性はシステムを効率的に反応できるようにするべきである&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;エラーが起きた時に、何故それが起きたか理解可能にするために、各モジュールは解釈可能であるべきであり、同様にモジュールの構成も解釈可能であるべきである&lt;/li&gt;
&lt;li&gt;システムは単調的に修正可能であるべきである: 起きたエラーに対して、別のエラーを引き起こさずに、どのようにモデルを修正すればよいかが明白であるべきである&lt;/li&gt;
&lt;li&gt;システムは意味表現に対して論理的推論をおこなえるべきである

&lt;ul&gt;
&lt;li&gt;システムの入力のテキストの意味表現とシステムの世界モデルを組み合わせることで論理的な結論をだせるべきである&lt;/li&gt;
&lt;li&gt;もろさを避けるため、また根拠を正しく結合するために、論理的思考は確率的であるべきなようである (Richardson and Domingos, 2006)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;システムは質問可能であるべきである

&lt;ul&gt;
&lt;li&gt;任意の仮説に関して、真であるかどうか (の確率) を断言することができること&lt;/li&gt;
&lt;li&gt;私達はなぜその断言ができるか理解することができるべきである&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;最近の研究では&#34;&gt;最近の研究では&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;論理形式を文に対してタグ付けするなど、意味のモデル化はアノテーションコストがとても高い

&lt;ul&gt;
&lt;li&gt;興味深い代替手段としては、質問-回答のペアから論理形式を帰納するアノテーションがより低いものがある (Liang et al., 2011)&lt;/li&gt;
&lt;li&gt;教師なし学習でやる研究もある (Goldwassar et al. (2011) は60%の精度、ただし教師あり学習は80%)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;データはクラウドソーシングを利用すればスケールする (特にゲームとして提供すれば (Ahn and Dabbish, 2004))&lt;/li&gt;
&lt;li&gt;大量のラベルなしデータを使えばある粒度の意味のモデル化はできる (らしい) (Mikolove et al., 2013)&lt;/li&gt;
&lt;li&gt;意味モデル化のもう一つの問題は、あるタスク用に作ったモデルが他のタスクに使えないこと&lt;/li&gt;
&lt;li&gt;とても難しいタスクに挑戦するとき、モジュラ性、デバッグ性、解釈性は、良い精度を出すのに役立つ

&lt;ul&gt;
&lt;li&gt;画像分類タスクの現在のレコードホルダーが畳み込みネットワークが実際に何をしているのかを理解するための手法を設計したのは偶然の一致ではない: (Zeiler and Fergus, 2013)&lt;/li&gt;
&lt;li&gt;修正可能性も強く関連している

&lt;ul&gt;
&lt;li&gt;現在の機械学習モデルは、誤った例を正しく分類できるように修正するとき、別の例で新たな誤りをしないという保証がない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;質問可能性は別のデバッグツールである

&lt;ul&gt;
&lt;li&gt;理解が簡単であるほど、そのモデルはうまくいく&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;seven-signposts&#34;&gt;Seven Signposts&lt;/h2&gt;

&lt;h3 id=&#34;how-to-incorporate-structure-in-learning&#34;&gt;How to Incorporate Structure in Learning?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;初期のAIはルールベース

&lt;ul&gt;
&lt;li&gt;経験的で、もろく、スケールしない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;機械学習手法は構造データを扱えるように拡張されているが、主な方法は統計的なものである: 教師あり学習の基本的な設定では、

&lt;ul&gt;
&lt;li&gt;データはある分布から生成されると仮定&lt;/li&gt;
&lt;li&gt;モデル、コスト関数 (しばしば凸関数) 、ラベル付きデータが必要&lt;/li&gt;
&lt;li&gt;ゴールは手元の訓練データのエラーを最小化すること (正則化は簡単のため考えない)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;構造は、コスト関数の探索時に構造の制約を入れることで考慮される

&lt;ul&gt;
&lt;li&gt;言語はすごく構造的なので、機械学習のモデルを微調整して構造を考慮するよりも、最初からこの構造を認識しておくべきである&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;言い換えれば機械学習は不確かさを扱う基本的な方法である

&lt;ul&gt;
&lt;li&gt;もし、あまりに早く不確かさをモデル化することが、データの構造について我々が知っていることのほとんどを無視してしまうことにつながるなら、この誘惑には対抗しなければならない&lt;/li&gt;
&lt;li&gt;そして、ほとんどの機械学習のアルゴリズムは、とてもシンプルなラベル (例えば二値ラベル) を使って、この上なく見事に不確かさをモデル化するように調整されている&lt;/li&gt;
&lt;li&gt;確率的なグラフィカルモデルはモデルの構造の問題に取り組んでいるが、モデルの構造は人手で設計されているのでスケールしない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;先程述べたように、最近の研究では論理構造と統計モデルを直接組み合わせているが、まだスケーラビリティが問題ある&lt;/li&gt;
&lt;li&gt;私達は、一つの極端 (人手で設計したルールに基づくAI) から、もう一つの極端 (明示的なルールがない機械学習) にきている&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;do-large-data-and-deep-learning-hold-the-key&#34;&gt;Do Large Data and Deep Learning Hold the Key?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;ここ10年で、大量のデータを使うことで、昔から難しいタスクであった、質問応答、オントロジーの構築などですばらしい進歩が得られた

&lt;ul&gt;
&lt;li&gt;deep neural networkがYouTubeの画像データを使って学習した&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;しかしながら、意味のモデル化を避け、データの規模に頼っているシステムはもろい&lt;/li&gt;
&lt;li&gt;AskMSR (人手で設計したルールに基づくQAシステム (Brill et al., 2002) に&amp;rdquo;How many feet are there in a lightyear? (1光年は何フィートか)？&amp;rdquo;という質問をしたら&amp;rdquo;Winnie the Pooh&amp;rdquo;と回答した

&lt;ul&gt;
&lt;li&gt;ディズニーのキャラクターであるBuzz Lightyearが根拠になって回答された&lt;/li&gt;
&lt;li&gt;意味の処理をちゃんとやっていない (質問は&amp;rdquo;how many&amp;rdquo;で始まっているので、回答は数字なはず)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;IBMのWatson (IRの様々な技術を組み合わせて人間のクイズ王に勝ったシステム) でさえもUSの都市に関する質問をしたらトロントと答えた&lt;/li&gt;
&lt;li&gt;Deep Learningは強力なパラダイムである

&lt;ul&gt;
&lt;li&gt;音声認識、画像分類では大きな成果を上げているが、まだシステムが解釈可能でなかったり、質問可能でなかったり、修正可能でなかったり、スケールしなかったりする&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;why-is-nlp-so-hard&#34;&gt;Why is NLP so Hard?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;自然言語処理はテキストの構造を直接モデル化する代替手段と見ることができるが、まだ初期段階である

&lt;ul&gt;
&lt;li&gt;文が意味をなすかどうか、あるいは文が文法的かどうかという人間には簡単な問題すらまだ解けていない

&lt;ul&gt;
&lt;li&gt;そのドメインにおけるリッチなモデルが、自然言語の理解には必要であるため

&lt;ul&gt;
&lt;li&gt;しかし、リッチなモデルを作るには、自然言語処理の高い技術が必要&lt;/li&gt;
&lt;li&gt;そのため、問題を限定して解くことが多い&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;別の理由としては、NLPのタスクで機械学習のモデルを学習するときには、データの構造を直接利用する、というよりは二値ラベルのようなシンプルなものを利用するため問題をうまく解けないということも考えられる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;can-we-limit-scope-for-manageability-yet-still-achive-scalability&#34;&gt;Can we Limit Scope for Manageability, yet Still Achive Scalability?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;意味をモデル化する試みでは、簡単のために、よく問題を限定する&lt;/li&gt;
&lt;li&gt;問題を限定すると、その解はスケールできない&lt;/li&gt;
&lt;li&gt;問題を限定することには、科学的には意味があるが、私達は一般化が簡単な問題の限定、大規模データがある問題を探さなければならない&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;are-brains-using-machine-learning&#34;&gt;Are Brains Using Machine Learning?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;あなたが友達が何か誤解をしていて苦労しているのに気づいたとしましょう&lt;/li&gt;
&lt;li&gt;どうやって友達を救いますか？

&lt;ul&gt;
&lt;li&gt;彼を何テラバイトもの訓練データとともに部屋に閉じ込め、「一週間これでパラメータを更新しといてね」ということはしないでしょう&lt;/li&gt;
&lt;li&gt;あなたはあっという間にもっともありがちな彼の誤解が何なのかを考える

&lt;ul&gt;
&lt;li&gt;「彼が誤解を修正すべきところはどこなんだろう」&lt;/li&gt;
&lt;li&gt;あなたは一つや二つ、彼に質問をするかもしれない: 彼には質問することができる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;つまり、あなたは彼の思考に関する解釈可能なモデルを持っていることになる&lt;/li&gt;
&lt;li&gt;モジュラ性は人間の学習の強い区分けによって提案される

&lt;ul&gt;
&lt;li&gt;人間は自転車に乗る方法を学ぶ時に歯の磨き方を忘れない&lt;/li&gt;
&lt;li&gt;機械は、あらたに間違えたことを修正する時に、もともと正しく分類できていたものを間違えるようになってしまう&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;難しいタスクにおいてさえ、人間は何かの意味を認識する時に、大量のラベル付きデータを使わない

&lt;ul&gt;
&lt;li&gt;学習のプロセスは世界知識のモデルを更新する小さなステップに分割される

&lt;ul&gt;
&lt;li&gt;見えない統計的なパラメータを更新しているわけではない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;人間は記録、更新が簡単な意味のモデルを持たなければならない

&lt;ul&gt;
&lt;li&gt;少なくとも、彼らのモデルは解釈可能で、修正可能で、質問可能であることを示唆している&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;discussion&#34;&gt;Discussion&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;AIの初期からあるルールベースからあって、研究者はそれに依存し過ぎることに慎重であることは明白であった&lt;/li&gt;
&lt;li&gt;ルールベースなシステムが解けない問題は、あまりない例外であり、それを解けるようにするために人手でルールを更新するというのは大規模なデータに対してスケールしない&lt;/li&gt;
&lt;li&gt;機械学習は多くの場合、強力なツールであるのだけど、多くの場合解釈が難しく、ラベル付きデータ無しに改善することが難しい&lt;/li&gt;
&lt;li&gt;機械学習は、適切な場面で使えば当然強力なツールである

&lt;ul&gt;
&lt;li&gt;データの構造を最大限活用した後に、データに残っている不確かさのモデル化に使うことに制限することが考えられる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;人間にとってテキストが曖昧性を持たないという事実は、不確かさのモデル化は解くべき重要な問題ではないことを示唆している

&lt;ul&gt;
&lt;li&gt;不確かさがモデル化されなければならない状況やラベルが極めて単純な状況において機械学習アルゴリズムの使用を抑えて、代わりにリッチな構造の、曖昧性のないテキストのために設計された他の手段を模索することは、機械学習が基づく数学的な基礎を放棄しているわけではない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>文書要約メモ（ACL2013）</title>
          <link>http://tma15.github.io/blog/2013/9/acl2013-summ-note/</link>
          <pubDate>Mon, 30 Sep 2013 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2013/9/acl2013-summ-note/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;http://aclweb.org/anthology//P/P13/&#34;&gt;acl anthology&lt;/a&gt;よりロングペーパーとして
採択された論文の中からSummarizationをタイトルに含む論文を探して概要だけを読んだときのメモ。&lt;/p&gt;

&lt;h1 id=&#34;fast-and-robust-compressive-summarization-with-dual-decomposition-and-multi-task-learning-p13-1020-pdf&#34;&gt;Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning (P13-1020.pdf)&lt;/h1&gt;

&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;複数文書要約のための文選択、文圧縮を同時におこなうモデルを使った双対分解を提案。&lt;/li&gt;
&lt;li&gt;先行研究のIneger Linear Programmingに基づいた手法と比べると

&lt;ul&gt;
&lt;li&gt;提案手法はソルバーを必要としない&lt;/li&gt;
&lt;li&gt;提案手法は有意に速い&lt;/li&gt;
&lt;li&gt;提案手法は簡潔さ・情報の豊富さ・文法のきれいさが優れている&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;さらに既存の抽出型要約、文圧縮の要約データを活用したマルチタスク学習を提案する&lt;/li&gt;
&lt;li&gt;TAC2008のデータで実験をおこなって今までで一番高いROUGE値となった。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;using-supervised-bigram-based-ilp-for-extractive-summarization-p13-1099-pdf&#34;&gt;Using Supervised Bigram-based ILP for Extractive Summarization (P13-1099.pdf)&lt;/h1&gt;

&lt;h2 id=&#34;概要-1&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Integer Linear Programmingによる抽出型文書要約において、bigramの重みを教師有り学習により推定する&lt;/li&gt;
&lt;li&gt;regression modelによってbigramが参照要約の中でどれくらいの頻度で出現するかを推定。&lt;/li&gt;
&lt;li&gt;学習では、参照要約中での真の頻度との距離が最小になるように学習をする&lt;/li&gt;
&lt;li&gt;選択されるbigramの重みの総和が最大になるように文選択をおこなうような定式化をしている&lt;/li&gt;
&lt;li&gt;提案手法は既存のILPな手法と比べてTACのデータにおいて良い性能であることと、TACのbestだったシステムとの比較結果を示す&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;summarization-through-submodularity-and-dispersion-p13-1100-pdf&#34;&gt;Summarization Through Submodularity and Dispersion (P13-1100.pdf)&lt;/h1&gt;

&lt;h2 id=&#34;概要-2&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Linらのサブモジュラな手法を一般化することにより新たな最適化手法を提案する&lt;/li&gt;
&lt;li&gt;提案手法では要約にとって欲しい情報はサブモジュラ関数と非サブモジュラ関数の総和で表される。この関数をdispersionと呼ぶ&lt;/li&gt;
&lt;li&gt;非サブモジュラ関数は要約の冗長性を除くために文同士の様々な似ていなさの度合いを図るために使う&lt;/li&gt;
&lt;li&gt;三つのdispersion関数を使って、全部の場合で貪欲法を使っても最適解が得られることを示す&lt;/li&gt;
&lt;li&gt;DUC 2004とニュース記事に対するユーザのコメントを使って実験&lt;/li&gt;
&lt;li&gt;サブモジュラ関数だけを使ったモデルよりも良い性能であることを示す&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;subtree-extractive-summarization-via-submodular-maximization-p13-1101-pdf&#34;&gt;Subtree Extractive Summarization via Submodular Maximization (P13-1101.pdf)&lt;/h1&gt;

&lt;h2 id=&#34;概要-3&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;@Pnnc205jさんの論文&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;towards-robust-abstractive-multi-document-summarization-a-caseframe-analysis-of-centrality-and-domain-p13-1121-pdf&#34;&gt;Towards Robust Abstractive Multi-Document Summarization: A Caseframe Analysis of Centrality and Domain (P13-1121.pdf)&lt;/h1&gt;

&lt;h2 id=&#34;概要-4&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;文書要約において中心性とは元の文書の核となる部分を含むべきだということ&lt;/li&gt;
&lt;li&gt;既存の手法は冗長性を除いたり文圧縮をおこなうことで中心性を得ようと試みている&lt;/li&gt;
&lt;li&gt;この論文では元文書のドメインを活用することで文書要約が、抽象型要約に向けてどれくらいこのようなパラダイムから前進できるかを調査する&lt;/li&gt;
&lt;li&gt;実験ではcaseframeという意味的なレベルで人手の要約とシステムの要約の近さを図る&lt;/li&gt;
&lt;li&gt;提案手法は

&lt;ul&gt;
&lt;li&gt;より抽象的で、文のまとめあげをおこなう&lt;/li&gt;
&lt;li&gt;topicalなcaseframeを他のシステムほど含まない&lt;/li&gt;
&lt;li&gt;元文書だけから再構築はできないけど、同じドメインの文書を加えればできる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;実験結果は、本質的な改善は中心性を最適化するための式を作ることよりも、ドメイン知識が必要であることを示唆している&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;a-sentence-compression-based-framework-to-query-focused-multi-document-summarization-p13-1136-pdf&#34;&gt;A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization (P13-1136.pdf)&lt;/h1&gt;

&lt;h2 id=&#34;概要-5&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;クエリ指向型複数文書要約のための文圧縮を使った手法を提案する&lt;/li&gt;
&lt;li&gt;構文木に基づく文圧縮モデル&lt;/li&gt;
&lt;li&gt;ビームサーチのデコーダを提案。効率的、高圧縮。&lt;/li&gt;
&lt;li&gt;圧縮するためのスコア関数にどうやって言語的な特徴やクエリとの関連性を組み込むのかを示す&lt;/li&gt;
&lt;li&gt;DUC 2006, DUC 2007のstate-of-the-artよりも有意によくなることを示す&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;domain-independent-abstract-generation-for-focused-meeting-summarization-p13-1137-pdf&#34;&gt;Domain-Independent Abstract Generation for Focused Meeting Summarization (P13-1137.pdf)&lt;/h1&gt;

&lt;h2 id=&#34;概要-6&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;ドメイン知識を使わずに会議の対話ログの抽象型要約をおこなう&lt;/li&gt;
&lt;li&gt;Multiple-Squence Alignmentという他のドメインにも使いまわせる抽象的な要約のテンプレートを使う&lt;/li&gt;
&lt;li&gt;Overgenerate-and-Rankというものを候補の生成、ランキングに使うらしい&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Robust Disambiguation of Named Entities in Text (EMNLP 2011)</title>
          <link>http://tma15.github.io/blog/2013/2/robust-disambiguation-of-named-entities-in-text/</link>
          <pubDate>Sat, 16 Feb 2013 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2013/2/robust-disambiguation-of-named-entities-in-text/</guid>
          <description>

&lt;p&gt;Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Furstenau, Manfred Pinkal,
Marc Spaniol, Bilyana Taneva, Stefan Thater, Gerhard Weikum&lt;/p&gt;

&lt;p&gt;proceeding: &lt;a href=&#34;http://www.aclweb.org/anthology-new/D/D11/D11-1072.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;解いている問題&#34;&gt;解いている問題&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Named entity disambiguationをする&lt;/li&gt;
&lt;li&gt;Collective disambiguationは、意味的に似た文脈に現れるentityを含むmentionがあるときにはうまくいく&lt;/li&gt;
&lt;li&gt;mentionが短かったり、あまり関連しないトピックについてのものだとうまくいかない
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;e.g. MadridでManchesterとBarcelonaの試合があった&lt;/li&gt;
&lt;li&gt;Madridは本当はLOCATIONだけど、ORGANIZATIONと判定される
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;アプローチ&#34;&gt;アプローチ&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;priorとcontext similarityとcoherenceの3つの要素の線形結合からなる関数をもとに、重み付きエッジからなるグラフをつくる
&lt;ul&gt;

&lt;ul&gt;
&lt;li&gt;priorは、mentionに含まれる表現が一般的にentity e_jである確率&lt;/li&gt;
&lt;li&gt;context similarityはmentionとentityの文脈類似度&lt;/li&gt;
&lt;li&gt;coherenceは他のmentionのentityとの意味的な近さ
&lt;ul&gt;

&lt;ul&gt;
&lt;li&gt;Wikipediaの二つの記事にともにリンクを張っている記事の数をもとにした指標
&lt;/ul&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;グラフの中からサブグラフを選択
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;サブグラフは、一つのmentionが一つのentityとエッジをもつ&lt;/li&gt;
&lt;li&gt;サブグラフは、ノードに貼られたエッジの重みの総和(weigted degree)の最小値を最大化するようにつくる&lt;/li&gt;
&lt;li&gt;サブグラフに含まれるエッジの重みの総和を最大化するシンプルな戦略は支配的なentityがあるとうまくいかない
&lt;ul&gt;
    + Michael Jordanみたいな支配的なentityがあるとlong tailに位置するentity disambiguationがうまくいかない
&lt;/ul&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;サブグラフの選択は、NP困難なので近似的なアルゴリズムをつかって問題を解く&lt;/li&gt;
&lt;li&gt;アルゴリズムは反復的にweighted degreeが小さなentity nodeを削除する&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ただし、必ずすべてのmentionがいずれかのentityとエッジを一つ持つようにする
&lt;ul&gt;
こうすると準最適な解に陥ることがあるので前処理でmentionとの距離が遠いentityは削除
&lt;/ul&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;prior, context similarity, coherenceの3つの要素をうまいこと使ってrobustなモデルになっているらしい&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Joint Inference of Named Entity Recognition and Normalization for Tweets (ACL 2012)</title>
          <link>http://tma15.github.io/blog/2013/2/joint-inference-of-named-entity-recognition-and-normalization-for-tweets/</link>
          <pubDate>Wed, 06 Feb 2013 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2013/2/joint-inference-of-named-entity-recognition-and-normalization-for-tweets/</guid>
          <description>

&lt;p&gt;Xiaohua Liu, Ming Zhou, Furu Wei, Zhongyang Fu, Xiangyang Zhou&lt;/p&gt;

&lt;p&gt;proceeding: &lt;a href=&#34;http://www.aclweb.org/anthology-new/P/P12/P12-1055.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;解いている問題&#34;&gt;解いている問題&lt;/h2&gt;

&lt;p&gt;tweet (英語のtweetに限定) の集合が与えられたときに&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tweetに対して固有表現を指しているテキストを同定し，あらかじめ決められたラベル {PERSON, ORGANIZATION, PRODUCT, LOCATION} を割り当てる．&lt;/li&gt;
&lt;li&gt;これらの同定されたテキストに対して名寄せをおこなう．
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;名寄せは，一番単語数が多い表現にまとめる&lt;/li&gt;
&lt;li&gt;最大の単語数の表現が複数あればWikipediaにある表現を採用&lt;/li&gt;
&lt;li&gt;PERSONと識別された三つの表現&amp;rdquo;Gaga&amp;rdquo;, &amp;ldquo;Lady Gaaaga&amp;rdquo;, &amp;ldquo;Lady Gaga&amp;rdquo;は&amp;rdquo;Lady Gaga&amp;rdquo;にまとめる．
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;アプローチ&#34;&gt;アプローチ&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;固有表現認識 (NER) モデルの学習の際に，固有表現の名寄せ (NEN) モデルの学習も同時に行うことでお互いの精度を上げる
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;tweetは，エンティティに対していろいろな表現をされる．&lt;/li&gt;
&lt;li&gt;e.g. &amp;ldquo;Anne Gronloh&amp;rdquo;というエンティティには&amp;rdquo;Mw.,Gronloh&amp;rdquo;, &amp;ldquo;Anneke Kronloh&amp;rdquo;, &amp;ldquo;Mevrouw G&amp;rdquo;など
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&amp;rdquo;&amp;hellip; Alex&amp;rsquo;s jokes. &amp;hellip;&amp;ldquo;と&amp;rdquo;&amp;hellip; Alex Russo was like&amp;hellip;&amp;ldquo;という二つのtweet
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;NERモデルにより&amp;rdquo;Alex&amp;rdquo;と&amp;rdquo;Alex Russo&amp;rdquo;がともにPERSONであることが識別できれば，NENモデルは&amp;rdquo;Alex&amp;rdquo;を&amp;rdquo;Alex Russo&amp;rdquo;に名寄せできる．
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&amp;rdquo; &amp;hellip; she knew Burger King when &amp;hellip;&amp;ldquo;と&amp;rdquo;.. I&amp;rsquo;m craving all sorts of food: mcdonalds, burger king, &amp;hellip;&amp;ldquo;という二つのtweet
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;NENモデルが&amp;rdquo;Burger King&amp;rdquo;と&amp;rsquo;burger king&amp;rdquo;が別のエンティティを指していると識別できればNERモデルはこれらに異なるラベルを割り当てられる．
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;学習にはCRFを用いる
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;skip-chain CRFと似たモデルだけど，tweet mのi番目の単語とtweet nのj番目の単語が同じエンティティを指しているかを表すnormalization変数があるのが違う．&lt;/li&gt;
&lt;li&gt;ラベルは{B, I, L, O, U}&lt;/li&gt;
&lt;li&gt;一つ目のtweetに含まれる&amp;rdquo;Gaga&amp;rdquo;と二つ目のtweetに含まれる&amp;rdquo;Lady Gaga&amp;rdquo;にPERSONが割り当てられ，一つ目のtweetに含まれる&amp;rdquo;Gaga&amp;rdquo;と二つ目のtweetに含まれる&amp;rdquo;Gaga&amp;rdquo;が同一のエンティティを指していると識別できれば&amp;rdquo;Gaga&amp;rdquo;と&amp;rdquo;Lady Gaga&amp;rdquo;は同じものを指している&lt;/li&gt;
&lt;li&gt;(CRFの復習) 重みを更新するときの，対数裕度関数を重み変数λで偏微分したときに二つの項がでてくる．&lt;/li&gt;
&lt;li&gt;初項は正解となるラベルが与えられたときの，素性関数kの訓練データに対しての合計値&lt;/li&gt;
&lt;li&gt;第二項は現在のパラメータによって決定されるモデルによる素性関数kの期待値の合計値&lt;/li&gt;
&lt;li&gt;初項が第二項よりも大きいほど，重みλ_kは大きくなるし，初項が第二項よりも小さいほど重みλ_kは小さくなる．&lt;/li&gt;
&lt;li&gt;skip-chainなので，素性関数は隣り合ったラベルの組み合わせに加えて，隣り合っていないラベルの組み合わせも見ることができるし，このモデルでは他のツイートの単語につくラベルとの関係も見る．
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;複数のtweetを同時に考慮することの利点&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;rdquo;&amp;hellip; Bobby Shaw you don&amp;rsquo;t invite the wind&amp;hellip;&amp;ldquo;と&amp;rdquo;&amp;hellip; I own yah! Loool bobby shaw&amp;hellip;&amp;rdquo;
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Bobby Shaw&amp;rdquo;をPERSONと識別することは比較的簡単．&lt;/li&gt;
&lt;li&gt;一つ目のtweetの&amp;rdquo;you&amp;rdquo;が，二つ目のtweetの&amp;rsquo;bobby shaw&amp;rdquo;がPERSONであることの手がかりとなる．
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ラベルの候補の絞り込み&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;外部資源から固有表現を取ってきて辞書を作っておく．&lt;/li&gt;
&lt;li&gt;tweetの中に，辞書に含まれる固有表現の一部と一致していれば，ラベルの候補の集合へその固有表現のラベルを加える
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;new york&amp;rdquo;という句が出てきたとき，辞書にある&amp;rdquo;New York City&amp;rdquo;と&amp;rdquo;New York Times&amp;rdquo;と一致する．&lt;/li&gt;
&lt;li&gt;&amp;ldquo;new&amp;rdquo;には，&amp;rdquo;B-LOCATION&amp;rdquo;, &amp;ldquo;B-ORGANIZATION&amp;rdquo;，&amp;rdquo;york&amp;rdquo;には&amp;rdquo;I-LOCATION&amp;rdquo;, &amp;ldquo;I-ORGANIZATION&amp;rdquo;がラベルの候補の集合にそれぞれ追加される．
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ラベルの候補の集合へひとつでもラベルが追加されていれば，y^i_mはこのラベルの候補の集合のみしか考えない&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;normalization変数zもルールである程度決めてしまう&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;同じtweet mで，表層的に同じ語があれば，それらは同じエンティティについて述べていると考え，z^{ij}_{mm}=1とする．&lt;/li&gt;
&lt;li&gt;tweet mとtweet nのcos類似度が0.8以上なら，すべてi, jに対してのz^{ij}_{mn}=1&lt;/li&gt;
&lt;li&gt;tweet mとtweet nのcos類似度が0.3以下なら，すべてi, jに対してのz^{ij}_{mn}=0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;素性&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;大文字かどうか，接頭辞，接尾辞，ストップワードかどうかなど&lt;/li&gt;
&lt;li&gt;基本形，out-of-vocabularyかどうか，ハッシュタグかどうかなど&lt;/li&gt;
&lt;li&gt;ラベル候補の絞り込み時にラベル候補の集合に何か追加されているかどうか，一番追加されているラベルは何か&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;感想-疑問点&#34;&gt;感想・疑問点&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Discussionで，エラーの大半がスラング，略語だと書かれているけど，これを解決することで提案手法がTwitterのデータを扱う上での強みとなりそうだと思った．&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Named Entity Disambiguation in Streaming Data (ACL 2012)</title>
          <link>http://tma15.github.io/blog/2013/2/named-entity-disambiguation-in-streaming-data/</link>
          <pubDate>Fri, 01 Feb 2013 00:00:00 UTC</pubDate>
          <author></author>
          <guid>http://tma15.github.io/blog/2013/2/named-entity-disambiguation-in-streaming-data/</guid>
          <description>

&lt;p&gt;Alexandre Davis, Adriano Veloso, Algigran S. da Silva, Wagner Meira Jr., Alberto H. F. Laender&lt;/p&gt;

&lt;p&gt;proceeding: &lt;a href=&#34;http://www.aclweb.org/anthology-new/P/P12/P12-1086.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;解いている問題&#34;&gt;解いている問題&lt;/h2&gt;

&lt;p&gt;名詞nを含む短いテキストが、あるエンティティeのことを指しているか、指していないかを当てる二値分類問題。&lt;/p&gt;

&lt;p&gt;課題&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Twitterのようなmicro-blogのテキストは単語の数が少なく、暗号のように書かれていることもあるため、固有表現を認識することが難しい&lt;/li&gt;
&lt;li&gt;テキストの単語の数の少なさから、エンティティの周辺に共通して現れる文脈から特徴を学習することが難しい&lt;/li&gt;
&lt;li&gt;テキストが次々と流れてくるため、テキストを処理するために外部知識を参照していると処理が間に合わない&lt;/li&gt;
&lt;li&gt;テキストが次々とやってきて、テキストの傾向も変わるのでモデルがすぐにデータに合わなくなってしまう&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;提案手法のモチベーション&#34;&gt;提案手法のモチベーション&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;外部知識を参照している余裕がないなら、ストリーム中の（ラベルなしの）大量のテキストから得られる情報を使う。&lt;/li&gt;
&lt;li&gt;ラベルなしのテキストを負例として学習すると、負例の多さからモデルが過学習をおこし、大量のfalse-negativeが出てしまうおそれがある。
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;正例を作ることは比較的簡単だが、負例を作るのはコストがかかる。
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;なので、EMアルゴリズムを使って二値分類器を反復的に洗練させるのがこの論文のアイディア。&lt;/li&gt;
&lt;li&gt;具体的には、ラベルなしの事例が負例である確率を計算してラベル付きデータとして訓練データを増やす。&lt;/li&gt;
&lt;li&gt;このラベル付きの事例は各ステップでラベルを変更することができる。&lt;/li&gt;
&lt;li&gt;どの事例がどちらのラベルになるかは、最終的には収束して、観測データに最もフィットしたラベルに落ち着くことが期待される。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;曖昧性解消のアプローチ&#34;&gt;曖昧性解消のアプローチ&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;（良くない）シンプルな正例の作り方の例&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Twitter中である会社と関連したアカウントあり、このアカウントのプロフィールに書かれたメッセージは、その会社名を含むメッセージである可能性がある。&lt;/li&gt;
&lt;li&gt;こんな感じで正例を集める方法が考えられるが、このやり方はfalse-positiveがないことを保証していない。
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;つまり、本当はその会社のことを言及したメッセージではないのに、そのアカウントのメッセージなので正例とみなされていまう可能性がある。
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;このようにして作成された訓練データを用いて学習したモデルの性能はそんなに上がることが期待できない。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ラベルなしの事例の信頼性を上げて、訓練データとして扱うことでモデルの性能を上げる&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ラベルなしの事例を扱うコストは、人手のアノテーションでラベル付きの事例を作成するコストより低い。&lt;/li&gt;
&lt;li&gt;具体的には、EMアルゴリズムを使う&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;訓練データの初期状態としてありうる二つのパターン&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;訓練データは真に正例の事例と、大量のラベルなしの事例からなる
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;ラベルなしのデータは最初、負例とみなされるのでfalse-negativeな事例を含む可能性がある
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;訓練データはおそらく正例の事例と、大量のラベルなしの事例からなる
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;正例は真に正例という保証はないので、false-positiveな事例を含む可能性がある&lt;/li&gt;
&lt;li&gt;ラベルなしのデータは最初、負例とみなされるのでfalse-negativeな事例を含む可能性がある
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;E-step&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;訓練データ中のすべての事例に、{正例、負例}のそれぞれの場合で閾値以上、あるいは以下であった場合に正例あるいは負例を割り当てる&lt;/li&gt;
&lt;li&gt;具体的には事例xが負例である確率α(x, -)が閾値α^x_{min}と等しいかそれより小さければ、xは正例となり、大きければ負例となる
&lt;ul&gt;&lt;/li&gt;
&lt;li&gt;α^x_{min}は、事例ごとに決定されるパラメータ
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;M-step&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分類器Rを更新、訓練データのすべての事例に負例である確率α(x, -)を割り当てる&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;分類器R&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ある単語の集合が正例に現れやすいか、負例に現れやすいかを学習する。&lt;/li&gt;
&lt;li&gt;このルール（単語の集合）の信頼性を、頻度をもとに計算して、事例が負である確率を、集めたルールの集合の重み付きの投票のような感じで計算する。&lt;/li&gt;
&lt;li&gt;ラベルのtransitでは、ラベル付きデータから、ランダムに正例をいくつか抜き出して、残りをラベルなしのデータとみなしている。&lt;/li&gt;
&lt;li&gt;分類器の更新は、すべての事例のlabel transitionを終えてから行うよりも、各事例のlabel transitionを終えるごとに行うほうがいい結果だった。&lt;/li&gt;
&lt;li&gt;また、label transition operationは負例を正例にする操作に加え、正例を負例にする操作もできるようにしたほうがいい結果だった。&lt;/li&gt;
&lt;li&gt;SVMの代わりにLazy Associative Classifiersの変種を使うことで、速度がかなり早くなった。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;疑問点&#34;&gt;疑問点&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;最初に選ぶ少数の正例によって精度がどれくらい変わるのだろうと思った (できあがるモデルがどれくらい初期値に依存するのか)&lt;/li&gt;
&lt;li&gt;α^x_{min}は、正例と負例のバランスがよくなるように決定しているが、正例と負例のバランスはちょうどいいという仮定は直感にあっているのか
（ある単語のパターンでは負例になりやすいとかそういうことではない？）&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
      
    

  </channel>
</rss>
