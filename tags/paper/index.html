<!DOCTYPE html>
<html lang="ja">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.67.0 with theme Tranquilpeak 0.4.7-BETA">
<meta name="author" content="Takuya Makino">
<meta name="keywords" content="">
<meta name="description" content="Hugo tranquilpeak theme demo">


<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta property="og:type" content="website">
<meta property="og:title" content="paper">
<meta name="twitter:title" content="paper">
<meta property="og:url" content="https://tma15.github.io/tags/paper/">
<meta property="twitter:url" content="https://tma15.github.io/tags/paper/">
<meta property="og:site_name" content="Now is better than never.">
<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta name="twitter:description" content="Hugo tranquilpeak theme demo">
<meta property="og:locale" content="ja">


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@tma15">


  <meta name="twitter:creator" content="@tma15">










  <meta property="og:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">


    <title>paper</title>

    <link rel="icon" href="https://tma15.github.io/favicon.png">
    
      <link rel="alternate" type="application/rss+xml" title="RSS" href="https://tma15.github.io/tags/paper/index.xml">
    

    

    <link rel="canonical" href="https://tma15.github.io/tags/paper/">

    
    <script type="text/javascript" async
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
          });
    </script>


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
          (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-5663917297524414",
                  enable_page_level_ads: true
                });
    </script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://tma15.github.io/css/style-twzjdbqhmnnacqs0pwwdzcdbt8yhv8giawvjqjmyfoqnvazl0dalmnhdkvp7.min.css" />
    
    
      
        <link rel="stylesheet"  href="https://tma15.github.io/css/mystyle.css">
      
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-20414370-4', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://tma15.github.io/">Now is better than never.</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://tma15.github.io/#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=90" alt="プロフィール画像" />
      
    
    </a>
  

  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
           (adsbygoogle = window.adsbygoogle || []).push({
                         google_ad_client: "ca-pub-5663917297524414",
                         enable_page_level_ads: true
                    });
  </script>
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://tma15.github.io/#about">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
        </a>
        <h4 class="sidebar-profile-name">Takuya Makino</h4>
        
          <h5 class="sidebar-profile-bio">自然言語処理の研究開発に従事しています。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、Python、C++に関する記事が多めです。詳細は<a href="https://tma15.github.io/about/">プロフィール</a>を御覧ください。</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">ホーム</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">タグ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">アーカイブ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">プロフィール</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/inquiry">
    
      
      
      <span class="sidebar-button-desc">お問い合わせ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/privacy-policy">
    
      
      
      <span class="sidebar-button-desc">プライバシーポリシー</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>

      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle"
      style="display:block; text-align:center;"
      data-ad-layout="in-article"
      data-ad-format="fluid"
      data-ad-client="ca-pub-5663917297524414"
      data-ad-slot="8357823829"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

    <h3 style="color:white">最近の投稿</h3>
    <ul >
    
    <li ><a href="https://tma15.github.io/blog/2020/12/13/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E9%AB%98%E9%80%9F%E3%81%AA%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3%E5%AE%9F%E8%A3%85ctranslate2%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/" class="sidebar-button-link" style="color:white; list-style:none;">【自然言語処理】高速なニューラル機械翻訳実装CTranslate2【論文紹介】</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/12/12/%E6%9B%B8%E8%A9%95who-you-are%E3%83%95%E3%83%BC%E3%83%A6%E3%83%BC%E3%82%A2%E3%83%BC%E5%90%9B%E3%81%AE%E7%9C%9F%E3%81%AE%E8%A8%80%E8%91%89%E3%81%A8%E8%A1%8C%E5%8B%95%E3%81%93%E3%81%9D%E3%81%8C%E5%9B%B0%E9%9B%A3%E3%82%92%E7%94%9F%E3%81%8D%E6%8A%9C%E3%81%8F%E3%83%81%E3%83%BC%E3%83%A0%E3%82%92%E3%81%A4%E3%81%8F%E3%82%8B/" class="sidebar-button-link" style="color:white; list-style:none;">【書評】Who You Are（フーユーアー）君の真の言葉と行動こそが困難を生き抜くチームをつくる</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/11/22/pythonmecab%E3%81%AEtagger%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%82%92%E6%8C%81%E3%81%A4%E5%8D%98%E8%AA%9E%E5%88%86%E5%89%B2%E5%99%A8%E3%82%92pickle%E3%81%A7%E4%BF%9D%E5%AD%98%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/" class="sidebar-button-link" style="color:white; list-style:none;">【Python】MeCabのTaggerオブジェクトを持つ単語分割器をpickleで保存する方法</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/11/21/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86scikit-learn%E3%81%A7tfidf%E3%81%A8%E3%81%9D%E3%82%8C%E4%BB%A5%E5%A4%96%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%82%92%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%82%8B/" class="sidebar-button-link" style="color:white; list-style:none;">【自然言語処理】scikit-learnでtfidfとそれ以外の特徴量を組み合わせる</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/11/14/pythonargparse%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9-%E5%85%A5%E9%96%80%E7%B7%A8/" class="sidebar-button-link" style="color:white; list-style:none;">【Python】argparseの使い方 (入門編)</a></li>
    
    </ul>

      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle"
      style="display:block; text-align:center;"
      data-ad-layout="in-article"
      data-ad-format="fluid"
      data-ad-client="ca-pub-5663917297524414"
      data-ad-slot="8357823829"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

  </div>
</nav>

      
        

      
      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        
          <section class="postShorten-group main-content-wrap">
            
            
              
  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/10/03/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEbert%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8Bfine-tuning%E3%81%AF%E3%81%AA%E3%81%9C%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B%E3%81%AE%E3%81%8B-%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/">
          【自然言語処理】 あなたのBERTに対するfine-tuningはなぜ失敗するのか 【論文紹介】
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-10-03T09:51:17&#43;09:00">
        
  
  
  
  
    2020-10-03
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/paper">paper</a>
    
  

  </div>


    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      
        <p>本記事では<a href="https://arxiv.org/abs/2006.04884">On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines</a>という論文を紹介します。
この論文ではBERTのfine-tuningが安定しにくいという問題に対して、単純で良い結果が得られる方法を提案しています。
またBERTのfine-tuningが安定しにくいという問題を細かく分析しており、参考になったのでそのあたりについてもまとめます。
本記事を読むことでBERTを自分の問題でfine-tuningするときの施策を立てやすくなるかと思います。</p>
      
      <p>
        <a href="https://tma15.github.io/blog/2020/10/03/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEbert%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8Bfine-tuning%E3%81%AF%E3%81%AA%E3%81%9C%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B%E3%81%AE%E3%81%8B-%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/" class="postShorten-excerpt_link link">続きを読む</a>
        
      </p>
    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2020/10/03/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEbert%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8Bfine-tuning%E3%81%AF%E3%81%AA%E3%81%9C%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B%E3%81%AE%E3%81%8B-%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/10/03/bert.png"/>
      </div>
    </a>
  
</article>

            
              
  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2019/09/04/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%87%BA%E5%8A%9B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E6%A4%9C%E7%B4%A2%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%95%E3%81%9B%E3%82%8B%E6%96%B9%E6%B3%95/">
          ニューラルネットの出力ベクトルを二値化して検索を高速化させる方法
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-09-04T18:19:54&#43;09:00">
        
  
  
  
  
    2019-09-04
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/acl2019">acl2019</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/paper">paper</a>
    
  

  </div>


    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      
        <p>自然言語処理において、ニューラルネットワークは文や単語を実数値の密ベクトル表現に変換し、
得られた表現に基づいて目的のタスクを解くというアプローチが多い。
自然言語処理のさまざまなタスクで高い精度を上げている一方で、
テキスト検索などの高速な処理速度を要求されるような場面では密ベクトルを処理するのは
速度が遅いなどの実用的な課題がある。
自然言語処理に関する国際会議ACL 2019で発表された論文
&lsquo;&lsquo;Learning Compressed Sentence Representations for On-Device Text Processing&rsquo;&rsquo;
(<a href="https://www.aclweb.org/anthology/P19-1011">pdf</a>)
が、類似文検索タスクにおいて、検索精度をほぼ落とさずに、高速な検索がおこなえるように、文の表現を実数値ではなく、
<strong>二値</strong>ベクトルで表現する方法を提案した。
本記事ではこの論文でどういった技術が提案されているのかをまとめる。</p>
      
      <p>
        <a href="https://tma15.github.io/blog/2019/09/04/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%87%BA%E5%8A%9B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E6%A4%9C%E7%B4%A2%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%95%E3%81%9B%E3%82%8B%E6%96%B9%E6%B3%95/" class="postShorten-excerpt_link link">続きを読む</a>
        
      </p>
    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2019/09/04/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%87%BA%E5%8A%9B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E6%A4%9C%E7%B4%A2%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%95%E3%81%9B%E3%82%8B%E6%96%B9%E6%B3%95/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2019/learning-to-compress.PNG"/>
      </div>
    </a>
  
</article>

            
              
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2016/09/04/early-update%E3%81%AF%E5%8F%8E%E6%9D%9F%E3%81%8C%E4%BF%9D%E8%A8%BC%E3%81%95%E3%82%8C%E3%82%8B/">
          Early updateは収束が保証される
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2016-09-04T11:00:13&#43;09:00">
        
  
  
  
  
    2016-09-04
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/paper">paper</a>
    
  

  </div>


    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      
        <!--adsense-->
<p>(<a href="http://www.aclweb.org/anthology/N12-1015">Structured Perceptron with Inexact Search</a>, NAACL 2012) を読んだ。</p>
<p>構造化パーセプトロンは構造を持つ出力を予測するパーセプトロンであり、自然言語処理では品詞タグ付けなどに用いられる。出力を予測する際には効率的に出力を探索するために、ビームサーチが用いられることが多いが、一般的な構造化パーセプトロンに対してビームサーチを適用すると、パーセプトロンの収束性が保証されない。</p>
<p>構造化パーセプトロンを効率的に学習する手法として、early updateというヒューリスティクスな手法が提案されている。early updateは出力を予測する途中で正解でないとわかった段階で場合に重みを更新するヒューリスティクスな手法である。しかしながら、early updateはラベル列を最後まで見ずに重みを更新するのにも関わらず、violation fixingという枠組みで収束が保証される。</p>
      
      <p>
        <a href="https://tma15.github.io/blog/2016/09/04/early-update%E3%81%AF%E5%8F%8E%E6%9D%9F%E3%81%8C%E4%BF%9D%E8%A8%BC%E3%81%95%E3%82%8C%E3%82%8B/" class="postShorten-excerpt_link link">続きを読む</a>
        
      </p>
    </div>
  </div>
  
</article>

            
              
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2014/12/03/question-answering-using-enhanced-lexical-semantic-models-acl2013-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/">
          Question Answering Using Enhanced Lexical Semantic Models (ACL2013) を読んだ
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2014-12-03T00:00:00Z">
        
  
  
  
  
    2014-12-03
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/paper">paper</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/acl2013">acl2013</a>
    
  

  </div>


    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      
        <p>Question Answering Using Enhanced Lexical Semantic Models (<a href="http://www.aclweb.org/anthology/P13-1171">pdf</a>)</p>
<p>Wen-tau Yih, Ming-Wei Chang, Christopher Meek and Andrzej Pastusiak, Microsoft Research, ACL 2013</p>
      
      <p>
        <a href="https://tma15.github.io/blog/2014/12/03/question-answering-using-enhanced-lexical-semantic-models-acl2013-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/" class="postShorten-excerpt_link link">続きを読む</a>
        
      </p>
    </div>
  </div>
  
</article>

            
              
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2013/12/27/%E3%82%A8%E3%83%83%E3%82%BB%E3%82%A4-towards-the-machine-comprehension-of-text-%E3%81%AE%E3%83%A1%E3%83%A2/">
          エッセイ Towards the Machine Comprehension of Text のメモ
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2013-12-27T00:00:00Z">
        
  
  
  
  
    2013-12-27
  


      </time>

      

    
    
  </div>


    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      
        エッセイの一部をメモ。
主張をまとめると「自然言語の機械的な理解には、大規模なデータ、性能の良い機械学習も重要だけど、言語の構造をしっかり考えることも大事」。
Introduction  Machine Comprehension of Text (MCT) (テキストの機械的理解) は人工知能のゴールである このゴールを達成したかどうかを確かめるために、研究者はよくチューリングテストを思い浮かべるが、Levesque (2013)が指摘するように、これは機械を知的に向かわせる、というよりは人間の知能を下げるほうに作業者を差し向けてしまう  ※ チューリングテストとは、ある人間から見て、二人の対話のどちらが人間かどうか判別するテスト   Levesqueはまた、チューリングテストよりも、世界知識を必要とするような選択肢が複数ある問題のほうが適しているとも主張している このエッセイでは、MCTは、&ldquo;ネイティブスピーカーの大半が正しく答えられる質問に対して機械が答えた回答が、ネイティブスピーカーが納得できるものであり、かつ関連していない情報を含んでいなければ、その機械はテキストを理解しているもの&quot;とする (つまり質問応答) このエッセイのゴールは、テキストの機械的理解という問題に何が必要なのかを観察することである  How To Measure Progress  複数の選択肢がある質問応答のデータセットをクラウドソーシングを利用して作った  7歳の子供が読めるレベルのフィクションの短いストーリー   Winograd Schema Test proposal (Levesque, 2013) は、質問と回答のペアは世界知識を要求するように注意深く設計されているので、生成には専門知識を要する質問を使うことを提案している  &ldquo;それは紙で出来ているので、ボールはテーブルから落ちた&quot;の&quot;それ&quot;は何を指しているか？   クラウドソーシングなのでスケーラビリティもある 進捗が早ければ、問題の難易度を上げることもできる  語彙数を現状の8000から増やす ノンフィクションなストーリーを混ぜる タスクの定義を変える  正解が1つ以上、あるいは正解が1つもない問題など 回答の根拠を出力するようにする     興味深いことは、ランダムな回答をするベースラインでは25%が正しい回答を得られる一方で、単純な単語ベースな手法が60%で、最近のモダンな含意認識システムを使っても60%くらいであることである  Desiderata and some Recent Work machine comprehensionに必要なものは、興味深い未解決な問題と通じている
 意味の表現は二つの意味でスケーラブルであるべきである、すなわち (1) 複数ソースのノイジーなデータから教師なし学習で学習できて、 (2) 任意のドメインの問題に適用できるべきである モデルが巨大で複雑になっても、推論はリアリタイムでおこなえるべきである 構築、デバッグの簡易化のためにシステムはモジュール化すべきである  モジュラ性はシステムを効率的に反応できるようにするべきである   エラーが起きた時に、何故それが起きたか理解可能にするために、各モジュールは解釈可能であるべきであり、同様にモジュールの構成も解釈可能であるべきである システムは単調的に修正可能であるべきである: 起きたエラーに対して、別のエラーを引き起こさずに、どのようにモデルを修正すればよいかが明白であるべきである システムは意味表現に対して論理的推論をおこなえるべきである  システムの入力のテキストの意味表現とシステムの世界モデルを組み合わせることで論理的な結論をだせるべきである もろさを避けるため、また根拠を正しく結合するために、論理的思考は確率的であるべきなようである (Richardson and Domingos, 2006)   システムは質問可能であるべきである  任意の仮説に関して、真であるかどうか (の確率) を断言することができること 私達はなぜその断言ができるか理解することができるべきである    最近の研究では  論理形式を文に対してタグ付けするなど、意味のモデル化はアノテーションコストがとても高い  興味深い代替手段としては、質問-回答のペアから論理形式を帰納するアノテーションがより低いものがある (Liang et al.
      
      <p>
        <a href="https://tma15.github.io/blog/2013/12/27/%E3%82%A8%E3%83%83%E3%82%BB%E3%82%A4-towards-the-machine-comprehension-of-text-%E3%81%AE%E3%83%A1%E3%83%A2/" class="postShorten-excerpt_link link">続きを読む</a>
        
      </p>
    </div>
  </div>
  
</article>

            
              
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2013/12/14/penguins-in-sweaters-or-serendipitous-entity-search-on-user-generated-content-cikm2013%E3%83%A1%E3%83%A2/">
          Penguins in Sweaters, or Serendipitous Entity Search on User-generated Content (CIKM2013)メモ
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2013-12-14T00:00:00Z">
        
  
  
  
  
    2013-12-14
  


      </time>

      

    
    
  </div>


    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      
        proceeding slide: slideshare
まとめ CIKM 2013でBest paperを取った、著者が全員女性(参考)という、自分が今まで読んだ中でおそらく一番華やかな論文で、Yahoo Answersを知識源として、セレンディピティ (思ってもみなかったけど、クエリと関連していること) を感じる検索を提供する話。 何か新たな手法を提案した、というよりは、Yahoo Answersという知識源を使うことで、何か思ってもみなかったけど、面白い検索結果を提供できるんじゃないかな〜というアイディアを実際に試してみた、という感じだろうか。
以下、メモ。
Why/when do penguins wear sweaters?  タスマニアで起きた原油漏れで体に油がついてしまったペンギンが、再び元の生活に戻れるようにするためのチャリティーソング (James GordonのSweaters for Penguins)  羽毛に原油がつくことで断熱性が落ち、ペンギンが凍えてしまう くちばしで羽毛に付いた原油を落とそうとすることで体を傷つけてしまう    Serendipity 役に立つんだけど、特に探していたわけではないもの。
Entity Search この論文ではWikipediaとYahoo! Answersから抽出した、メタデータで情報を豊富にしたentityネットワークを基にentity-driven serendipitous search systemを作成する。
この論文の焦点 WHAT ウェブコミュニティの知識源はどのようなentity間の関係を提供するのか？
WHY そのような知識源がどのように面白く、セレンディピティなブラウジング経験に寄与するのか？
データ Yahoo! Answers  ごくわずかにまとめられた意見、ゴシップ、個人情報 観点が多様  Wikipedia  高品質の情報が整理されている ニッチなトピックが豊富  Entity &amp; Relation Extraction Entity: Wikipediaに記述されている概念 1 テキストから表層形を識別し、 2 Wikipediaのentityと紐付けして、
 文脈依存 文脈非依存な素性  click log    3 Wikipediaのentityを、テキストとの関連度順に基いてランキングする (aboutnessスコア(34)を使ってランキングする)
      
      <p>
        <a href="https://tma15.github.io/blog/2013/12/14/penguins-in-sweaters-or-serendipitous-entity-search-on-user-generated-content-cikm2013%E3%83%A1%E3%83%A2/" class="postShorten-excerpt_link link">続きを読む</a>
        
      </p>
    </div>
  </div>
  
</article>

            
              
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2013/09/30/%E6%96%87%E6%9B%B8%E8%A6%81%E7%B4%84%E3%83%A1%E3%83%A2acl2013/">
          文書要約メモ（ACL2013）
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2013-09-30T00:00:00Z">
        
  
  
  
  
    2013-09-30
  


      </time>

      

    
    
  </div>


    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      
        acl anthologyよりロングペーパーとして 採択された論文の中からSummarizationをタイトルに含む論文を探して概要だけを読んだときのメモ。
Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning (P13-1020.pdf) 概要  複数文書要約のための文選択、文圧縮を同時におこなうモデルを使った双対分解を提案。 先行研究のIneger Linear Programmingに基づいた手法と比べると  提案手法はソルバーを必要としない 提案手法は有意に速い 提案手法は簡潔さ・情報の豊富さ・文法のきれいさが優れている   さらに既存の抽出型要約、文圧縮の要約データを活用したマルチタスク学習を提案する TAC2008のデータで実験をおこなって今までで一番高いROUGE値となった。  Using Supervised Bigram-based ILP for Extractive Summarization (P13-1099.pdf) 概要  Integer Linear Programmingによる抽出型文書要約において、bigramの重みを教師有り学習により推定する regression modelによってbigramが参照要約の中でどれくらいの頻度で出現するかを推定。 学習では、参照要約中での真の頻度との距離が最小になるように学習をする 選択されるbigramの重みの総和が最大になるように文選択をおこなうような定式化をしている 提案手法は既存のILPな手法と比べてTACのデータにおいて良い性能であることと、TACのbestだったシステムとの比較結果を示す  Summarization Through Submodularity and Dispersion (P13-1100.pdf) 概要  Linらのサブモジュラな手法を一般化することにより新たな最適化手法を提案する 提案手法では要約にとって欲しい情報はサブモジュラ関数と非サブモジュラ関数の総和で表される。この関数をdispersionと呼ぶ 非サブモジュラ関数は要約の冗長性を除くために文同士の様々な似ていなさの度合いを図るために使う 三つのdispersion関数を使って、全部の場合で貪欲法を使っても最適解が得られることを示す DUC 2004とニュース記事に対するユーザのコメントを使って実験 サブモジュラ関数だけを使ったモデルよりも良い性能であることを示す  Subtree Extractive Summarization via Submodular Maximization (P13-1101.
      
      <p>
        <a href="https://tma15.github.io/blog/2013/09/30/%E6%96%87%E6%9B%B8%E8%A6%81%E7%B4%84%E3%83%A1%E3%83%A2acl2013/" class="postShorten-excerpt_link link">続きを読む</a>
        
      </p>
    </div>
  </div>
  
</article>

            
            
  <div class="pagination-bar">
    <ul class="pagination">
      
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="https://tma15.github.io/tags/paper/page/2/">
              <span>古い投稿</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
      
      <li class="pagination-number">page 1 of 2</li>
    </ul>
  </div>


          </section>
        
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2021 Takuya Makino. All Rights Reserved
  </span>
</footer>

      </div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
    
    <h4 id="about-card-name">Takuya Makino</h4>
    
      <div id="about-card-bio">自然言語処理の研究開発に従事しています。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、Python、C++に関する記事が多めです。詳細は<a href="https://tma15.github.io/about/">プロフィール</a>を御覧ください。</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        自然言語処理の研究開発に従事
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Kanagawa, Japan
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://tma15.github.io/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://tma15.github.io/js/script-pcw6v3xilnxydl1vddzazdverrnn9ctynvnxgwho987mfyqkuylcb1nlt.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>





    
  </body>
</html>

