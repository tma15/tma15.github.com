<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on Now is better than never.</title>
    <link>https://tma15.github.io/tags/python/</link>
    <description>Recent content in python on Now is better than never.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 31 Oct 2020 10:58:05 +0900</lastBuildDate>
    
	<atom:link href="https://tma15.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>【自然言語処理】文書分類に特化したPythonライブラリを作り始めました【プログラムほぼ不要で使えます】</title>
      <link>https://tma15.github.io/blog/2020/10/31/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%AB%E7%89%B9%E5%8C%96%E3%81%97%E3%81%9Fpython%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%92%E4%BD%9C%E3%82%8A%E5%A7%8B%E3%82%81%E3%81%BE%E3%81%97%E3%81%9F%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%BB%E3%81%BC%E4%B8%8D%E8%A6%81%E3%81%A7%E4%BD%BF%E3%81%88%E3%81%BE%E3%81%99/</link>
      <pubDate>Sat, 31 Oct 2020 10:58:05 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/10/31/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%AB%E7%89%B9%E5%8C%96%E3%81%97%E3%81%9Fpython%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%92%E4%BD%9C%E3%82%8A%E5%A7%8B%E3%82%81%E3%81%BE%E3%81%97%E3%81%9F%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%BB%E3%81%BC%E4%B8%8D%E8%A6%81%E3%81%A7%E4%BD%BF%E3%81%88%E3%81%BE%E3%81%99/</guid>
      <description>&lt;p&gt;本記事では文書分類に特化した自然言語処理ライブラリの開発について紹介します。
文書分類器一つを作るにも、前処理、開発、評価といった一連のプログラム開発に加えて、ニューラルネットワークに基づくモデルとそれ以外の機械学習アルゴリズムのどちらが良いのかといった比較を検討する必要もあったりと、かかる手間は少なくありません。
そこで、これらのプログラム開発をできるだけ簡易化するために開発した自然言語処理ライブラリを紹介します。
本記事を読むことで簡単に文書分類器を構築するためのライブラリの利用方法を理解できます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【Python】YouTube APIから動画情報を取得</title>
      <link>https://tma15.github.io/blog/2020/09/25/pythonyoutube-api%E3%81%8B%E3%82%89%E5%8B%95%E7%94%BB%E6%83%85%E5%A0%B1%E3%82%92%E5%8F%96%E5%BE%97/</link>
      <pubDate>Fri, 25 Sep 2020 21:50:47 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/09/25/pythonyoutube-api%E3%81%8B%E3%82%89%E5%8B%95%E7%94%BB%E6%83%85%E5%A0%B1%E3%82%92%E5%8F%96%E5%BE%97/</guid>
      <description>&lt;p&gt;本記事ではPythonで&lt;a href=&#34;https://developers.google.com/youtube/v3/docs/&#34;&gt;YouTube Data API v3&lt;/a&gt;を介して動画を検索する方法について紹介します。
ここ最近のYouTubeの盛り上がりによって多種多様で高品質な動画を無料で楽しむことができるようになってきました。
これらの動画情報をプログラミングで自動的に収集し、閲覧したり分析できるようになると便利ですよね。
そこで実際に動画情報を検索するPythonコードとともに利用例を説明します。
本記事を読むことで、YouTube動画の検索方法、検索対象のフィルタリングに加えて、検索では省略されてしまう概要欄全文の取得方法がわかります。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【自然言語処理】LSTMに基づく文書分類 (PyTorchコード付き)</title>
      <link>https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</link>
      <pubDate>Sun, 06 Sep 2020 09:46:04 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</guid>
      <description>&lt;p&gt;本記事では日本語を対象としたLSTMに基づく文書分類モデルをPyTorchコード付きで紹介します。
以前、LSTMを用いた言語モデルについて紹介しました (
&lt;a href=&#34;https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/&#34;&gt;[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)&lt;/a&gt;
)
が、ニューラルネットワークを用いた自然言語処理の応用例として文書分類のほうがイメージしやすそうなので、こちらについても紹介したいと思います。
実験にはライブドアコーパスから作成した、記事の見出しに対して9つのカテゴリのうち、どれか1つが付与されたデータを使います。
本記事を読むことで日本語を対象に、ニューラルネットワークを活用した自然言語処理の概要を知ることができます。
また、PyTorchで事前学習済みの単語分散表現を扱う方法も紹介しています。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【PyTorch】不要になった計算グラフを削除してメモリを節約</title>
      <link>https://tma15.github.io/blog/2020/08/22/pytorch%E4%B8%8D%E8%A6%81%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%9F%E8%A8%88%E7%AE%97%E3%82%B0%E3%83%A9%E3%83%95%E3%82%92%E5%89%8A%E9%99%A4%E3%81%97%E3%81%A6%E3%83%A1%E3%83%A2%E3%83%AA%E3%82%92%E7%AF%80%E7%B4%84/</link>
      <pubDate>Sat, 22 Aug 2020 13:27:43 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/08/22/pytorch%E4%B8%8D%E8%A6%81%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%9F%E8%A8%88%E7%AE%97%E3%82%B0%E3%83%A9%E3%83%95%E3%82%92%E5%89%8A%E9%99%A4%E3%81%97%E3%81%A6%E3%83%A1%E3%83%A2%E3%83%AA%E3%82%92%E7%AF%80%E7%B4%84/</guid>
      <description>&lt;p&gt;本記事ではPyTorchを使ったニューラルネットワークの学習において、不要な計算グラフを削除することでできるだけメモリを節約するための方法を紹介します。
本記事を読むことで、少しでもGPUメモリの不足によるout of memoryエラーを減らしたり、よりバッチサイズを大きくしたりして学習を実施できるようになります。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【Python】Twitter APIを利用してツイートを検索（画像、いいね、リツイートの取得も）</title>
      <link>https://tma15.github.io/blog/2020/08/02/pythontwitter-api%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6%E3%83%84%E3%82%A4%E3%83%BC%E3%83%88%E3%82%92%E6%A4%9C%E7%B4%A2%E7%94%BB%E5%83%8F%E3%81%84%E3%81%84%E3%81%AD%E3%83%AA%E3%83%84%E3%82%A4%E3%83%BC%E3%83%88%E3%81%AE%E5%8F%96%E5%BE%97%E3%82%82/</link>
      <pubDate>Sun, 02 Aug 2020 08:55:14 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/08/02/pythontwitter-api%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6%E3%83%84%E3%82%A4%E3%83%BC%E3%83%88%E3%82%92%E6%A4%9C%E7%B4%A2%E7%94%BB%E5%83%8F%E3%81%84%E3%81%84%E3%81%AD%E3%83%AA%E3%83%84%E3%82%A4%E3%83%BC%E3%83%88%E3%81%AE%E5%8F%96%E5%BE%97%E3%82%82/</guid>
      <description>&lt;p&gt;Twitterの検索APIを利用することで、Twitterに投稿されるツイートを検索し、ツイート本文、いいね数などに加えて、ツイートに添付される画像やURLなどを取得できます。
Twitterの検索APIを利用するにはAPIや得られるデータの仕様を把握しておく必要があります。
本記事では、検索APIの主な仕様およびツイートに添付されている画像データやURLなどへのアクセス方法を紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【無料でデータ収集】Herokuで収集したツイートをスプレッドシートに蓄積する</title>
      <link>https://tma15.github.io/blog/2020/07/25/%E7%84%A1%E6%96%99%E3%81%A7%E3%83%87%E3%83%BC%E3%82%BF%E5%8F%8E%E9%9B%86heroku%E3%81%A7%E5%8F%8E%E9%9B%86%E3%81%97%E3%81%9F%E3%83%84%E3%82%A4%E3%83%BC%E3%83%88%E3%82%92%E3%82%B9%E3%83%97%E3%83%AC%E3%83%83%E3%83%89%E3%82%B7%E3%83%BC%E3%83%88%E3%81%AB%E8%93%84%E7%A9%8D%E3%81%99%E3%82%8B/</link>
      <pubDate>Sat, 25 Jul 2020 10:18:02 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/07/25/%E7%84%A1%E6%96%99%E3%81%A7%E3%83%87%E3%83%BC%E3%82%BF%E5%8F%8E%E9%9B%86heroku%E3%81%A7%E5%8F%8E%E9%9B%86%E3%81%97%E3%81%9F%E3%83%84%E3%82%A4%E3%83%BC%E3%83%88%E3%82%92%E3%82%B9%E3%83%97%E3%83%AC%E3%83%83%E3%83%89%E3%82%B7%E3%83%BC%E3%83%88%E3%81%AB%E8%93%84%E7%A9%8D%E3%81%99%E3%82%8B/</guid>
      <description>&lt;p&gt;Twitterに日々投稿されるツイートを分析することで、今話題の情報など有用な知見を得ることができます。
日々投稿されるツイートを分析するには、定期的にツイートを収集し、蓄積する基盤が必要です。
特に個人開発においてはツイートを収集・蓄積する基盤にかかる初期費用・運用費用を可能な限り抑えたいです。
本記事では、無料で定期的にツイートを収集、蓄積するための手順をまとめました。
具体的には&lt;a href=&#34;https://jp.heroku.com/&#34;&gt;Heroku&lt;/a&gt;と&lt;a href=&#34;https://www.google.com/intl/ja_jp/sheets/about/&#34;&gt;スプレッドシート&lt;/a&gt;を使ってTwitterから定期的に収集したツイートを蓄積するための手順を紹介します。&lt;/p&gt;
&lt;!--adsense--&gt;</description>
    </item>
    
    <item>
      <title>【自然言語処理】公開されているデータセットを簡単に使うライブラリ (nlp) の紹介</title>
      <link>https://tma15.github.io/blog/2020/05/17/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E5%85%AC%E9%96%8B%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%82%92%E7%B0%A1%E5%8D%98%E3%81%AB%E4%BD%BF%E3%81%86%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA-nlp-%E3%81%AE%E7%B4%B9%E4%BB%8B/</link>
      <pubDate>Sun, 17 May 2020 20:40:22 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/05/17/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E5%85%AC%E9%96%8B%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%82%92%E7%B0%A1%E5%8D%98%E3%81%AB%E4%BD%BF%E3%81%86%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA-nlp-%E3%81%AE%E7%B4%B9%E4%BB%8B/</guid>
      <description>&lt;p&gt;huggingfaceから自然言語処理でベンチマークによく用いられるデータセット (数は本記事公開時点で98) を容易に利用するためのライブラリ &lt;a href=&#34;https://github.com/huggingface/nlp&#34;&gt;nlp&lt;/a&gt; が公開されました。
本記事ではこのライブラリの特徴と利用方法をご紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【PyTorch】DataLoaderのミニバッチ化の仕組み</title>
      <link>https://tma15.github.io/blog/2020/05/02/pytorchdataloader%E3%81%AE%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%8C%96%E3%81%AE%E4%BB%95%E7%B5%84%E3%81%BF/</link>
      <pubDate>Sat, 02 May 2020 16:26:18 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/05/02/pytorchdataloader%E3%81%AE%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%8C%96%E3%81%AE%E4%BB%95%E7%B5%84%E3%81%BF/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;PyTorchではDataLoaderを使うことで読み込んだデータから自動でミニバッチを作成することができます。
DataLoaderを使いこなすことで、ニューラルネットワークの学習部分を簡単に書くことができます。
本記事ではPyTorchのDataLoaderがミニバッチを作成する仕組みについて解説します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【PyTorch】Version1.5でTPUを利用する方法</title>
      <link>https://tma15.github.io/blog/2020/04/26/pytorchversion1.5%E3%81%A7tpu%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Sun, 26 Apr 2020 10:18:59 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/04/26/pytorchversion1.5%E3%81%A7tpu%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>&lt;p&gt;PyTorchのVersion1.5.0が&lt;a href=&#34;https://github.com/pytorch/pytorch/releases&#34;&gt;リリースされました&lt;/a&gt;。
いくつかの変更がされていますが、その中の一つが、PyTorchでXLAの利用が可能となったというものです。
XLAを利用できると、PyTorch実装をTPU上で実行できるようになります。
本記事ではPyTorch1.5.0を使ってGoogle ColabのTPUを利用できるようになるところまでの流れを説明します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【Python】自作ライブラリのパッケージング方法</title>
      <link>https://tma15.github.io/blog/2020/04/19/python%E8%87%AA%E4%BD%9C%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%83%B3%E3%82%B0%E6%96%B9%E6%B3%95/</link>
      <pubDate>Sun, 19 Apr 2020 16:07:11 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/04/19/python%E8%87%AA%E4%BD%9C%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%83%B3%E3%82%B0%E6%96%B9%E6%B3%95/</guid>
      <description>&lt;p&gt;自分で開発したPythonプログラムを再利用しやすいように、ライブラリとして整備したいことがあると思います。本記事ではPythonプログラムをライブラリ化するための手順を解説します。Pythonプログラムののモジュール化に加えて、コマンドラインを作成する方法についても触れます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【Python】zip, zip_longestの違い、同じ長さの入力を前提としたzip_longestの使用</title>
      <link>https://tma15.github.io/blog/2020/04/07/pythonzip-zip_longest%E3%81%AE%E9%81%95%E3%81%84%E5%90%8C%E3%81%98%E9%95%B7%E3%81%95%E3%81%AE%E5%85%A5%E5%8A%9B%E3%82%92%E5%89%8D%E6%8F%90%E3%81%A8%E3%81%97%E3%81%9Fzip_longest%E3%81%AE%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Tue, 07 Apr 2020 17:23:57 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/04/07/pythonzip-zip_longest%E3%81%AE%E9%81%95%E3%81%84%E5%90%8C%E3%81%98%E9%95%B7%E3%81%95%E3%81%AE%E5%85%A5%E5%8A%9B%E3%82%92%E5%89%8D%E6%8F%90%E3%81%A8%E3%81%97%E3%81%9Fzip_longest%E3%81%AE%E4%BD%BF%E7%94%A8/</guid>
      <description>&lt;p&gt;本記事ではPythonにおいて複数の入力を列挙する関数である&lt;code&gt;zip&lt;/code&gt;、&lt;code&gt;zip_longest&lt;/code&gt;およびそれらの違いを紹介します。
また、これらの関数は入力の長さが異なっていても動作するため、
同じ長さを保証するように入力の要素を列挙する方法も紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【PyTorch】限られたメモリにおける大きなバッチサイズでの学習</title>
      <link>https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/</link>
      <pubDate>Sun, 05 Apr 2020 16:26:26 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/</guid>
      <description>&lt;p&gt;ニューラルネットワークの学習ではミニバッチ学習という複数の学習事例に対して得られる損失の総和を最小化するようにパラメータを更新します。
バッチサイズは計算機のメモリ容量に応じて人が決める値ですが、
BERTはバッチサイズを大きくしたほうが学習が安定しやすいという&lt;a href=&#34;https://arxiv.org/abs/1907.11692&#34;&gt;報告&lt;/a&gt;があります。
しかし、デバイスのメモリに載りきらないサイズでは学習中にメモリーエラーを起こしてしまいます。
本記事ではPyTorchコードを使って、メモリ容量が限られた環境でも大きなバッチサイズでミニバッチ学習する方法を紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【機械学習】scikit-learnで学ぶstacking</title>
      <link>https://tma15.github.io/blog/2020/03/29/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6stacking/</link>
      <pubDate>Sun, 29 Mar 2020 16:08:15 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/29/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6stacking/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;stackingはアンサンブル学習と呼ばれる機械学習の一種で、他の機械学習に基づく複数の予測モデルの出力を入力の一部として扱い、予測モデルを構築します。
単純なアルゴリズムであるのにもかかわらず、何かしらの分類器単体よりも高い予測精度を得やすく、予測精度を競うようなコンペにおいて良く用いられています。
本記事ではscikit-learnのバージョン0.22で導入された&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html&#34;&gt;StackingClassifier&lt;/a&gt;の使い方について紹介するとともに、学習時の挙動を紹介します。
本記事を読むことでscikit-learnでのstackingの学習の流れを理解できます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Flask] Blueprintを使ったアプリ開発のテンプレート</title>
      <link>https://tma15.github.io/blog/2020/03/22/flask-blueprint%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%82%A2%E3%83%97%E3%83%AA%E9%96%8B%E7%99%BA%E3%81%AE%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88/</link>
      <pubDate>Sun, 22 Mar 2020 15:39:12 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/22/flask-blueprint%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%82%A2%E3%83%97%E3%83%AA%E9%96%8B%E7%99%BA%E3%81%AE%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;本記事ではPythonのWebアプリケーションフレームワークの一つである&lt;a href=&#34;https://palletsprojects.com/p/flask/&#34;&gt;Flask&lt;/a&gt;のblueprintの使い方について紹介します。
blueprintを使うことによって、アプリケーションをblueprint単位で分割できます。
特に規模が大きなアプリケーションほど、blueprintの利用によってアプリケーションを分割することでプログラムを管理しやすくなり、得られるメリットが大きいです。
本記事は&lt;a href=&#34;https://github.com/Robpol86/Flask-Large-Application-Example&#34;&gt;Flask-Large-Aplication-Example&lt;/a&gt;を参考にして、特にblueprintに関する箇所を抽出し、簡素化して自分の理解をまとめたものです。
Flaskのblueprintを使って初めてアプリケーションを実装する人の参考になるような入門記事です。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)</title>
      <link>https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</link>
      <pubDate>Sun, 15 Mar 2020 15:24:03 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。&lt;/p&gt;
&lt;p&gt;本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Python] scikit-learnで学ぶパーセプトロンによる文書分類入門</title>
      <link>https://tma15.github.io/blog/2020/03/03/python-scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%85%A5%E9%96%80/</link>
      <pubDate>Tue, 03 Mar 2020 09:54:42 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/03/python-scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%85%A5%E9%96%80/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;この記事ではパーセプトロンを使って文書分類器を学習し、学習済みの分類器を使って文書を分類する流れをご紹介します。パーセプトロンはシンプルな分類アルゴリズムの一つである一方で、これを理解していると他の分類アルゴリズムを理解する助けになるため、初めて機械学習を学ぶ初学者の方にとってよい題材といえます。
この記事に載せているプログラムは&lt;a href=&#34;https://github.com/tma15/scikit-learn-document-classification&#34;&gt;ここ&lt;/a&gt;にまとまっています。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Python] Joblibのキャッシュを使って同じ計算を省略する</title>
      <link>https://tma15.github.io/blog/2019/10/06/python-joblib%E3%81%AE%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E5%90%8C%E3%81%98%E8%A8%88%E7%AE%97%E3%82%92%E7%9C%81%E7%95%A5%E3%81%99%E3%82%8B/</link>
      <pubDate>Sun, 06 Oct 2019 07:08:25 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2019/10/06/python-joblib%E3%81%AE%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E5%90%8C%E3%81%98%E8%A8%88%E7%AE%97%E3%82%92%E7%9C%81%E7%95%A5%E3%81%99%E3%82%8B/</guid>
      <description>&lt;p&gt;本エントリではPythonの&lt;a href=&#34;https://joblib.readthedocs.io/en/latest/&#34;&gt;Joblib&lt;/a&gt;がもつキャッシュ機能によって同じ計算を省略し、処理を高速化するための方法を説明する。このエントリを読むことで、関数をキャッシュ可能にする方法、numpyのarrayをメモリーマップを使って読み込む方法、参照を使ってデータにアクセスする方法がわかる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PythonでElasticsearchを使うときのメモ</title>
      <link>https://tma15.github.io/blog/2014/11/08/python%E3%81%A7elasticsearch%E3%82%92%E4%BD%BF%E3%81%86%E3%81%A8%E3%81%8D%E3%81%AE%E3%83%A1%E3%83%A2/</link>
      <pubDate>Sat, 08 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://tma15.github.io/blog/2014/11/08/python%E3%81%A7elasticsearch%E3%82%92%E4%BD%BF%E3%81%86%E3%81%A8%E3%81%8D%E3%81%AE%E3%83%A1%E3%83%A2/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;本記事ではPythonとElasticsearchを使って、日本のレストランに関するデータを使って記事を検索エンジンにbulk APIを使って登録し、検索するまでを紹介する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mafが便利そう</title>
      <link>https://tma15.github.io/blog/2014/11/03/maf%E3%81%8C%E4%BE%BF%E5%88%A9%E3%81%9D%E3%81%86/</link>
      <pubDate>Mon, 03 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://tma15.github.io/blog/2014/11/03/maf%E3%81%8C%E4%BE%BF%E5%88%A9%E3%81%9D%E3%81%86/</guid>
      <description>概要 mafというツールが便利そうだったのでメモ。 評価のために必要なめんどくさい処理が簡略化されそうな気がする。 実験結果の管理などがヘタなので、mafを使ってちょっとでもうまくなりたい。 まだ調べ始めたばかりなので、以降で出てくるコードよりももっとうまい書き方があると思う。
今回は色々とパラメータを変えて学習した分類器を評価する例で進める。
使ってみた まず、wafとmafとダウンロードする。
$cd /path/to/project/ $wget https://github.com/pfi/maf/raw/master/waf $wget https://github.com/pfi/maf/raw/master/maf.py $chmod +x waf 以下の様な wscript を作成。
#!/usr/bin/python import re import json import numpy as np import maf import maflib.util def configure(conf): pass @maflib.util.rule def jsonize(task): &amp;#34;&amp;#34;&amp;#34; Calculate accuracy from a format as below: Recall[-1]: 0.932965 (21934/23510) Prec[-1]: 0.849562 (21934/25818) -- Recall[+1]: 0.478378 (3562/7446) Prec[+1]: 0.693266 (3562/5138) &amp;#34;&amp;#34;&amp;#34; out = task.parameter with open(task.inputs[0].abspath(), &amp;#39;r&amp;#39;) as f: num = 0 num_trues = 0 for line in f: if line.</description>
    </item>
    
    <item>
      <title>Induced SortingをPythonで書いた</title>
      <link>https://tma15.github.io/blog/2014/05/07/induced-sorting%E3%82%92python%E3%81%A7%E6%9B%B8%E3%81%84%E3%81%9F/</link>
      <pubDate>Wed, 07 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://tma15.github.io/blog/2014/05/07/induced-sorting%E3%82%92python%E3%81%A7%E6%9B%B8%E3%81%84%E3%81%9F/</guid>
      <description>「高速文字列解析の世界」を一旦通読したので、実際に手を動かしてみた。 Induced Sortingは効率的に接尾辞配列を構築するアルゴリズム。 詳細はこの本を始め、下の参考にあるエントリなどが個人的に参考になった。
  GitHubにコードを上げた (sais.py)。
参考  Suffix Array を作る - SA-IS の実装 https://github.com/beam2d/sara SA-IS: SuffixArray線形構築  実装時にはやはり元の論文を読まないとよくわからなかった。
 Two Efficient Algorithms for Linear Time Suffix Array Construction  </description>
    </item>
    
    <item>
      <title>scikit-learnのソースコードリーディング（ナイーブベイズ分類）</title>
      <link>https://tma15.github.io/blog/2013/11/10/scikit-learn%E3%81%AE%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%8A%E3%82%A4%E3%83%BC%E3%83%96%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E/</link>
      <pubDate>Sun, 10 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://tma15.github.io/blog/2013/11/10/scikit-learn%E3%81%AE%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%8A%E3%82%A4%E3%83%BC%E3%83%96%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E/</guid>
      <description>個人的にはプログラミングの勉強は写経が一番頭に入る気がする、ということで読んでいた。
気になったところ データに正規分布を仮定したときのナイーブベイズ分類器について。 平均を\(\mu\)、分散を\(\sigma^2\)としたときの正規分布は
\[ p(x;\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\} \]
これのlogをとると、
$$ \begin{eqnarray} \log p(x;\mu, \sigma^2) &amp;amp;=&amp;amp; \log \{\frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}\} \\\
&amp;amp;=&amp;amp; -\frac{1}{2}\log (2\pi \sigma^2) - \frac{(x-\mu)^2}{2\sigma^2} \end{eqnarray} $$
ナイーブベイズ分類器の対数尤度関数は、データがK次元ベクトルで表現されていて、それがN個あるとすると、 $$ \begin{eqnarray} \log L(X, Y; \mu, \sigma) &amp;amp;=&amp;amp; \log(\prod_{n=1}^N p(\mathbf{x}_n, y_n))\\\
&amp;amp;=&amp;amp; \log(\prod_{n=1}^N p(y_n)p(\mathbf{x}_n|y_n))\\\
&amp;amp;=&amp;amp; \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \log p(\mathbf{x}_n|y_n)\\\
&amp;amp;=&amp;amp; \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K\log p(x_{nk}|y_n)\\\
&amp;amp;=&amp;amp; \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma_{y_nk}^2) - \frac{(x_{nk}-\mu_{y_nk})^2}{2\sigma_{y_nk}^2}\} \end{eqnarray} $$</description>
    </item>
    
    <item>
      <title>食べログAPIのPythonラッパーを書いた</title>
      <link>https://tma15.github.io/blog/2013/05/12/%E9%A3%9F%E3%81%B9%E3%83%AD%E3%82%B0api%E3%81%AEpython%E3%83%A9%E3%83%83%E3%83%91%E3%83%BC%E3%82%92%E6%9B%B8%E3%81%84%E3%81%9F/</link>
      <pubDate>Sun, 12 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://tma15.github.io/blog/2013/05/12/%E9%A3%9F%E3%81%B9%E3%83%AD%E3%82%B0api%E3%81%AEpython%E3%83%A9%E3%83%83%E3%83%91%E3%83%BC%E3%82%92%E6%9B%B8%E3%81%84%E3%81%9F/</guid>
      <description>ソースコードはこちら。
食べログAPI利用登録 まず食べログAPI サービス案内から利用登録をして access key (40桁の文字列)を入手する。
インストール git clone https://github.com/tma15/python-tabelog.git cd python-tabelog python setup.py install 使い方 最初に from tabelog import Tabelog key = &amp;#39;Your access key here.&amp;#39; tabelog = Tabelog(key) レストラン検索 prefecture = &amp;#39;東京&amp;#39; station = &amp;#39;渋谷&amp;#39; restaurants = tabelog.search_restaurant(prefecture=prefecture, station=station) for restaurant in restaurants: print &amp;#39;rcd:&amp;#39;, restaurant.rcd print &amp;#39;name:&amp;#39;, restaurant.name print &amp;#39;url:&amp;#39;, restaurant.tabelogurl print &amp;#39;mobile url:&amp;#39;, restaurant.tabelogmobileurl print &amp;#39;dinner price:&amp;#39;, restaurant.dinnerprice print &amp;#39;lunch price:&amp;#39;, restaurant.lunchprice print &amp;#39;total score:&amp;#39;, restaurant.</description>
    </item>
    
  </channel>
</rss>