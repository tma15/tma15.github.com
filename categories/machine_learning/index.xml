<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine_learning on Now is better than never.</title>
    <link>https://tma15.github.io/categories/machine_learning/</link>
    <description>Recent content in machine_learning on Now is better than never.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Mar 2020 09:54:42 +0900</lastBuildDate>
    
	<atom:link href="https://tma15.github.io/categories/machine_learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] scikit-learnで学ぶパーセプトロンによる文書分類入門</title>
      <link>https://tma15.github.io/blog/2020/03/03/python-scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%85%A5%E9%96%80/</link>
      <pubDate>Tue, 03 Mar 2020 09:54:42 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/03/python-scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%85%A5%E9%96%80/</guid>
      <description>&lt;!--adsense--&gt;

&lt;p&gt;この記事ではパーセプトロンを使って文書分類器を学習し、学習済みの分類器を使って文書を分類する流れをご紹介します。パーセプトロンはシンプルな分類アルゴリズムの一つである一方で、これを理解していると他の分類アルゴリズムを理解する助けになるため、初めて機械学習を学ぶ初学者の方にとってよい題材といえます。
この記事に載せているプログラムは&lt;a href=&#34;https://github.com/tma15/scikit-learn-document-classification&#34;&gt;ここ&lt;/a&gt;にまとまっています。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kaggle初参加記録</title>
      <link>https://tma15.github.io/blog/2017/07/29/kaggle%E5%88%9D%E5%8F%82%E5%8A%A0%E8%A8%98%E9%8C%B2/</link>
      <pubDate>Sat, 29 Jul 2017 15:30:01 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2017/07/29/kaggle%E5%88%9D%E5%8F%82%E5%8A%A0%E8%A8%98%E9%8C%B2/</guid>
      <description>&lt;p&gt;この一週間休暇を取っていて、多少の暇な時間があったので前から気になっていた&lt;a href=&#34;https://www.kaggle.com/&#34;&gt;Kaggle&lt;/a&gt;に手を付けてみた。
今回はチュートリアル的に公開されているtitanic号の生存予測タスクに参加した。
他の参加者がブログで公開されている&lt;a href=&#34;http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html&#34;&gt;素性&lt;/a&gt;を参考に素性を設計した。
予測モデルには以前C++で実装した平均化パーセプトロンを用いた。
Scoreが0.79426 (2017/7/29 16:00時点で1428位/7247位) となった。
Kaggleを続けると、機械学習に関するエンジニア能力が高まりそうで良い。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AdaBoostからLarge Margin Distribution Machineの流れ</title>
      <link>https://tma15.github.io/blog/2016/08/28/adaboost%E3%81%8B%E3%82%89large-margin-distribution-machine%E3%81%AE%E6%B5%81%E3%82%8C/</link>
      <pubDate>Sun, 28 Aug 2016 18:59:58 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2016/08/28/adaboost%E3%81%8B%E3%82%89large-margin-distribution-machine%E3%81%AE%E6%B5%81%E3%82%8C/</guid>
      <description>&lt;!--adsense--&gt;

&lt;p&gt;AdaBoostはKaggleなどのコンペで良い成績を出しているアンサンブル学習手法の一つである。このエントリはまずAdaBoostの概要および、なぜAdaBoostが高い汎化能力を示しやすいのかをまとめる。汎化能力が出やすい理由を調査することで、Large Margin Distribution Machineへと発展していった、という経緯を俯瞰することを目的とする。&lt;/p&gt;

&lt;p&gt;具体的には&lt;a href=&#34;http://cs.nju.edu.cn/zhouzh/&#34;&gt;Zhi-Hua Zhou&lt;/a&gt;先生のスライド (&lt;a href=&#34;http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/Adaboost2LDM.pdf&#34;&gt;From AdaBoost to LDM&lt;/a&gt;) を眺めて、自分の理解のためにメモとして残したものになっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>平均化パーセプトロンの効率的な計算</title>
      <link>https://tma15.github.io/blog/2016/07/31/%E5%B9%B3%E5%9D%87%E5%8C%96%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AE%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AA%E8%A8%88%E7%AE%97/</link>
      <pubDate>Sun, 31 Jul 2016 10:13:38 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2016/07/31/%E5%B9%B3%E5%9D%87%E5%8C%96%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AE%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AA%E8%A8%88%E7%AE%97/</guid>
      <description>&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;パーセプトロンは学習事例を受け取り重みベクトルを更新する、という処理を反復した後に重みベクトルを出力する&lt;/li&gt;
&lt;li&gt;平均化パーセプトロンは過去の反復で学習した重みベクトルの平均を出力する&lt;/li&gt;
&lt;li&gt;平均化パーセプトロンは実装が簡単でありながら、良い予測精度が出ることが多い&lt;/li&gt;
&lt;li&gt;素直に平均化パーセプトロンの出力を計算しようとすると各反復における重みベクトルを保持する必要がありメモリ的に学習が非効率であるため、実際には今回メモする方法で実装されることが多い&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>