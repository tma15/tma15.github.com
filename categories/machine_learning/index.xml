<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine_learning on Now is better than never.</title>
    <link>https://tma15.github.io/categories/machine_learning/</link>
    <description>Recent content in machine_learning on Now is better than never.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 13 Dec 2020 17:11:32 +0900</lastBuildDate>
    
	<atom:link href="https://tma15.github.io/categories/machine_learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>【自然言語処理】高速なニューラル機械翻訳実装CTranslate2【論文紹介】</title>
      <link>https://tma15.github.io/blog/2020/12/13/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E9%AB%98%E9%80%9F%E3%81%AA%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3%E5%AE%9F%E8%A3%85ctranslate2%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/</link>
      <pubDate>Sun, 13 Dec 2020 17:11:32 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/12/13/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E9%AB%98%E9%80%9F%E3%81%AA%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3%E5%AE%9F%E8%A3%85ctranslate2%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/</guid>
      <description>&lt;p&gt;本記事では&lt;a href=&#34;https://sites.google.com/view/wngt20/home&#34;&gt;WNGT 2020&lt;/a&gt;のefficiencyシェアドタスクに提出された&lt;a href=&#34;https://www.aclweb.org/anthology/2020.ngt-1.25.pdf&#34;&gt;Efficient and High-Quality Neural Machine Translation with OpenNMT&lt;/a&gt;を紹介します。
このタスクでは精度だけではなく、省メモリ、高速であることに焦点を当てています。
自然言語処理タスクの多くはニューラルネットワークに基づく巨大なモデルによって最高精度が塗り替えられていますが、実用上は精度以外にもメモリや速度の観点を検討しなければならない場面が多く、現実に即したタスクとなっています。
紹介する論文では機械翻訳で実験を行っていますが、その他のタスクに対しても適用できそうなテクニックが多く、勉強になりそうだったので紹介することにしました。
このタスクに参加した他のシステムも精度や速度などの指標においてパレート曲線状にあり、それぞれのシステムが重きをおいた指標が異なっています。
本記事で紹介する論文は速度、省メモリに焦点を当てています。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【機械学習】学習データ作成作業を効率化する能動学習OSSまとめ</title>
      <link>https://tma15.github.io/blog/2020/09/13/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%AD%A6%E7%BF%92%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90%E4%BD%9C%E6%A5%AD%E3%82%92%E5%8A%B9%E7%8E%87%E5%8C%96%E3%81%99%E3%82%8B%E8%83%BD%E5%8B%95%E5%AD%A6%E7%BF%92oss%E3%81%BE%E3%81%A8%E3%82%81/</link>
      <pubDate>Sun, 13 Sep 2020 08:57:58 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/09/13/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%AD%A6%E7%BF%92%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90%E4%BD%9C%E6%A5%AD%E3%82%92%E5%8A%B9%E7%8E%87%E5%8C%96%E3%81%99%E3%82%8B%E8%83%BD%E5%8B%95%E5%AD%A6%E7%BF%92oss%E3%81%BE%E3%81%A8%E3%82%81/</guid>
      <description>&lt;p&gt;本記事では機械学習モデルを効率的に構築するためのアプローチのひとつである、能動学習を利用可能なOSSについて調査し、その概要をまとめます。
機械学習を活用するときは、モデルを構築するために必要な学習データをどのように作成するかという点を検討しなければなりません。
コンペなどで利用されるベンチマークデータでは規模の大きな学習データが用意されていますが、自分のプロジェクトで機械学習を利用するために必要な学習データがすでに揃っているというケースはあまり多くありません。
効率的に学習データを作成するための手法として、能動学習というものがあります。
能動学習は、予め学習済みの機械学習モデルが予測結果に自信のない事例に対して、人の作業者にラベル付を依頼し、新しく作成された学習データでモデルを再学習するような処理の流れになります。
やみくもに事例にラベルをつけるのではなく、現在のモデルが失敗しやすい事例に対してラベルを付与するため、効率的な学習データの構築が期待できます。
本記事を読むことで、状況に合わせたOSSの選定に役立てられます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【自然言語処理】LSTMに基づく文書分類 (PyTorchコード付き)</title>
      <link>https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</link>
      <pubDate>Sun, 06 Sep 2020 09:46:04 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</guid>
      <description>&lt;p&gt;本記事では日本語を対象としたLSTMに基づく文書分類モデルをPyTorchコード付きで紹介します。
以前、LSTMを用いた言語モデルについて紹介しました (
&lt;a href=&#34;https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/&#34;&gt;[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)&lt;/a&gt;
)
が、ニューラルネットワークを用いた自然言語処理の応用例として文書分類のほうがイメージしやすそうなので、こちらについても紹介したいと思います。
実験にはライブドアコーパスから作成した、記事の見出しに対して9つのカテゴリのうち、どれか1つが付与されたデータを使います。
本記事を読むことで日本語を対象に、ニューラルネットワークを活用した自然言語処理の概要を知ることができます。
また、PyTorchで事前学習済みの単語分散表現を扱う方法も紹介しています。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【NVIDIA直伝】あなたのPyTorchプログラムを高速化するかもしれないTips</title>
      <link>https://tma15.github.io/blog/2020/08/29/nvidia%E7%9B%B4%E4%BC%9D%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEpytorch%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%99%E3%82%8B%E3%81%8B%E3%82%82%E3%81%97%E3%82%8C%E3%81%AA%E3%81%84tips/</link>
      <pubDate>Sat, 29 Aug 2020 13:16:11 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/08/29/nvidia%E7%9B%B4%E4%BC%9D%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEpytorch%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%99%E3%82%8B%E3%81%8B%E3%82%82%E3%81%97%E3%82%8C%E3%81%AA%E3%81%84tips/</guid>
      <description>&lt;p&gt;本記事では画像認識系の国際会議 &lt;a href=&#34;https://eccv2020.eu/&#34;&gt;ECCV2020&lt;/a&gt;のチュートリアルでNVIDIAが発表した資料 &lt;a href=&#34;https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf&#34;&gt;PYTORCH PERFORMANCE TUNING GUIDE&lt;/a&gt; の内容をまとめるとともに、理解の助けになるような関連情報を参照します。
PyTorchは簡単にニューラルネットワークの実装のを容易さだけでなく、処理速度にも注意を払って開発が進められています。
プログラムにほんの少し修正を加えるだけで高速化できる可能性があります。
本記事を読み、実践することで、手元のPyTorchプログラム (特にGPUを使った学習処理) を高速化できる可能性があります。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【自然言語処理】Scheduled samplingによるニューラル言語モデルの学習</title>
      <link>https://tma15.github.io/blog/2020/07/19/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86scheduled-sampling%E3%81%AB%E3%82%88%E3%82%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92/</link>
      <pubDate>Sun, 19 Jul 2020 13:34:44 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/07/19/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86scheduled-sampling%E3%81%AB%E3%82%88%E3%82%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;ニューラル言語モデルはこれまでのn-gram言語モデルと比較して流暢なテキストを生成することができます。
ニューラル言語モデルの学習にはTeacher-forcingという方法がよく用いられます。
この手法はニューラル言語モデルの学習がしやすい一方で、テキスト生成時の挙動と乖離があります。
本記事では、Teacher-forcingを説明するとともに、この手法の課題を改善するための手法であるScheduled samplingを紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【自然言語処理】Kaggleコンペで利用されている文書分類のtips</title>
      <link>https://tma15.github.io/blog/2020/05/03/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86kaggle%E3%82%B3%E3%83%B3%E3%83%9A%E3%81%A7%E5%88%A9%E7%94%A8%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%AEtips/</link>
      <pubDate>Sun, 03 May 2020 16:47:46 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/05/03/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86kaggle%E3%82%B3%E3%83%B3%E3%83%9A%E3%81%A7%E5%88%A9%E7%94%A8%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%AEtips/</guid>
      <description>&lt;p&gt;Kaggleの文書分類タスクにおける参加者のtipsが&lt;a href=&#34;https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions&#34;&gt;Text Classification: All Tips and Tricks from 5 Kaggle Competitions&lt;/a&gt;にまとまっていました。英語が前提になっているものの、参考になったので目を通し、概要をまとめました。
また日本語を対象とした場合に参考になりそうな記事も挙げておきます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【PyTorch】限られたメモリにおける大きなバッチサイズでの学習</title>
      <link>https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/</link>
      <pubDate>Sun, 05 Apr 2020 16:26:26 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/</guid>
      <description>&lt;p&gt;ニューラルネットワークの学習ではミニバッチ学習という複数の学習事例に対して得られる損失の総和を最小化するようにパラメータを更新します。
バッチサイズは計算機のメモリ容量に応じて人が決める値ですが、
BERTはバッチサイズを大きくしたほうが学習が安定しやすいという&lt;a href=&#34;https://arxiv.org/abs/1907.11692&#34;&gt;報告&lt;/a&gt;があります。
しかし、デバイスのメモリに載りきらないサイズでは学習中にメモリーエラーを起こしてしまいます。
本記事ではPyTorchコードを使って、メモリ容量が限られた環境でも大きなバッチサイズでミニバッチ学習する方法を紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【機械学習】scikit-learnで学ぶstacking</title>
      <link>https://tma15.github.io/blog/2020/03/29/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6stacking/</link>
      <pubDate>Sun, 29 Mar 2020 16:08:15 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/29/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6stacking/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;stackingはアンサンブル学習と呼ばれる機械学習の一種で、他の機械学習に基づく複数の予測モデルの出力を入力の一部として扱い、予測モデルを構築します。
単純なアルゴリズムであるのにもかかわらず、何かしらの分類器単体よりも高い予測精度を得やすく、予測精度を競うようなコンペにおいて良く用いられています。
本記事ではscikit-learnのバージョン0.22で導入された&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html&#34;&gt;StackingClassifier&lt;/a&gt;の使い方について紹介するとともに、学習時の挙動を紹介します。
本記事を読むことでscikit-learnでのstackingの学習の流れを理解できます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)</title>
      <link>https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</link>
      <pubDate>Sun, 15 Mar 2020 15:24:03 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。&lt;/p&gt;
&lt;p&gt;本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[PyTorch][自然言語処理] より少ないパディングでミニバッチ学習する方法</title>
      <link>https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Tue, 10 Mar 2020 16:50:53 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;ニューラルネットワークの学習には、複数の事例 (たとえば単語の系列) に対して並列に損失関数を計算し、得られた勾配に基づいてパラメータを更新するミニバッチ学習が用いられます。自然言語処理において、ミニバッチ学習時は単語の系列を同じ長さにそろえて処理します。これはニューラルネットワーク内での計算において、データが密行列として扱われることが多いためです。
この長さをそろえる処理はパディングといわれています。
当然ながら、ミニバッチ内で系列の長さが不ぞろいなほど、パディングによって追加される疑似的な単語が増えるため、本来不要な計算が増えます。また、ミニバッチを表す密行列が大きいほど、計算にかかる時間が大きくなります。
本記事ではPyTorchにおける実装において、系列の長さが近い事例でミニバッチを作成することで、不要なパディングをできるだけ減らし、ミニバッチを表す密行列の大きさを小さくする方法を紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[PyTorch] Datasetの読み込みにかかるメモリ消費量を節約する</title>
      <link>https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/</link>
      <pubDate>Sun, 08 Mar 2020 16:04:11 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;ニューラルネットワークを用いた自然言語処理では、大量のラベルなしテキストを利用した事前学習によって、目的のタスクの予測モデルの精度を改善することが報告されています。
事前学習に用いるテキストの量が多いと、データを計算機上のメモリに一度に載りきらない場合があります。
この記事ではPyTorchでニューラルネットワークの学習を記述する際に、テキストをファイルに分割して、ファイル単位でテキストを読み込むことで、計算機上で利用するメモリの使用量を節約する方法を紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Python] scikit-learnで学ぶパーセプトロンによる文書分類入門</title>
      <link>https://tma15.github.io/blog/2020/03/03/python-scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%85%A5%E9%96%80/</link>
      <pubDate>Tue, 03 Mar 2020 09:54:42 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/03/python-scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%85%A5%E9%96%80/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;この記事ではパーセプトロンを使って文書分類器を学習し、学習済みの分類器を使って文書を分類する流れをご紹介します。パーセプトロンはシンプルな分類アルゴリズムの一つである一方で、これを理解していると他の分類アルゴリズムを理解する助けになるため、初めて機械学習を学ぶ初学者の方にとってよい題材といえます。
この記事に載せているプログラムは&lt;a href=&#34;https://github.com/tma15/scikit-learn-document-classification&#34;&gt;ここ&lt;/a&gt;にまとまっています。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kaggle初参加記録</title>
      <link>https://tma15.github.io/blog/2017/07/29/kaggle%E5%88%9D%E5%8F%82%E5%8A%A0%E8%A8%98%E9%8C%B2/</link>
      <pubDate>Sat, 29 Jul 2017 15:30:01 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2017/07/29/kaggle%E5%88%9D%E5%8F%82%E5%8A%A0%E8%A8%98%E9%8C%B2/</guid>
      <description>&lt;p&gt;この一週間休暇を取っていて、多少の暇な時間があったので前から気になっていた&lt;a href=&#34;https://www.kaggle.com/&#34;&gt;Kaggle&lt;/a&gt;に手を付けてみた。
今回はチュートリアル的に公開されているtitanic号の生存予測タスクに参加した。
他の参加者がブログで公開されている&lt;a href=&#34;http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html&#34;&gt;素性&lt;/a&gt;を参考に素性を設計した。
予測モデルには以前C++で実装した平均化パーセプトロンを用いた。
Scoreが0.79426 (2017/7/29 16:00時点で1428位/7247位) となった。
Kaggleを続けると、機械学習に関するエンジニア能力が高まりそうで良い。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Early updateは収束が保証される</title>
      <link>https://tma15.github.io/blog/2016/09/04/early-update%E3%81%AF%E5%8F%8E%E6%9D%9F%E3%81%8C%E4%BF%9D%E8%A8%BC%E3%81%95%E3%82%8C%E3%82%8B/</link>
      <pubDate>Sun, 04 Sep 2016 11:00:13 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2016/09/04/early-update%E3%81%AF%E5%8F%8E%E6%9D%9F%E3%81%8C%E4%BF%9D%E8%A8%BC%E3%81%95%E3%82%8C%E3%82%8B/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;(&lt;a href=&#34;http://www.aclweb.org/anthology/N12-1015&#34;&gt;Structured Perceptron with Inexact Search&lt;/a&gt;, NAACL 2012) を読んだ。&lt;/p&gt;
&lt;p&gt;構造化パーセプトロンは構造を持つ出力を予測するパーセプトロンであり、自然言語処理では品詞タグ付けなどに用いられる。出力を予測する際には効率的に出力を探索するために、ビームサーチが用いられることが多いが、一般的な構造化パーセプトロンに対してビームサーチを適用すると、パーセプトロンの収束性が保証されない。&lt;/p&gt;
&lt;p&gt;構造化パーセプトロンを効率的に学習する手法として、early updateというヒューリスティクスな手法が提案されている。early updateは出力を予測する途中で正解でないとわかった段階で場合に重みを更新するヒューリスティクスな手法である。しかしながら、early updateはラベル列を最後まで見ずに重みを更新するのにも関わらず、violation fixingという枠組みで収束が保証される。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AdaBoostからLarge Margin Distribution Machineの流れ</title>
      <link>https://tma15.github.io/blog/2016/08/28/adaboost%E3%81%8B%E3%82%89large-margin-distribution-machine%E3%81%AE%E6%B5%81%E3%82%8C/</link>
      <pubDate>Sun, 28 Aug 2016 18:59:58 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2016/08/28/adaboost%E3%81%8B%E3%82%89large-margin-distribution-machine%E3%81%AE%E6%B5%81%E3%82%8C/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;AdaBoostはKaggleなどのコンペで良い成績を出しているアンサンブル学習手法の一つである。このエントリはまずAdaBoostの概要および、なぜAdaBoostが高い汎化能力を示しやすいのかをまとめる。汎化能力が出やすい理由を調査することで、Large Margin Distribution Machineへと発展していった、という経緯を俯瞰することを目的とする。&lt;/p&gt;
&lt;p&gt;具体的には&lt;a href=&#34;http://cs.nju.edu.cn/zhouzh/&#34;&gt;Zhi-Hua Zhou&lt;/a&gt;先生のスライド (&lt;a href=&#34;http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/Adaboost2LDM.pdf&#34;&gt;From AdaBoost to LDM&lt;/a&gt;) を眺めて、自分の理解のためにメモとして残したものになっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>平均化パーセプトロンの効率的な計算</title>
      <link>https://tma15.github.io/blog/2016/07/31/%E5%B9%B3%E5%9D%87%E5%8C%96%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AE%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AA%E8%A8%88%E7%AE%97/</link>
      <pubDate>Sun, 31 Jul 2016 10:13:38 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2016/07/31/%E5%B9%B3%E5%9D%87%E5%8C%96%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AE%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AA%E8%A8%88%E7%AE%97/</guid>
      <description>&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;パーセプトロンは学習事例を受け取り重みベクトルを更新する、という処理を反復した後に重みベクトルを出力する&lt;/li&gt;
&lt;li&gt;平均化パーセプトロンは過去の反復で学習した重みベクトルの平均を出力する&lt;/li&gt;
&lt;li&gt;平均化パーセプトロンは実装が簡単でありながら、良い予測精度が出ることが多い&lt;/li&gt;
&lt;li&gt;素直に平均化パーセプトロンの出力を計算しようとすると各反復における重みベクトルを保持する必要がありメモリ的に学習が非効率であるため、実際には今回メモする方法で実装されることが多い&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>scikit-learnのソースコードリーディング（ナイーブベイズ分類）</title>
      <link>https://tma15.github.io/blog/2013/11/10/scikit-learn%E3%81%AE%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%8A%E3%82%A4%E3%83%BC%E3%83%96%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E/</link>
      <pubDate>Sun, 10 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://tma15.github.io/blog/2013/11/10/scikit-learn%E3%81%AE%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%8A%E3%82%A4%E3%83%BC%E3%83%96%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E/</guid>
      <description>個人的にはプログラミングの勉強は写経が一番頭に入る気がする、ということで読んでいた。
気になったところ データに正規分布を仮定したときのナイーブベイズ分類器について。 平均を\(\mu\)、分散を\(\sigma^2\)としたときの正規分布は
\[ p(x;\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\} \]
これのlogをとると、
$$ \begin{eqnarray} \log p(x;\mu, \sigma^2) &amp;amp;=&amp;amp; \log \{\frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}\} \\\
&amp;amp;=&amp;amp; -\frac{1}{2}\log (2\pi \sigma^2) - \frac{(x-\mu)^2}{2\sigma^2} \end{eqnarray} $$
ナイーブベイズ分類器の対数尤度関数は、データがK次元ベクトルで表現されていて、それがN個あるとすると、 $$ \begin{eqnarray} \log L(X, Y; \mu, \sigma) &amp;amp;=&amp;amp; \log(\prod_{n=1}^N p(\mathbf{x}_n, y_n))\\\
&amp;amp;=&amp;amp; \log(\prod_{n=1}^N p(y_n)p(\mathbf{x}_n|y_n))\\\
&amp;amp;=&amp;amp; \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \log p(\mathbf{x}_n|y_n)\\\
&amp;amp;=&amp;amp; \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K\log p(x_{nk}|y_n)\\\
&amp;amp;=&amp;amp; \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma_{y_nk}^2) - \frac{(x_{nk}-\mu_{y_nk})^2}{2\sigma_{y_nk}^2}\} \end{eqnarray} $$</description>
    </item>
    
    <item>
      <title>Practical Machine Learning Tricks</title>
      <link>https://tma15.github.io/blog/2012/12/15/practical-machine-learning-tricks/</link>
      <pubDate>Sat, 15 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://tma15.github.io/blog/2012/12/15/practical-machine-learning-tricks/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;&lt;a href=&#34;http://blog.david-andrzejewski.com/machine-learning/practical-machine-learning-tricks-from-the-kdd-2011-best-industry-paper/&#34;&gt;Practical machine learning tricks from the KDD 2011 best industry paper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上のブログはKDD 2011のindustry tracksでbest paperを受賞した論文を紹介しているのだけど、その紹介している内容がとても参考になったので日本語でまとめなおしている。間違った解釈をしていることがおおいにありうるので、英語が読める人は元のブログを読むことをおすすめします。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>