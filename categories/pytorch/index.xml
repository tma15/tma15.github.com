<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pytorch on Now is better than never.</title>
    <link>https://tma15.github.io/categories/pytorch/</link>
    <description>Recent content in pytorch on Now is better than never.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 26 Apr 2020 10:18:59 +0900</lastBuildDate>
    
	<atom:link href="https://tma15.github.io/categories/pytorch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>【PyTorch】Version1.5でTPUを利用する方法</title>
      <link>https://tma15.github.io/blog/2020/04/26/pytorchversion1.5%E3%81%A7tpu%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Sun, 26 Apr 2020 10:18:59 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/04/26/pytorchversion1.5%E3%81%A7tpu%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>&lt;p&gt;PyTorchのVersion1.5.0が&lt;a href=&#34;https://github.com/pytorch/pytorch/releases&#34;&gt;リリースされました&lt;/a&gt;。
いくつかの変更がされていますが、その中の一つが、PyTorchでXLAの利用が可能となったというものです。
XLAを利用できると、PyTorch実装をTPU上で実行できるようになります。
本記事ではPyTorch1.5.0を使ってGoogle ColabのTPUを利用できるようになるところまでの流れを説明します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【PyTorch】限られたメモリにおける大きなバッチサイズでの学習</title>
      <link>https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/</link>
      <pubDate>Sun, 05 Apr 2020 16:26:26 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/</guid>
      <description>&lt;p&gt;ニューラルネットワークの学習ではミニバッチ学習という複数の学習事例に対して得られる損失の総和を最小化するようにパラメータを更新します。
バッチサイズは計算機のメモリ容量に応じて人が決める値ですが、
BERTはバッチサイズを大きくしたほうが学習が安定しやすいという&lt;a href=&#34;https://arxiv.org/abs/1907.11692&#34;&gt;報告&lt;/a&gt;があります。
しかし、デバイスのメモリに載りきらないサイズでは学習中にメモリーエラーを起こしてしまいます。
本記事ではPyTorchコードを使って、メモリ容量が限られた環境でも大きなバッチサイズでミニバッチ学習する方法を紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)</title>
      <link>https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</link>
      <pubDate>Sun, 15 Mar 2020 15:24:03 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。&lt;/p&gt;
&lt;p&gt;本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Colab] Googleの無料GPU環境を使うための準備</title>
      <link>https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/</link>
      <pubDate>Wed, 11 Mar 2020 15:05:37 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;Google Colaboratory (略称: Colab) はGoogleが提供する無料の計算環境です。
ウェブブラウザ上でコードを記述して実行できるインタラクティブな操作ができます。
さらにGPUやTPUを無料で利用できる素晴らしい計算環境です。
本記事ではColabを利用するための計算環境の構築手順を紹介します。
またハードウェアやエディタといった計算環境のカスタマイズの方法や、自分で作成したプログラム資産をColab上でも活用する方法も紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[PyTorch][自然言語処理] より少ないパディングでミニバッチ学習する方法</title>
      <link>https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Tue, 10 Mar 2020 16:50:53 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;ニューラルネットワークの学習には、複数の事例 (たとえば単語の系列) に対して並列に損失関数を計算し、得られた勾配に基づいてパラメータを更新するミニバッチ学習が用いられます。自然言語処理において、ミニバッチ学習時は単語の系列を同じ長さにそろえて処理します。これはニューラルネットワーク内での計算において、データが密行列として扱われることが多いためです。
この長さをそろえる処理はパディングといわれています。
当然ながら、ミニバッチ内で系列の長さが不ぞろいなほど、パディングによって追加される疑似的な単語が増えるため、本来不要な計算が増えます。また、ミニバッチを表す密行列が大きいほど、計算にかかる時間が大きくなります。
本記事ではPyTorchにおける実装において、系列の長さが近い事例でミニバッチを作成することで、不要なパディングをできるだけ減らし、ミニバッチを表す密行列の大きさを小さくする方法を紹介します。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[PyTorch] Datasetの読み込みにかかるメモリ消費量を節約する</title>
      <link>https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/</link>
      <pubDate>Sun, 08 Mar 2020 16:04:11 +0900</pubDate>
      
      <guid>https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/</guid>
      <description>&lt;!--adsense--&gt;
&lt;p&gt;ニューラルネットワークを用いた自然言語処理では、大量のラベルなしテキストを利用した事前学習によって、目的のタスクの予測モデルの精度を改善することが報告されています。
事前学習に用いるテキストの量が多いと、データを計算機上のメモリに一度に載りきらない場合があります。
この記事ではPyTorchでニューラルネットワークの学習を記述する際に、テキストをファイルに分割して、ファイル単位でテキストを読み込むことで、計算機上で利用するメモリの使用量を節約する方法を紹介します。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>