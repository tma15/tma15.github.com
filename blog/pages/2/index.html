<!doctype html>
<html lang="ja">
    <head>
        <link href="http://fonts.googleapis.com/css?family=Anton" rel="stylesheet" type="text/css">
        <link href='http://fonts.googleapis.com/css?family=Inconsolata' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Bubblegum+Sans' rel='stylesheet' type='text/css'>
        <title>Blog
 | Now is better than never.</title>
        <meta charset="utf-8" />
        <link href='http://fonts.googleapis.com/css?family=Permanent+Marker' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="/media/css/font-awesome.css">
        <link rel="stylesheet" href="/media/css/style.css">
        <link rel="stylesheet" href="/media/css/pygments.css">
        <link rel="shortcut icon" href="/media/img/background.jpg">
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }
            });
        </script>
        <script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
        <!--[if lt IE 9]>
        <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js">
        </script>
        <![endif]-->
    </head>
    <body >
        <header>
            <hgroup>
              <h1>Now is better than never.</h1>
              <h3>Although never is often better than right now.</h3>
            </hgroup>
        </header>
        <nav>
                                <ul>
<li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/blog">Blog</a></li><li><a href="/blog/archive.html">Archive</a></li></ul>
        </nav>
        <article id="content">
                                            <section class="posts">

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2014/2/jeff-bezos-and-the-age-of-amazon.html" title="ジェフ・ベゾス 果てなき野望-アマゾンを創った無敵の奇才経営者" itemprop="url">ジェフ・ベゾス 果てなき野望-アマゾンを創った無敵の奇才経営者</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/book.html" rel="tag">book</a> 
</div>

<div class="entry" itemprop="articleBody">
        <div align="center">
<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?t=takuya6315-22&o=9&p=8&l=as1&asins=B00H3WR470&ref=qf_sp_asin_til&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>
</div>

<p>Amazonの中の話はあまりWeb上で見たことがなかったので興味深く読めた。</p>
<p>会社の方針は、ジェフ・ベゾスの意思を強く反映している感じ。
ジェフ・ベゾスは顧客のことを第一に考えていて、それを背景にして社員の福利厚生はかなり貧しい感じ。
例えば、社員にバスが動いている時間に帰ってほしくないから、という理由でバスの定期を買う際の補助金を却下しているらしい。
また、長期的なメリットを考えて、短期的な利益は考えずに赤字覚悟で商品の価格を引き下げたりしている。
これで競合他社が立ち入る隙を見せないようにしている。すごい。。&nbsp;いちAmazonユーザからすると、なんて顧客のことを考えてくれる会社なんだろうと思う。</p>
<p>誰かを雇ったら、その人を基準に次はもっと優れた人を雇うようにすると言った、Googleなどの話でも聞いたようなことをやっていて、
人材はどの企業でも大事なんだなあと改めて思った&nbsp;(小並感)。</p>
<p>ジェフ・ベゾス個人の話も書いてあった。&nbsp;仕事では冷徹で、鬼のような怖さだけど、家族には優しい一面ものぞかせいている。</p>
<p>A9がたまに学会のスポンサーとかで見かけていて、Amazonのにっこりマークが付いていてどういう関係なんだろうと思っていたが、A9はAmazonの技術系の子会社だということもこの本で知った。
あと、もともと本を始めとする小売業のようなことをやっていたのに、どのようにAmazon Web&nbsp;Serviceを提供するに至ったかの話も書いてあって面白かった。</p>
<p>個人的には、部門間の調整が難しいという大企業ならではの問題をなんとかしたいと思った中間管理職のチームが、部門間の対話を推進する仕組みを提案した時にジェフ・ベゾスが言った以下の言葉が印象に残った。</p>
<p>「言いたいことはわかるが、それは大まちがいだ。コミュニケーションは機能不全の印なんだ。緊密で有機的につながる仕事ができないから、関係者のコミュニケーションが必要になる。部署間のコミュニケーションを増やす方法ではなく、減らす方法を探すべきだ。」</p>
</div>

<div>Posted <abbr class="timeago" title="2014-02-17T00:00:00+0800"></abbr> on <time datetime="2014-02-17" class="date" itemprop="datePublished">17 Feb 2014</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2014/1/2013-2014.html" title="2013年と2014年" itemprop="url">2013年と2014年</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/diary.html" rel="tag">diary</a> 
</div>

<div class="entry" itemprop="articleBody">
        <h2>2013年の振り返り</h2>
<p><a href="http://tma15.github.io/blog/2013/1/start-of-2013.html">2013年の抱負</a>と照らしあわせて。</p>
<h3>飲み過ぎない</h3>
<p>12月は飲み過ぎた。次の日に食欲がなくなったりしてしまったり、ひどい時は2,3日胃がむかむかする感じだったので、反省。回数は多くても、一回あたりに飲む量を少し減らしたい。他の月は適度に楽しめたと思う。いつもお世話になっている美容師さん曰く、</p>
<p>「最初に飲む量を決めると良い。」</p>
<h3>反転してシュート</h3>
<p>あまり出来なかった。どうしても前を向いている後ろの選手にはたこうという気持ちが強すぎる。一旦「パスを出せ」と怒られるくらいのプレーが必要かも。</p>
<h3>論文を読む</h3>
<p>二日に一本読む、というのは出来なかった（無謀すぎた&#8230;）。とはいえ、すずかけ台論文読み会を主催し、今年は7回開催することが出来た点に関しては満足している。</p>
<p>この読み会は次の二つの（自分が享受したい）メリットを狙って、参加者は少人数にしぼり、基本的には参加者は読んだ論文をみんなの前で紹介するというスタイルにした:</p>
<ol>
<li>他の参加者にわかりやすく伝えるようにするためにより紹介する論文を読み込むようになる</li>
<li>参加者は少人数に絞っているので、気楽に場を止めて質問することができる</li>
</ol>
<p>ので自分を含め、参加した人の得るものはそれなりに多くできたと思う。ただ、自分は紹介する論文に対してまだ曖昧な理解をしているままなことも多く、ありがたいご指摘も多々受けるので、もっと読み込まなければいけないところ。</p>
<p>参加者の規模はこのままで良いのだけど、紹介する論文を参加者にとって有益そうなものにする仕組みを採用すべきかな、とぼんやり考えたり。ある程度人数がいれば、対象となる学会を絞って、気になる論文に投票するという形もありだと思うけど、少人数ではこの形は難しいので、2014年は色々と模索したい。</p>
<h2>2014年の抱負</h2>
<p>いくつもあっても大変なので大きく二つ。</p>
<h3>論文を書く</h3>
<p>有名どころの国際学会の論文を読んでいるのは、自分もそういった国際学会に論文を通すため。査読付き国際学会に論文を通す、というのを目標にすべきところだけど、まずは論文を書く回数を増やす。あと、論文を書き始めるタイミングを、研究を始めるとき、あるいは研究の途中にする。論文を書き始めるタイミングは早いほうが良いという意見については色々なところで目にする気がする。例えば、</p>
<p><a href="http://www.cs.ucr.edu/~eamonn/Keogh_SIGKDD09_tutorial.pdf">How to do good research, get it published in <span class="caps">SIGKDD</span> and get it cited</a>とか</p>
<blockquote class="twitter-tweet" lang="ja"><p><a href="https://twitter.com/Pnnc205j">@Pnnc205j</a>&nbsp;だから早い段階からの論文執筆開始を推しているのさ。こうすると自分の研究の進め方につっこみが入れやすいしね。</p>&mdash; Tetsuya Sakai (酒井哲也) (@tetsuyasakai) <a href="https://twitter.com/tetsuyasakai/statuses/184170104878141440">2012, 3月 26</a></blockquote>

<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>とか。<a href="http://ymatsuo.com/japanese/ronbun_eng.html">松尾ぐみの論文の書き方：英語論文</a>でその重要性について書かれている、論文の「完成度を上げる」ためにも、早く書くことがとても大事なんだと思う。あとは、取り組むタスクに対して研究になりそうなところを目を凝らして物色したい。</p>
<h3>サボれないフットサル・サッカー環境に身を置く</h3>
<p>T村さんから指摘されたが、普段からヌルい空気でプレーしていることが攻守の切り替えの遅さを招いている気がする。仲間内でプレーしている時は大きな問題ではないけど、まじめな試合でこのことが致命的に自分の価値を下げていた。みんなで楽しむフットサル・サッカーも続けるけど、サボれない場所でもプレーする機会をつくりたいところ。とりあえずは個サルに参加して、知らない人の前で「情けないプレーなんてできない」と思える環境を少なくとも月に1回はつくる。</p>
</div>

<div>Posted <abbr class="timeago" title="2014-01-02T00:00:00+0800"></abbr> on <time datetime="2014-01-02" class="date" itemprop="datePublished">02 Jan 2014</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/12/mct.html" title="エッセイ"Towards the Machine Comprehension of Text"のメモ" itemprop="url">エッセイ"Towards the Machine Comprehension of Text"のメモ</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/nlp.html" rel="tag">nlp</a> 
<a href="/blog/tags/paper.html" rel="tag">paper</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p><a href="http://research.microsoft.com/apps/pubs/default.aspx?id=206771">エッセイ</a>の一部をメモ。</p>
<p>主張をまとめると「自然言語の機械的な理解には、大規模なデータ、性能の良い機械学習も重要だけど、言語の構造をしっかり考えることも大事」。</p>
<h2>Introduction</h2>
<ul>
<li>Machine Comprehension of Text (<span class="caps">MCT</span>) (テキストの機械的理解)&nbsp;は人工知能のゴールである</li>
<li>このゴールを達成したかどうかを確かめるために、研究者はよくチューリングテストを思い浮かべるが、Levesque (2013)が指摘するように、これは機械を知的に向かわせる、というよりは人間の知能を下げるほうに作業者を差し向けてしまう<ul>
<li>※&nbsp;チューリングテストとは、ある人間から見て、二人の対話のどちらが人間かどうか判別するテスト</li>
</ul>
</li>
<li>Levesqueはまた、チューリングテストよりも、世界知識を必要とするような選択肢が複数ある問題のほうが適しているとも主張している</li>
<li>このエッセイでは、<span class="caps">MCT</span>は、&#8221;ネイティブスピーカーの大半が正しく答えられる質問に対して機械が答えた回答が、ネイティブスピーカーが納得できるものであり、かつ関連していない情報を含んでいなければ、その機械はテキストを理解しているもの&#8221;とする&nbsp;(つまり質問応答)</li>
<li>このエッセイのゴールは、テキストの機械的理解という問題に何が必要なのかを観察することである</li>
</ul>
<h3>How To Measure&nbsp;Progress</h3>
<ul>
<li>複数の選択肢がある質問応答のデータセットをクラウドソーシングを利用して作った<ul>
<li>7歳の子供が読めるレベルのフィクションの短いストーリー</li>
</ul>
</li>
<li>Winograd Schema Test proposal (Levesque, 2013) は、質問と回答のペアは世界知識を要求するように注意深く設計されているので、生成には専門知識を要する質問を使うことを提案している<ul>
<li><span class="dquo">&#8220;</span>それは紙で出来ているので、ボールはテーブルから落ちた&#8221;の&#8221;それ&#8221;は何を指しているか？</li>
</ul>
</li>
<li>クラウドソーシングなのでスケーラビリティもある</li>
<li>進捗が早ければ、問題の難易度を上げることもできる<ul>
<li>語彙数を現状の8000から増やす</li>
<li>ノンフィクションなストーリーを混ぜる</li>
<li>タスクの定義を変える<ul>
<li>正解が1つ以上、あるいは正解が1つもない問題など</li>
<li>回答の根拠を出力するようにする</li>
</ul>
</li>
</ul>
</li>
<li>興味深いことは、ランダムな回答をするベースラインでは25%が正しい回答を得られる一方で、単純な単語ベースな手法が60%で、最近のモダンな含意認識システムを使っても60%くらいであることである</li>
</ul>
<h2>Desiderata and some Recent&nbsp;Work</h2>
<p>machine&nbsp;comprehensionに必要なものは、興味深い未解決な問題と通じている</p>
<ol>
<li>意味の表現は二つの意味でスケーラブルであるべきである、すなわち (1) 複数ソースのノイジーなデータから教師なし学習で学習できて、 (2)&nbsp;任意のドメインの問題に適用できるべきである</li>
<li>モデルが巨大で複雑になっても、推論はリアリタイムでおこなえるべきである</li>
<li>構築、デバッグの簡易化のためにシステムはモジュール化すべきである<ul>
<li>モジュラ性はシステムを効率的に反応できるようにするべきである</li>
</ul>
</li>
<li>エラーが起きた時に、何故それが起きたか理解可能にするために、各モジュールは解釈可能であるべきであり、同様にモジュールの構成も解釈可能であるべきである</li>
<li>システムは単調的に修正可能であるべきである:&nbsp;起きたエラーに対して、別のエラーを引き起こさずに、どのようにモデルを修正すればよいかが明白であるべきである</li>
<li>システムは意味表現に対して論理的推論をおこなえるべきである<ul>
<li>システムの入力のテキストの意味表現とシステムの世界モデルを組み合わせることで論理的な結論をだせるべきである</li>
<li>もろさを避けるため、また根拠を正しく結合するために、論理的思考は確率的であるべきなようである (Richardson and Domingos,&nbsp;2006)</li>
</ul>
</li>
<li>システムは質問可能であるべきである<ul>
<li>任意の仮説に関して、真であるかどうか (の確率)&nbsp;を断言することができること</li>
<li>私達はなぜその断言ができるか理解することができるべきである</li>
</ul>
</li>
</ol>
<h3>最近の研究では</h3>
<ul>
<li>論理形式を文に対してタグ付けするなど、意味のモデル化はアノテーションコストがとても高い<ul>
<li>興味深い代替手段としては、質問-回答のペアから論理形式を帰納するアノテーションがより低いものがある (Liang et al.,&nbsp;2011)</li>
<li>教師なし学習でやる研究もある (Goldwassar et al. (2011)&nbsp;は60%の精度、ただし教師あり学習は80%)</li>
</ul>
</li>
<li>データはクラウドソーシングを利用すればスケールする (特にゲームとして提供すれば (Ahn and Dabbish,&nbsp;2004))</li>
<li>大量のラベルなしデータを使えばある粒度の意味のモデル化はできる (らしい) (Mikolove et al.,&nbsp;2013)</li>
<li>意味モデル化のもう一つの問題は、あるタスク用に作ったモデルが他のタスクに使えないこと</li>
<li>とても難しいタスクに挑戦するとき、モジュラ性、デバッグ性、解釈性は、良い精度を出すのに役立つ<ul>
<li>画像分類タスクの現在のレコードホルダーが畳み込みネットワークが実際に何をしているのかを理解するための手法を設計したのは偶然の一致ではない: (Zeiler and Fergus,&nbsp;2013)</li>
<li>修正可能性も強く関連している<ul>
<li>現在の機械学習モデルは、誤った例を正しく分類できるように修正するとき、別の例で新たな誤りをしないという保証がない</li>
</ul>
</li>
<li>質問可能性は別のデバッグツールである<ul>
<li>理解が簡単であるほど、そのモデルはうまくいく</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>Seven&nbsp;Signposts</h2>
<h3>How to Incorporate Structure in&nbsp;Learning?</h3>
<ul>
<li>初期の<span class="caps">AI</span>はルールベース<ul>
<li>経験的で、もろく、スケールしない</li>
</ul>
</li>
<li>機械学習手法は構造データを扱えるように拡張されているが、主な方法は統計的なものである: 教師あり学習の基本的な設定では、<ul>
<li>データはある分布から生成されると仮定</li>
<li>モデル、コスト関数 (しばしば凸関数)&nbsp;、ラベル付きデータが必要</li>
<li>ゴールは手元の訓練データのエラーを最小化すること&nbsp;(正則化は簡単のため考えない)</li>
</ul>
</li>
<li>構造は、コスト関数の探索時に構造の制約を入れることで考慮される<ul>
<li>言語はすごく構造的なので、機械学習のモデルを微調整して構造を考慮するよりも、最初からこの構造を認識しておくべきである</li>
</ul>
</li>
<li>言い換えれば機械学習は不確かさを扱う基本的な方法である<ul>
<li>もし、あまりに早く不確かさをモデル化することが、データの構造について我々が知っていることのほとんどを無視してしまうことにつながるなら、この誘惑には対抗しなければならない</li>
<li>そして、ほとんどの機械学習のアルゴリズムは、とてもシンプルなラベル (例えば二値ラベル)&nbsp;を使って、この上なく見事に不確かさをモデル化するように調整されている</li>
<li>確率的なグラフィカルモデルはモデルの構造の問題に取り組んでいるが、モデルの構造は人手で設計されているのでスケールしない</li>
</ul>
</li>
<li>先程述べたように、最近の研究では論理構造と統計モデルを直接組み合わせているが、まだスケーラビリティが問題ある</li>
<li>私達は、一つの極端 (人手で設計したルールに基づく<span class="caps">AI</span>) から、もう一つの極端 (明示的なルールがない機械学習)&nbsp;にきている</li>
</ul>
<h3>Do Large Data and Deep Learning Hold the&nbsp;Key?</h3>
<ul>
<li>ここ10年で、大量のデータを使うことで、昔から難しいタスクであった、質問応答、オントロジーの構築などですばらしい進歩が得られた<ul>
<li>deep neural&nbsp;networkがYouTubeの画像データを使って学習した</li>
</ul>
</li>
<li>しかしながら、意味のモデル化を避け、データの規模に頼っているシステムはもろい</li>
<li>AskMSR (人手で設計したルールに基づく<span class="caps">QA</span>システム (Brill et al., 2002) に&#8221;How many feet are there in a lightyear? (1光年は何フィートか)？&#8221;という質問をしたら&#8221;Winnie the Pooh&#8221;と回答した<ul>
<li>ディズニーのキャラクターであるBuzz&nbsp;Lightyearが根拠になって回答された</li>
<li>意味の処理をちゃんとやっていない (質問は&#8221;how&nbsp;many&#8221;で始まっているので、回答は数字なはず)</li>
</ul>
</li>
<li><span class="caps">IBM</span>のWatson (<span class="caps">IR</span>の様々な技術を組み合わせて人間のクイズ王に勝ったシステム)&nbsp;でさえも<span class="caps">US</span>の都市に関する質問をしたらトロントと答えた</li>
<li>Deep Learningは強力なパラダイムである<ul>
<li>音声認識、画像分類では大きな成果を上げているが、まだシステムが解釈可能でなかったり、質問可能でなかったり、修正可能でなかったり、スケールしなかったりする</li>
</ul>
</li>
</ul>
<h3>Why is <span class="caps">NLP</span> so&nbsp;Hard?</h3>
<ul>
<li>自然言語処理はテキストの構造を直接モデル化する代替手段と見ることができるが、まだ初期段階である<ul>
<li>文が意味をなすかどうか、あるいは文が文法的かどうかという人間には簡単な問題すらまだ解けていない<ul>
<li>そのドメインにおけるリッチなモデルが、自然言語の理解には必要であるため<ul>
<li>しかし、リッチなモデルを作るには、自然言語処理の高い技術が必要</li>
<li>そのため、問題を限定して解くことが多い</li>
</ul>
</li>
<li>別の理由としては、<span class="caps">NLP</span>のタスクで機械学習のモデルを学習するときには、データの構造を直接利用する、というよりは二値ラベルのようなシンプルなものを利用するため問題をうまく解けないということも考えられる</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Can we Limit Scope for Manageability, yet Still Achive&nbsp;Scalability?</h3>
<ul>
<li>意味をモデル化する試みでは、簡単のために、よく問題を限定する</li>
<li>問題を限定すると、その解はスケールできない</li>
<li>問題を限定することには、科学的には意味があるが、私達は一般化が簡単な問題の限定、大規模データがある問題を探さなければならない</li>
</ul>
<h3>Are Brains Using Machine&nbsp;Learning?</h3>
<ul>
<li>あなたが友達が何か誤解をしていて苦労しているのに気づいたとしましょう</li>
<li>どうやって友達を救いますか？<ul>
<li>彼を何テラバイトもの訓練データとともに部屋に閉じ込め、「一週間これでパラメータを更新しといてね」ということはしないでしょう</li>
<li>あなたはあっという間にもっともありがちな彼の誤解が何なのかを考える<ul>
<li>「彼が誤解を修正すべきところはどこなんだろう」</li>
<li>あなたは一つや二つ、彼に質問をするかもしれない:&nbsp;彼には質問することができる</li>
</ul>
</li>
</ul>
</li>
<li>つまり、あなたは彼の思考に関する解釈可能なモデルを持っていることになる</li>
<li>モジュラ性は人間の学習の強い区分けによって提案される<ul>
<li>人間は自転車に乗る方法を学ぶ時に歯の磨き方を忘れない</li>
<li>機械は、あらたに間違えたことを修正する時に、もともと正しく分類できていたものを間違えるようになってしまう</li>
</ul>
</li>
<li>難しいタスクにおいてさえ、人間は何かの意味を認識する時に、大量のラベル付きデータを使わない<ul>
<li>学習のプロセスは世界知識のモデルを更新する小さなステップに分割される<ul>
<li>見えない統計的なパラメータを更新しているわけではない</li>
</ul>
</li>
<li>人間は記録、更新が簡単な意味のモデルを持たなければならない<ul>
<li>少なくとも、彼らのモデルは解釈可能で、修正可能で、質問可能であることを示唆している</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>Discussion</h2>
<ul>
<li><span class="caps">AI</span>の初期からあるルールベースからあって、研究者はそれに依存し過ぎることに慎重であることは明白であった</li>
<li>ルールベースなシステムが解けない問題は、あまりない例外であり、それを解けるようにするために人手でルールを更新するというのは大規模なデータに対してスケールしない</li>
<li>機械学習は多くの場合、強力なツールであるのだけど、多くの場合解釈が難しく、ラベル付きデータ無しに改善することが難しい</li>
<li>機械学習は、適切な場面で使えば当然強力なツールである<ul>
<li>データの構造を最大限活用した後に、データに残っている不確かさのモデル化に使うことに制限することが考えられる</li>
</ul>
</li>
<li>人間にとってテキストが曖昧性を持たないという事実は、不確かさのモデル化は解くべき重要な問題ではないことを示唆している<ul>
<li>不確かさがモデル化されなければならない状況やラベルが極めて単純な状況において機械学習アルゴリズムの使用を抑えて、代わりにリッチな構造の、曖昧性のないテキストのために設計された他の手段を模索することは、機械学習が基づく数学的な基礎を放棄しているわけではない</li>
</ul>
</li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2013-12-27T00:00:00+0800"></abbr> on <time datetime="2013-12-27" class="date" itemprop="datePublished">27 Dec 2013</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/12/penguins-in-sweaters-or-serendipitous-entity-search-on-user-generated-content.html" title="Penguins in Sweaters, or Serendipitous Entity Search on User-generated Content (CIKM2013)メモ" itemprop="url">Penguins in Sweaters, or Serendipitous Entity Search on User-generated Content (CIKM2013)メモ</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/paper.html" rel="tag">paper</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p><a href="http://labs.yahoo.com/publication/penguins-in-sweaters-or-serendipitous-entity-search-on-user-generated-content/">proceeding</a>
slide: <a href="http://www.slideshare.net/mounialalmas/penguins-in-sweaters-or-serendipitous-entity-search-on-usergenerated-content">slideshare</a></p>
<h2>まとめ</h2>
<p><span class="caps">CIKM</span> 2013でBest paperを取った、著者が全員女性(<a href="http://labs.yahoo.com/news/ilaria-bordino-yelena-mejova-mounia-lalmas-awarded-best-paper-at-cikm-2013/">参考</a>)という、自分が今まで読んだ中でおそらく一番華やかな論文で、Yahoo Answersを知識源として、セレンディピティ (思ってもみなかったけど、クエリと関連していること) を感じる検索を提供する話。
何か新たな手法を提案した、というよりは、Yahoo&nbsp;Answersという知識源を使うことで、何か思ってもみなかったけど、面白い検索結果を提供できるんじゃないかな〜というアイディアを実際に試してみた、という感じだろうか。</p>
<p>以下、メモ。</p>
<h2>Why/when do penguins wear&nbsp;sweaters?</h2>
<ul>
<li>タスマニアで起きた原油漏れで体に油がついてしまったペンギンが、再び元の生活に戻れるようにするためのチャリティーソング (James GordonのSweaters for Penguins)<ul>
<li>羽毛に原油がつくことで断熱性が落ち、ペンギンが凍えてしまう</li>
<li>くちばしで羽毛に付いた原油を落とそうとすることで体を傷つけてしまう</li>
</ul>
</li>
</ul>
<h3>Serendipity</h3>
<p>役に立つんだけど、特に探していたわけではないもの。</p>
<h3>Entity&nbsp;Search</h3>
<p>この論文ではWikipediaとYahoo! Answersから抽出した、メタデータで情報を豊富にしたentityネットワークを基にentity-driven serendipitous search&nbsp;systemを作成する。</p>
<h2>この論文の焦点</h2>
<h3><span class="caps">WHAT</span></h3>
<p>ウェブコミュニティの知識源はどのようなentity間の関係を提供するのか？</p>
<h3><span class="caps">WHY</span></h3>
<p>そのような知識源がどのように面白く、セレンディピティなブラウジング経験に寄与するのか？</p>
<h2>データ</h2>
<h3>Yahoo!&nbsp;Answers</h3>
<ul>
<li>ごくわずかにまとめられた意見、ゴシップ、個人情報</li>
<li>観点が多様</li>
</ul>
<h3>Wikipedia</h3>
<ul>
<li>高品質の情報が整理されている</li>
<li>ニッチなトピックが豊富</li>
</ul>
<h2>Entity <span class="amp">&amp;</span> Relation&nbsp;Extraction</h2>
<h3>Entity:&nbsp;Wikipediaに記述されている概念</h3>
<p>1 テキストから表層形を識別し、
2&nbsp;Wikipediaのentityと紐付けして、</p>
<ul>
<li>文脈依存</li>
<li>文脈非依存な素性<ul>
<li>click&nbsp;log</li>
</ul>
</li>
</ul>
<p>3 Wikipediaのentityを、テキストとの関連度順に基いてランキングする&nbsp;(aboutnessスコア(34)を使ってランキングする)</p>
<h3>Reationship:&nbsp;tf/idfベクトルのコサイン類似度</h3>
<p>entityが現れるドキュメントを結合したものがベクトルで表される</p>
<h2>Dataset Features&nbsp;(Metadata)</h2>
<h3>Sentiment</h3>
<ul>
<li>SentiStrengthを用いてpositive <span class="amp">&amp;</span> negativeのスコアを計算する<ul>
<li>インフォーマルな英語の極性判定でstate-of-the-art</li>
<li>このままだと文書レベルでの極性判定<ul>
<li>文単位でpositive、negativeのスコアを割り当てて、それぞれの平均が文書単位の極性のスコアになる</li>
</ul>
</li>
<li>文書は複数のentityを含むことが多いのでentity単位での極性はうまく測れない</li>
<li>まずentityのそれぞれ前後10単語のウィンドウに対して極性のスコアを計算する</li>
</ul>
</li>
<li>attitudeとsentimentalityをウィンドウに対して計算する[Kucuktunc&#8216;12]<ul>
<li>attitude:&nbsp;positiveもしくはnegativeに対する傾向</li>
<li>sentimentality:&nbsp;極性の大きさ</li>
</ul>
</li>
<li>entityが現れるウィンドウのattitude,&nbsp;sentimentalityの平均値がentity単位の素性とする</li>
</ul>
<h3>Quality</h3>
<ul>
<li>可読性</li>
<li>Flesch Reading Ease score[14]<ul>
<li>スコアが高いほど理解するのが難しい</li>
<li>スコアが低いほど理解するのが易しい</li>
</ul>
</li>
<li>Fig1は二つのデータセットにおけるエンティティの可読性の分布</li>
</ul>
<h3>Topical&nbsp;Category</h3>
<ul>
<li>Yahoo Content Taxonomy<ul>
<li>Table&nbsp;2</li>
<li>二つのデータ・セット中の概念体型は使わない<ul>
<li>整合性をとるため</li>
<li>二つのデータセットにおける実験結果を比較するため</li>
</ul>
</li>
</ul>
</li>
<li><span class="caps">US</span>-Englishのニュース記事を使って訓練した分類器で文書分類する</li>
<li>entityレベルの素性にするため、そのentityが現れた文書に割り当てられたカテゴリのうち、頻度が高い上位3つのカテゴリを素性にする</li>
</ul>
<h2>Retrieval</h2>
<h3>Algorithm: Lazy Randomwalk with&nbsp;restart</h3>
<ul>
<li>self-loop probability: beta
他のノードへの伝搬を遅らせて、random walkの開始ノードの重要性をより高める<ul>
<li>先行研究にしたがって、beta = 0.9 [6,&nbsp;12]</li>
</ul>
</li>
<li>follow one of the out-links with probability: 1 - beta
エッジの重みに比例してrandom&nbsp;walkする</li>
<li>random jumpの確率は0 (alpha = 0)<ul>
<li>random&nbsp;jumpすると結果が悪くなるため</li>
</ul>
</li>
<li>反復の終了条件<ul>
<li>前回とのノルムの差が10^-6以下、もしくは30回反復した</li>
</ul>
</li>
</ul>
<h4>scoring&nbsp;method</h4>
<ul>
<li>popularなentityはどこにでも上位にランクされるのでこれらをフィルタリング</li>
</ul>
<h3>Testbed</h3>
<ul>
<li>2010~2011にGoogle Zeitgeistで最も検索されたクエリの中から、Wikipedia、Yahoo!&nbsp;Answersの文書中に共に現れる上位50件のクエリ</li>
</ul>
<h3>Precision @5,&nbsp;<span class="caps">MAP</span></h3>
<ul>
<li>Precision: 66.8% on <span class="caps">WP</span>, 72.4% on&nbsp;<span class="caps">YA</span></li>
<li><span class="caps">MAP</span>: 0.716 on <span class="caps">WP</span>, 0.762 on <span class="caps">YA</span>
ふたつのデータセットでの性能は同等であるものの、ランキングされるentityにはあまり重複がないため、二つのランキング結果を結合すると性能が上がる<ul>
<li>Fagin et al. [13]のrank&nbsp;aggregationを使う</li>
</ul>
</li>
</ul>
<h3>Annotator&nbsp;agreement</h3>
<ul>
<li>1つのクエリにつき、annotatorは3人<ul>
<li>クラウドソーシングしてるので、信頼出来ないannotatorは排除</li>
</ul>
</li>
<li>(overlap): 0.85%<ul>
<li>馴染みのないクエリはagreementが低い (Secosteroid, Sally Kern,&nbsp;&#8230;)</li>
</ul>
</li>
</ul>
<h3>Average overlap in top&nbsp;5</h3>
<ul>
<li>results: 12%<ul>
<li>= 0.6 entity/top 5&nbsp;entities</li>
</ul>
</li>
</ul>
<h3>Error&nbsp;analysis</h3>
<p>提案手法の有効性はクエリのentityのすぐとなりのentityをあまり上に挙げないことによる</p>
<ul>
<li>例) Egyptに最も近い二つのentity<ul>
<li>British Pacific Fleet, <span class="caps">FC</span> Groningen&nbsp;(<span class="caps">WP</span>)</li>
<li>Spring, <span class="caps">IGN</span>&nbsp;(<span class="caps">YA</span>)</li>
<li>Springは&#8221;Arab&nbsp;Spring&#8221;と間違えて識別された可能性があるが、このSpringは提案手法があまりEgyptの近くをみないので下位にランクされる</li>
</ul>
</li>
</ul>
<p>とても似通ったentityばかりが上位にランクされてしまうこともある</p>
<ul>
<li>例) インフルエンザのウィルス名、Mac PowerBookのバージョン名で上位がうまる<ul>
<li>random&nbsp;walk時に密度が高いサブグラフにトラップされてしまうことで起きる</li>
</ul>
</li>
</ul>
<p>entityは関連していないentityが近くに来ることがある</p>
<ul>
<li>entity&nbsp;extractionの失敗</li>
<li>文脈類似度を測るときのノイズ</li>
<li>例) 同音異義語が強くつながってしまう<ul>
<li>意味的な素性を使わずに類似度を測ってしまう</li>
<li>(意味が違うなら文脈も違う気もする&#8230;)</li>
</ul>
</li>
</ul>
<h2>制約</h2>
<p>二つのデータセットが、serendipitous&nbsp;searchに何をもたらしてくれるのか調べる</p>
<ul>
<li><span class="caps">YA</span>と<span class="caps">WP</span>における実験結果を比べる</li>
<li>どの素性が検索結果に影響するのか調べる<ul>
<li>このために、データセットからメタデータを抽出する</li>
<li>そして、sentimentality, quality, topical&nbsp;categoryの次元に対して、検索に制約をかける</li>
</ul>
</li>
</ul>
<p>制約をかけたネットワークと、制約をかけていないネットワークでの結果を比べる</p>
<h3>Topic</h3>
<p>Question: クエリに対してトピック的にコヒーレントなentityは良い結果をもたらすのか？
Constraint 1:&nbsp;entityは少なくとも1つ以上のクエリと同じトピックカテゴリに属さなければならない</p>
<h3>High/Low&nbsp;Sentimentalyty</h3>
<p>Question: より感情的な(感情的でない)entityは良い結果をもたらすのか？
Constraint 2(3): entityは中央値(0.6 for <span class="caps">YP</span>, 0 for&nbsp;<span class="caps">WP</span>)よりも高いsentimentalityでなければならない</p>
<h3>High/Low&nbsp;Readability</h3>
<p>Question: より読みやすい(読みにくい)entityは良い結果をもたらすのか？
Constraint 4(5): entityのreadabilityスコアは中央値(46 for <span class="caps">YA</span>, 41 for&nbsp;<span class="caps">WP</span>)でなければならない</p>
<h3>制約の結果</h3>
<ul>
<li>low-sentimentalityとlow-readabilityが負の影響を持っている</li>
</ul>
<h2>Serendipity</h2>
<ul>
<li>accuracy以外にも推薦エンジンの性能を測ることが重要である</li>
<li>serendipity = unexpectedness +&nbsp;relevance</li>
<li>baselineの結果に入っていない結果のrelの平均<ul>
<li>relはannotatorの判断（？）</li>
</ul>
</li>
<li>baseline<ul>
<li>Top:&nbsp;2つの商用検索エンジンの検索結果のうち、最も上位5位の検索結果に現れる回数が多いentity</li>
<li>Top Nwp:&nbsp;TopからqueryのWikipediaの記事を除いたもの。<span class="caps">WP</span>に対するバイアスを避けるため</li>
<li>Rel:&nbsp;2つの商用検索エンジンから提案される関連クエリから得られる結果のうち、頻度が高い上位5件のentity</li>
<li>Top+Rel: Top,&nbsp;Relの和集合</li>
</ul>
</li>
<li>Table 5: 各baselineに対する、各制約条件で計算されたserendipity<ul>
<li>topic-constrainedな条件ではすべてのbasline/datasetにおけるserendipityを上回っている</li>
<li><span class="caps">YA</span>は常に<span class="caps">WP</span>を上回っている</li>
<li><span class="caps">COM</span>が一番良いserendipityを出せる</li>
<li>括弧の中の値は各制約条件で提示されたすべての結果に対するunexpectedでrelaventな結果の割合<ul>
<li>baselineによって弾かれていたentityも含めたときの値</li>
</ul>
</li>
<li>これはだいたいserendipityと同じくらいの高さになっている<ul>
<li>つまり、最も強いbasline&nbsp;Rel+Topと比べた時でさえ、提案手法はすごい数のunexpectedでrelaventな結果を検索している</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>User-Perceived&nbsp;Quality</h2>
<ul>
<li>主観的な評価になるので、結果に値を入れるのでは無く、色々な条件での実験結果を比較する</li>
<li>順序付きリストの要素のペアワイズで比較する (順番はランダムに決める)<ul>
<li>最初のほうが良かった</li>
<li>二つ目のほうが良かった</li>
<li>両方だめだった</li>
</ul>
</li>
<li>reference result rankingを各次元に対して構築する<ul>
<li>ランキング結果の集合の和集合(?)</li>
</ul>
</li>
<li>各ペアは3人のannotatorにより評価される<ul>
<li>ほとんど重複がない時に評価するのは非常に手間がかかる</li>
<li>適切なランクを推定するために、すべての順序リスト中の要素のペアから比較するペアをサンプリングする<ul>
<li>votingによってreference result&nbsp;rankingにおける順位を決める</li>
<li>http://www.cs.cmu.edu/~callan/Papers/ecir11-jarguello.pdf</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Labeling</h3>
<ol>
<li>どちらの結果がよりクエリと関連しているか？</li>
<li>そのクエリに興味を持つ人がいたら、その人はこの結果に興味を持つと思うか？</li>
<li>あなたがそのクエリに興味がないとしても、この結果はおもしろいか？</li>
<li>そのクエリについてなにか新しいことを学んだか？</li>
</ol>
<h3>Table 6: ランキングの集合とreference ranking間のKendall&#8217;s&nbsp;tau-b</h3>
<ul>
<li>personal interest (Q3)とrelevance (Q1)の好みの割合の差を計算する時に、おもしろいけど必ずしもクエリと関連している必要のないentityを見つけた<ul>
<li>Oil Spill -&gt; Sweaters for&nbsp;Penguins</li>
<li>Robert Pattinson -&gt; Water for&nbsp;Elephants</li>
<li>Egypt -&gt; Ptolematic&nbsp;Kingdom</li>
</ul>
</li>
<li>専門的には似ているけど、面白くない例<ul>
<li>Egypt -&gt; Cairo&nbsp;Conference</li>
<li>Netflix -&gt; Blu-ray&nbsp;Disc</li>
</ul>
</li>
<li><span class="caps">YA</span>はreference&nbsp;rankに似た結果を出せている</li>
<li>Topical categoryはreferece&nbsp;rankingとの類似度を高めている</li>
<li>Sentiment <span class="amp">&amp;</span> Readabilityもreferece&nbsp;rankingとの類似度を高めている</li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2013-12-14T00:00:00+0800"></abbr> on <time datetime="2013-12-14" class="date" itemprop="datePublished">14 Dec 2013</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/11/read-naive-bayes-in-scikit-learn.html" title="scikit-learnのソースコードリーディング（ナイーブベイズ分類）" itemprop="url">scikit-learnのソースコードリーディング（ナイーブベイズ分類）</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/python.html" rel="tag">python</a> 
<a href="/blog/tags/machine_learning.html" rel="tag">machine_learning</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p>個人的にはプログラミングの勉強は写経が一番頭に入る気がする、ということで読んでいた。</p>
<h2>気になったところ</h2>
<p>データに正規分布を仮定したときのナイーブベイズ分類器について。&nbsp;平均を\(\mu\)、分散を\(\sigma^2\)としたときの正規分布は</p>
<p>\[
p(x;\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}&nbsp;\]</p>
<p>これのlogをとると、
\[
\begin{split}
\log p(x;\mu, \sigma^2) &amp;= \log \{\frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}\}&#92;
&amp;= -\frac{1}{2}\log (2\pi \sigma^2) - \frac{(x-\mu)^2}{2\sigma^2}
\end{split}&nbsp;\]</p>
<p>ナイーブベイズ分類器の対数尤度関数は、データがK次元ベクトルで表現されていて、それがN個あるとすると、</p>
<p>\[
\begin{split}
\log L(X, Y; \mu, \sigma) &amp;= \log(\prod_{n=1}^N p(\mathbf{x}_n, y_n))&#92;
<span class="amp">&amp;</span> = \log(\prod_{n=1}^N p(y_n)p(\mathbf{x}_n|y_n))&#92;
<span class="amp">&amp;</span> = \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \log p(\mathbf{x}_n|y_n)&#92;
<span class="amp">&amp;</span> = \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K\log p(x_{nk}|y_n)&#92;
<span class="amp">&amp;</span> = \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma_{y_nk}^2) - \frac{(x_{nk}-\mu_{y_nk})^2}{2\sigma_{y_nk}^2}\}
\end{split}&nbsp;\]</p>
<p>サンプル\(\mathbf{x}\)に対して出力される予測ラベル\(\hat{y}\)は</p>
<p>\[
\begin{split}
\hat{y} &amp;= \mathop{\arg\,\max}\limits_y \log p(\mathbf{x}, y)&#92;
&amp;= \mathop{\arg\,\max}\limits_y \log p(y)p(\mathbf{x}|y)&#92;
<span class="amp">&amp;</span> = \mathop{\arg\,\max}\limits_y \{\log p(y) + \sum_{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma_{yk}^2) - \frac{(x_k-\mu_{yk})^2}{2\sigma_{yk}^2}\}\}
\end{split}&nbsp;\]</p>
<p>対数尤度関数をnumpyに落とすと</p>
<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span><br /><span class="sd">sigma.shape = (n_classes, n_features)</span><br /><span class="sd">mu.shape = (n_classes, n_features)</span><br /><span class="sd">&quot;&quot;&quot;</span><br />&nbsp;<br /><span class="n">joint_log_likelihood</span> <span class="o">=</span> <span class="p">[]</span><br /><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">classes</span><span class="p">)):</span><br />    <span class="c"># 事前分布の対数</span><br />    <span class="n">log_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">class_piror</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><br />    <span class="c"># log p(x|y)の対数の初項</span><br />    <span class="n">log_gauss1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span><br />    <span class="c"># log p(x|y)の対数の第二項</span><br />    <span class="n">log_gauss2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span><br />    <span class="c"># クラスiの尤度のlogを取った値</span><br />    <span class="n">joint_log_likelihood</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_prior</span> <span class="o">+</span> <span class="n">log_gauss1</span> <span class="o">+</span> <span class="n">log_gauss2</span><span class="p">)</span><br /></pre></div><br /><figcaption>Python</figcaption></figure></div>

<p><br>&nbsp;となる。と思っていた。ところがscikit-learnのGaussianNBの該当箇所を見て見ると、</p>
<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="k">def</span> <span class="nf">_joint_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span><br />        <span class="n">X</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><br />        <span class="n">joint_log_likelihood</span> <span class="o">=</span> <span class="p">[]</span><br />        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)):</span><br />            <span class="n">jointi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_prior_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><br />            <span class="n">n_ij</span> <span class="o">=</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span> <span class="c"># np.piの前に2がない</span><br />            <span class="n">n_ij</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span><br />                                 <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]),</span> <span class="mi">1</span><span class="p">)</span><br />            <span class="n">joint_log_likelihood</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jointi</span> <span class="o">+</span> <span class="n">n_ij</span><span class="p">)</span><br /></pre></div><br /><figcaption>Python</figcaption></figure></div>

<p><br></p>
<p>数式の展開が間違えているのだろうか&#8230;。それとも2は必要ないのだろうか&#8230;。</p>
<h2>参考</h2>
<ul>
<li><a href="http://r9y9.github.io/blog/2013/07/28/naive-bayes-formulation/">Naive&nbsp;Bayesの復習（導出編）</a></li>
<li><a href="http://cs.nyu.edu/~dsontag/courses/ml12/slides/lecture17.pdf">Naïve Bayes&nbsp;Lecture17</a></li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2013-11-10T00:00:00+0800"></abbr> on <time datetime="2013-11-10" class="date" itemprop="datePublished">10 Nov 2013</time></div>
</article><!-- /.post -->
<br><br><br>

</section>

<div align="center">
<a class="next"
    href="/blog/pages/3/index.html">
    &laquo; Older
</a>
&nbsp;&nbsp;

<a class="prev"
    href="/blog/index.html">
    Newer &raquo;
</a></div>
        <br>
                        </article>

                <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-20414370-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>    </body>
</html>