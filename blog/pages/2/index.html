<!doctype html>
<html lang="ja">
    <head>
        <link href="http://fonts.googleapis.com/css?family=Anton" rel="stylesheet" type="text/css">
        <link href='http://fonts.googleapis.com/css?family=Inconsolata' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Bubblegum+Sans' rel='stylesheet' type='text/css'>
        <title>Blog
 | Now is better than never.</title>
        <meta charset="utf-8" />
        <link href='http://fonts.googleapis.com/css?family=Permanent+Marker' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="/media/css/font-awesome.css">
        <link rel="stylesheet" href="/media/css/style.css">
        <link rel="stylesheet" href="/media/css/pygments.css">
        <link rel="shortcut icon" href="/media/img/background.jpg">
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }
            });
        </script>
        <script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
        <!--[if lt IE 9]>
        <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js">
        </script>
        <![endif]-->
    </head>
    <body >
        <header>
            <hgroup>
              <h1>Now is better than never.</h1>
              <h3>Although never is often better than right now.</h3>
            </hgroup>
        </header>
        <nav>
                                <ul>
<li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/blog">Blog</a></li><li><a href="/blog/archive.html">Archive</a></li></ul>
        </nav>
        <article id="content">
                                            <section class="posts">

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/12/penguins-in-sweaters-or-serendipitous-entity-search-on-user-generated-content.html" title="Penguins in Sweaters, or Serendipitous Entity Search on User-generated Content (CIKM2013)メモ" itemprop="url">Penguins in Sweaters, or Serendipitous Entity Search on User-generated Content (CIKM2013)メモ</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/paper.html" rel="tag">paper</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p><a href="http://labs.yahoo.com/publication/penguins-in-sweaters-or-serendipitous-entity-search-on-user-generated-content/">proceeding</a>
slide: <a href="http://www.slideshare.net/mounialalmas/penguins-in-sweaters-or-serendipitous-entity-search-on-usergenerated-content">slideshare</a></p>
<h2>まとめ</h2>
<p><span class="caps">CIKM</span> 2013でBest paperを取った、著者が全員女性(<a href="http://labs.yahoo.com/news/ilaria-bordino-yelena-mejova-mounia-lalmas-awarded-best-paper-at-cikm-2013/">参考</a>)という、自分が今まで読んだ中でおそらく一番華やかな論文で、Yahoo Answersを知識源として、セレンディピティ (思ってもみなかったけど、クエリと関連していること) を感じる検索を提供する話。
何か新たな手法を提案した、というよりは、Yahoo&nbsp;Answersという知識源を使うことで、何か思ってもみなかったけど、面白い検索結果を提供できるんじゃないかな〜というアイディアを実際に試してみた、という感じだろうか。</p>
<p>以下、メモ。</p>
<h2>Why/when do penguins wear&nbsp;sweaters?</h2>
<ul>
<li>タスマニアで起きた原油漏れで体に油がついてしまったペンギンが、再び元の生活に戻れるようにするためのチャリティーソング (James GordonのSweaters for Penguins)<ul>
<li>羽毛に原油がつくことで断熱性が落ち、ペンギンが凍えてしまう</li>
<li>くちばしで羽毛に付いた原油を落とそうとすることで体を傷つけてしまう</li>
</ul>
</li>
</ul>
<h3>Serendipity</h3>
<p>役に立つんだけど、特に探していたわけではないもの。</p>
<h3>Entity&nbsp;Search</h3>
<p>この論文ではWikipediaとYahoo! Answersから抽出した、メタデータで情報を豊富にしたentityネットワークを基にentity-driven serendipitous search&nbsp;systemを作成する。</p>
<h2>この論文の焦点</h2>
<h3><span class="caps">WHAT</span></h3>
<p>ウェブコミュニティの知識源はどのようなentity間の関係を提供するのか？</p>
<h3><span class="caps">WHY</span></h3>
<p>そのような知識源がどのように面白く、セレンディピティなブラウジング経験に寄与するのか？</p>
<h2>データ</h2>
<h3>Yahoo!&nbsp;Answers</h3>
<ul>
<li>ごくわずかにまとめられた意見、ゴシップ、個人情報</li>
<li>観点が多様</li>
</ul>
<h3>Wikipedia</h3>
<ul>
<li>高品質の情報が整理されている</li>
<li>ニッチなトピックが豊富</li>
</ul>
<h2>Entity <span class="amp">&amp;</span> Relation&nbsp;Extraction</h2>
<h3>Entity:&nbsp;Wikipediaに記述されている概念</h3>
<p>1 テキストから表層形を識別し、
2&nbsp;Wikipediaのentityと紐付けして、</p>
<ul>
<li>文脈依存</li>
<li>文脈非依存な素性<ul>
<li>click&nbsp;log</li>
</ul>
</li>
</ul>
<p>3 Wikipediaのentityを、テキストとの関連度順に基いてランキングする&nbsp;(aboutnessスコア(34)を使ってランキングする)</p>
<h3>Reationship:&nbsp;tf/idfベクトルのコサイン類似度</h3>
<p>entityが現れるドキュメントを結合したものがベクトルで表される</p>
<h2>Dataset Features&nbsp;(Metadata)</h2>
<h3>Sentiment</h3>
<ul>
<li>SentiStrengthを用いてpositive <span class="amp">&amp;</span> negativeのスコアを計算する<ul>
<li>インフォーマルな英語の極性判定でstate-of-the-art</li>
<li>このままだと文書レベルでの極性判定<ul>
<li>文単位でpositive、negativeのスコアを割り当てて、それぞれの平均が文書単位の極性のスコアになる</li>
</ul>
</li>
<li>文書は複数のentityを含むことが多いのでentity単位での極性はうまく測れない</li>
<li>まずentityのそれぞれ前後10単語のウィンドウに対して極性のスコアを計算する</li>
</ul>
</li>
<li>attitudeとsentimentalityをウィンドウに対して計算する[Kucuktunc&#8216;12]<ul>
<li>attitude:&nbsp;positiveもしくはnegativeに対する傾向</li>
<li>sentimentality:&nbsp;極性の大きさ</li>
</ul>
</li>
<li>entityが現れるウィンドウのattitude,&nbsp;sentimentalityの平均値がentity単位の素性とする</li>
</ul>
<h3>Quality</h3>
<ul>
<li>可読性</li>
<li>Flesch Reading Ease score[14]<ul>
<li>スコアが高いほど理解するのが難しい</li>
<li>スコアが低いほど理解するのが易しい</li>
</ul>
</li>
<li>Fig1は二つのデータセットにおけるエンティティの可読性の分布</li>
</ul>
<h3>Topical&nbsp;Category</h3>
<ul>
<li>Yahoo Content Taxonomy<ul>
<li>Table&nbsp;2</li>
<li>二つのデータ・セット中の概念体型は使わない<ul>
<li>整合性をとるため</li>
<li>二つのデータセットにおける実験結果を比較するため</li>
</ul>
</li>
</ul>
</li>
<li><span class="caps">US</span>-Englishのニュース記事を使って訓練した分類器で文書分類する</li>
<li>entityレベルの素性にするため、そのentityが現れた文書に割り当てられたカテゴリのうち、頻度が高い上位3つのカテゴリを素性にする</li>
</ul>
<h2>Retrieval</h2>
<h3>Algorithm: Lazy Randomwalk with&nbsp;restart</h3>
<ul>
<li>self-loop probability: beta
他のノードへの伝搬を遅らせて、random walkの開始ノードの重要性をより高める<ul>
<li>先行研究にしたがって、beta = 0.9 [6,&nbsp;12]</li>
</ul>
</li>
<li>follow one of the out-links with probability: 1 - beta
エッジの重みに比例してrandom&nbsp;walkする</li>
<li>random jumpの確率は0 (alpha = 0)<ul>
<li>random&nbsp;jumpすると結果が悪くなるため</li>
</ul>
</li>
<li>反復の終了条件<ul>
<li>前回とのノルムの差が10^-6以下、もしくは30回反復した</li>
</ul>
</li>
</ul>
<h4>scoring&nbsp;method</h4>
<ul>
<li>popularなentityはどこにでも上位にランクされるのでこれらをフィルタリング</li>
</ul>
<h3>Testbed</h3>
<ul>
<li>2010~2011にGoogle Zeitgeistで最も検索されたクエリの中から、Wikipedia、Yahoo!&nbsp;Answersの文書中に共に現れる上位50件のクエリ</li>
</ul>
<h3>Precision @5,&nbsp;<span class="caps">MAP</span></h3>
<ul>
<li>Precision: 66.8% on <span class="caps">WP</span>, 72.4% on&nbsp;<span class="caps">YA</span></li>
<li><span class="caps">MAP</span>: 0.716 on <span class="caps">WP</span>, 0.762 on <span class="caps">YA</span>
ふたつのデータセットでの性能は同等であるものの、ランキングされるentityにはあまり重複がないため、二つのランキング結果を結合すると性能が上がる<ul>
<li>Fagin et al. [13]のrank&nbsp;aggregationを使う</li>
</ul>
</li>
</ul>
<h3>Annotator&nbsp;agreement</h3>
<ul>
<li>1つのクエリにつき、annotatorは3人<ul>
<li>クラウドソーシングしてるので、信頼出来ないannotatorは排除</li>
</ul>
</li>
<li>(overlap): 0.85%<ul>
<li>馴染みのないクエリはagreementが低い (Secosteroid, Sally Kern,&nbsp;&#8230;)</li>
</ul>
</li>
</ul>
<h3>Average overlap in top&nbsp;5</h3>
<ul>
<li>results: 12%<ul>
<li>= 0.6 entity/top 5&nbsp;entities</li>
</ul>
</li>
</ul>
<h3>Error&nbsp;analysis</h3>
<p>提案手法の有効性はクエリのentityのすぐとなりのentityをあまり上に挙げないことによる</p>
<ul>
<li>例) Egyptに最も近い二つのentity<ul>
<li>British Pacific Fleet, <span class="caps">FC</span> Groningen&nbsp;(<span class="caps">WP</span>)</li>
<li>Spring, <span class="caps">IGN</span>&nbsp;(<span class="caps">YA</span>)</li>
<li>Springは&#8221;Arab&nbsp;Spring&#8221;と間違えて識別された可能性があるが、このSpringは提案手法があまりEgyptの近くをみないので下位にランクされる</li>
</ul>
</li>
</ul>
<p>とても似通ったentityばかりが上位にランクされてしまうこともある</p>
<ul>
<li>例) インフルエンザのウィルス名、Mac PowerBookのバージョン名で上位がうまる<ul>
<li>random&nbsp;walk時に密度が高いサブグラフにトラップされてしまうことで起きる</li>
</ul>
</li>
</ul>
<p>entityは関連していないentityが近くに来ることがある</p>
<ul>
<li>entity&nbsp;extractionの失敗</li>
<li>文脈類似度を測るときのノイズ</li>
<li>例) 同音異義語が強くつながってしまう<ul>
<li>意味的な素性を使わずに類似度を測ってしまう</li>
<li>(意味が違うなら文脈も違う気もする&#8230;)</li>
</ul>
</li>
</ul>
<h2>制約</h2>
<p>二つのデータセットが、serendipitous&nbsp;searchに何をもたらしてくれるのか調べる</p>
<ul>
<li><span class="caps">YA</span>と<span class="caps">WP</span>における実験結果を比べる</li>
<li>どの素性が検索結果に影響するのか調べる<ul>
<li>このために、データセットからメタデータを抽出する</li>
<li>そして、sentimentality, quality, topical&nbsp;categoryの次元に対して、検索に制約をかける</li>
</ul>
</li>
</ul>
<p>制約をかけたネットワークと、制約をかけていないネットワークでの結果を比べる</p>
<h3>Topic</h3>
<p>Question: クエリに対してトピック的にコヒーレントなentityは良い結果をもたらすのか？
Constraint 1:&nbsp;entityは少なくとも1つ以上のクエリと同じトピックカテゴリに属さなければならない</p>
<h3>High/Low&nbsp;Sentimentalyty</h3>
<p>Question: より感情的な(感情的でない)entityは良い結果をもたらすのか？
Constraint 2(3): entityは中央値(0.6 for <span class="caps">YP</span>, 0 for&nbsp;<span class="caps">WP</span>)よりも高いsentimentalityでなければならない</p>
<h3>High/Low&nbsp;Readability</h3>
<p>Question: より読みやすい(読みにくい)entityは良い結果をもたらすのか？
Constraint 4(5): entityのreadabilityスコアは中央値(46 for <span class="caps">YA</span>, 41 for&nbsp;<span class="caps">WP</span>)でなければならない</p>
<h3>制約の結果</h3>
<ul>
<li>low-sentimentalityとlow-readabilityが負の影響を持っている</li>
</ul>
<h2>Serendipity</h2>
<ul>
<li>accuracy以外にも推薦エンジンの性能を測ることが重要である</li>
<li>serendipity = unexpectedness +&nbsp;relevance</li>
<li>baselineの結果に入っていない結果のrelの平均<ul>
<li>relはannotatorの判断（？）</li>
</ul>
</li>
<li>baseline<ul>
<li>Top:&nbsp;2つの商用検索エンジンの検索結果のうち、最も上位5位の検索結果に現れる回数が多いentity</li>
<li>Top Nwp:&nbsp;TopからqueryのWikipediaの記事を除いたもの。<span class="caps">WP</span>に対するバイアスを避けるため</li>
<li>Rel:&nbsp;2つの商用検索エンジンから提案される関連クエリから得られる結果のうち、頻度が高い上位5件のentity</li>
<li>Top+Rel: Top,&nbsp;Relの和集合</li>
</ul>
</li>
<li>Table 5: 各baselineに対する、各制約条件で計算されたserendipity<ul>
<li>topic-constrainedな条件ではすべてのbasline/datasetにおけるserendipityを上回っている</li>
<li><span class="caps">YA</span>は常に<span class="caps">WP</span>を上回っている</li>
<li><span class="caps">COM</span>が一番良いserendipityを出せる</li>
<li>括弧の中の値は各制約条件で提示されたすべての結果に対するunexpectedでrelaventな結果の割合<ul>
<li>baselineによって弾かれていたentityも含めたときの値</li>
</ul>
</li>
<li>これはだいたいserendipityと同じくらいの高さになっている<ul>
<li>つまり、最も強いbasline&nbsp;Rel+Topと比べた時でさえ、提案手法はすごい数のunexpectedでrelaventな結果を検索している</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>User-Perceived&nbsp;Quality</h2>
<ul>
<li>主観的な評価になるので、結果に値を入れるのでは無く、色々な条件での実験結果を比較する</li>
<li>順序付きリストの要素のペアワイズで比較する (順番はランダムに決める)<ul>
<li>最初のほうが良かった</li>
<li>二つ目のほうが良かった</li>
<li>両方だめだった</li>
</ul>
</li>
<li>reference result rankingを各次元に対して構築する<ul>
<li>ランキング結果の集合の和集合(?)</li>
</ul>
</li>
<li>各ペアは3人のannotatorにより評価される<ul>
<li>ほとんど重複がない時に評価するのは非常に手間がかかる</li>
<li>適切なランクを推定するために、すべての順序リスト中の要素のペアから比較するペアをサンプリングする<ul>
<li>votingによってreference result&nbsp;rankingにおける順位を決める</li>
<li>http://www.cs.cmu.edu/~callan/Papers/ecir11-jarguello.pdf</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Labeling</h3>
<ol>
<li>どちらの結果がよりクエリと関連しているか？</li>
<li>そのクエリに興味を持つ人がいたら、その人はこの結果に興味を持つと思うか？</li>
<li>あなたがそのクエリに興味がないとしても、この結果はおもしろいか？</li>
<li>そのクエリについてなにか新しいことを学んだか？</li>
</ol>
<h3>Table 6: ランキングの集合とreference ranking間のKendall&#8217;s&nbsp;tau-b</h3>
<ul>
<li>personal interest (Q3)とrelevance (Q1)の好みの割合の差を計算する時に、おもしろいけど必ずしもクエリと関連している必要のないentityを見つけた<ul>
<li>Oil Spill -&gt; Sweaters for&nbsp;Penguins</li>
<li>Robert Pattinson -&gt; Water for&nbsp;Elephants</li>
<li>Egypt -&gt; Ptolematic&nbsp;Kingdom</li>
</ul>
</li>
<li>専門的には似ているけど、面白くない例<ul>
<li>Egypt -&gt; Cairo&nbsp;Conference</li>
<li>Netflix -&gt; Blu-ray&nbsp;Disc</li>
</ul>
</li>
<li><span class="caps">YA</span>はreference&nbsp;rankに似た結果を出せている</li>
<li>Topical categoryはreferece&nbsp;rankingとの類似度を高めている</li>
<li>Sentiment <span class="amp">&amp;</span> Readabilityもreferece&nbsp;rankingとの類似度を高めている</li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2013-12-14T00:00:00+0800"></abbr> on <time datetime="2013-12-14" class="date" itemprop="datePublished">14 Dec 2013</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/11/read-naive-bayes-in-scikit-learn.html" title="scikit-learnのソースコードリーディング（ナイーブベイズ分類）" itemprop="url">scikit-learnのソースコードリーディング（ナイーブベイズ分類）</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/python.html" rel="tag">python</a> 
<a href="/blog/tags/machine_learning.html" rel="tag">machine_learning</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p>個人的にはプログラミングの勉強は写経が一番頭に入る気がする、ということで読んでいた。</p>
<h2>気になったところ</h2>
<p>データに正規分布を仮定したときのナイーブベイズ分類器について。&nbsp;平均を\(\mu\)、分散を\(\sigma^2\)としたときの正規分布は</p>
<p>\[
p(x;\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}&nbsp;\]</p>
<p>これのlogをとると、
\[
\begin{split}
\log p(x;\mu, \sigma^2) &amp;= \log \{\frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}\}&#92;
&amp;= -\frac{1}{2}\log (2\pi \sigma^2) - \frac{(x-\mu)^2}{2\sigma^2}
\end{split}&nbsp;\]</p>
<p>ナイーブベイズ分類器の対数尤度関数は、データがK次元ベクトルで表現されていて、それがN個あるとすると、</p>
<p>\[
\begin{split}
\log L(X, Y; \mu, \sigma) &amp;= \log(\prod_{n=1}^N p(\mathbf{x}_n, y_n))&#92;
<span class="amp">&amp;</span> = \log(\prod_{n=1}^N p(y_n)p(\mathbf{x}_n|y_n))&#92;
<span class="amp">&amp;</span> = \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \log p(\mathbf{x}_n|y_n)&#92;
<span class="amp">&amp;</span> = \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K\log p(x_{nk}|y_n)&#92;
<span class="amp">&amp;</span> = \sum_{n=1}^N \log p(y_n) + \sum_{n=1}^N \sum_{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma_{y_nk}^2) - \frac{(x_{nk}-\mu_{y_nk})^2}{2\sigma_{y_nk}^2}\}
\end{split}&nbsp;\]</p>
<p>サンプル\(\mathbf{x}\)に対して出力される予測ラベル\(\hat{y}\)は</p>
<p>\[
\begin{split}
\hat{y} &amp;= \mathop{\arg\,\max}\limits_y \log p(\mathbf{x}, y)&#92;
&amp;= \mathop{\arg\,\max}\limits_y \log p(y)p(\mathbf{x}|y)&#92;
<span class="amp">&amp;</span> = \mathop{\arg\,\max}\limits_y \{\log p(y) + \sum_{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma_{yk}^2) - \frac{(x_k-\mu_{yk})^2}{2\sigma_{yk}^2}\}\}
\end{split}&nbsp;\]</p>
<p>対数尤度関数をnumpyに落とすと</p>
<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span><br /><span class="sd">sigma.shape = (n_classes, n_features)</span><br /><span class="sd">mu.shape = (n_classes, n_features)</span><br /><span class="sd">&quot;&quot;&quot;</span><br />&nbsp;<br /><span class="n">joint_log_likelihood</span> <span class="o">=</span> <span class="p">[]</span><br /><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">classes</span><span class="p">)):</span><br />    <span class="c"># 事前分布の対数</span><br />    <span class="n">log_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">class_piror</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><br />    <span class="c"># log p(x|y)の対数の初項</span><br />    <span class="n">log_gauss1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span><br />    <span class="c"># log p(x|y)の対数の第二項</span><br />    <span class="n">log_gauss2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span><br />    <span class="c"># クラスiの尤度のlogを取った値</span><br />    <span class="n">joint_log_likelihood</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_prior</span> <span class="o">+</span> <span class="n">log_gauss1</span> <span class="o">+</span> <span class="n">log_gauss2</span><span class="p">)</span><br /></pre></div><br /><figcaption>Python</figcaption></figure></div>

<p><br>&nbsp;となる。と思っていた。ところがscikit-learnのGaussianNBの該当箇所を見て見ると、</p>
<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="k">def</span> <span class="nf">_joint_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span><br />        <span class="n">X</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><br />        <span class="n">joint_log_likelihood</span> <span class="o">=</span> <span class="p">[]</span><br />        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)):</span><br />            <span class="n">jointi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_prior_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><br />            <span class="n">n_ij</span> <span class="o">=</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span> <span class="c"># np.piの前に2がない</span><br />            <span class="n">n_ij</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span><br />                                 <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]),</span> <span class="mi">1</span><span class="p">)</span><br />            <span class="n">joint_log_likelihood</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jointi</span> <span class="o">+</span> <span class="n">n_ij</span><span class="p">)</span><br /></pre></div><br /><figcaption>Python</figcaption></figure></div>

<p><br></p>
<p>数式の展開が間違えているのだろうか&#8230;。それとも2は必要ないのだろうか&#8230;。</p>
<h2>参考</h2>
<ul>
<li><a href="http://r9y9.github.io/blog/2013/07/28/naive-bayes-formulation/">Naive&nbsp;Bayesの復習（導出編）</a></li>
<li><a href="http://cs.nyu.edu/~dsontag/courses/ml12/slides/lecture17.pdf">Naïve Bayes&nbsp;Lecture17</a></li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2013-11-10T00:00:00+0800"></abbr> on <time datetime="2013-11-10" class="date" itemprop="datePublished">10 Nov 2013</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/9/acl2013-summ-note.html" title="文書要約メモ（ACL2013）" itemprop="url">文書要約メモ（ACL2013）</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/nlp.html" rel="tag">nlp</a> 
<a href="/blog/tags/paper.html" rel="tag">paper</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p><a href="http://aclweb.org/anthology//P/P13/">acl anthology</a>よりロングペーパーとして&nbsp;採択された論文の中からSummarizationをタイトルに含む論文を探して概要だけを読んだときのメモ。</p>
<h1>Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning&nbsp;(P13-1020.pdf)</h1>
<h2>概要</h2>
<ul>
<li>複数文書要約のための文選択、文圧縮を同時におこなうモデルを使った双対分解を提案。</li>
<li>先行研究のIneger Linear Programmingに基づいた手法と比べると<ul>
<li>提案手法はソルバーを必要としない</li>
<li>提案手法は有意に速い</li>
<li>提案手法は簡潔さ・情報の豊富さ・文法のきれいさが優れている</li>
</ul>
</li>
<li>さらに既存の抽出型要約、文圧縮の要約データを活用したマルチタスク学習を提案する</li>
<li><span class="caps">TAC2008</span>のデータで実験をおこなって今までで一番高い<span class="caps">ROUGE</span>値となった。</li>
</ul>
<h1>Using Supervised Bigram-based <span class="caps">ILP</span> for Extractive Summarization&nbsp;(P13-1099.pdf)</h1>
<h2>概要</h2>
<ul>
<li>Integer Linear&nbsp;Programmingによる抽出型文書要約において、bigramの重みを教師有り学習により推定する</li>
<li>regression&nbsp;modelによってbigramが参照要約の中でどれくらいの頻度で出現するかを推定。</li>
<li>学習では、参照要約中での真の頻度との距離が最小になるように学習をする</li>
<li>選択されるbigramの重みの総和が最大になるように文選択をおこなうような定式化をしている</li>
<li>提案手法は既存の<span class="caps">ILP</span>な手法と比べて<span class="caps">TAC</span>のデータにおいて良い性能であることと、<span class="caps">TAC</span>のbestだったシステムとの比較結果を示す</li>
</ul>
<h1>Summarization Through Submodularity and Dispersion&nbsp;(P13-1100.pdf)</h1>
<h2>概要</h2>
<ul>
<li>Linらのサブモジュラな手法を一般化することにより新たな最適化手法を提案する</li>
<li>提案手法では要約にとって欲しい情報はサブモジュラ関数と非サブモジュラ関数の総和で表される。この関数をdispersionと呼ぶ</li>
<li>非サブモジュラ関数は要約の冗長性を除くために文同士の様々な似ていなさの度合いを図るために使う</li>
<li>三つのdispersion関数を使って、全部の場合で貪欲法を使っても最適解が得られることを示す</li>
<li><span class="caps">DUC</span>&nbsp;2004とニュース記事に対するユーザのコメントを使って実験</li>
<li>サブモジュラ関数だけを使ったモデルよりも良い性能であることを示す</li>
</ul>
<h1>Subtree Extractive Summarization via Submodular Maximization&nbsp;(P13-1101.pdf)</h1>
<h2>概要</h2>
<ul>
<li>@Pnnc205jさんの論文</li>
</ul>
<h1>Towards Robust Abstractive Multi-Document Summarization: A Caseframe Analysis of Centrality and Domain&nbsp;(P13-1121.pdf)</h1>
<h2>概要</h2>
<ul>
<li>文書要約において中心性とは元の文書の核となる部分を含むべきだということ</li>
<li>既存の手法は冗長性を除いたり文圧縮をおこなうことで中心性を得ようと試みている</li>
<li>この論文では元文書のドメインを活用することで文書要約が、抽象型要約に向けてどれくらいこのようなパラダイムから前進できるかを調査する</li>
<li>実験ではcaseframeという意味的なレベルで人手の要約とシステムの要約の近さを図る</li>
<li>提案手法は<ul>
<li>より抽象的で、文のまとめあげをおこなう</li>
<li>topicalなcaseframeを他のシステムほど含まない</li>
<li>元文書だけから再構築はできないけど、同じドメインの文書を加えればできる</li>
</ul>
</li>
<li>実験結果は、本質的な改善は中心性を最適化するための式を作ることよりも、ドメイン知識が必要であることを示唆している</li>
</ul>
<h1>A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization&nbsp;(P13-1136.pdf)</h1>
<h2>概要</h2>
<ul>
<li>クエリ指向型複数文書要約のための文圧縮を使った手法を提案する</li>
<li>構文木に基づく文圧縮モデル</li>
<li>ビームサーチのデコーダを提案。効率的、高圧縮。</li>
<li>圧縮するためのスコア関数にどうやって言語的な特徴やクエリとの関連性を組み込むのかを示す</li>
<li><span class="caps">DUC</span> 2006, <span class="caps">DUC</span>&nbsp;2007のstate-of-the-artよりも有意によくなることを示す</li>
</ul>
<h1>Domain-Independent Abstract Generation for Focused Meeting Summarization&nbsp;(P13-1137.pdf)</h1>
<h2>概要</h2>
<ul>
<li>ドメイン知識を使わずに会議の対話ログの抽象型要約をおこなう</li>
<li>Multiple-Squence&nbsp;Alignmentという他のドメインにも使いまわせる抽象的な要約のテンプレートを使う</li>
<li>Overgenerate-and-Rankというものを候補の生成、ランキングに使うらしい</li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2013-09-30T00:00:00+0800"></abbr> on <time datetime="2013-09-30" class="date" itemprop="datePublished">30 Sep 2013</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/9/diversity-maximization-under-matroid-constraints.html" title="Diversity Maximization Under Matroid Constraints (KDD 2013)を読んだ" itemprop="url">Diversity Maximization Under Matroid Constraints (KDD 2013)を読んだ</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/paper.html" rel="tag">paper</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p><span class="caps">KDD</span> 2013読み会に参加させていただきました。
せっかくなのでと思い論文を読んで発表してきた。
主催してくださった@y_benjoさん、会場を提供してくださったGunosy Inc.さん、ありがとうございます。
これまであまり外部の勉強会で発表する機会が無かったので少し緊張したけどその緊張感はとてもよい感じだった。&nbsp;個人的には参加者数が多すぎず少なすぎなかったのが良かった。</p>
<h2>読んだ論文</h2>
<p>Diversity Maximization Under Matroid Constraints, Zeinab Abbassi, Vahab S. Mirrokni and Mayur Thakur, <span class="caps">KDD</span>&nbsp;2013</p>
<p>proceeding (<a href="http://delivery.acm.org/10.1145/2490000/2487636/p32-thakur.pdf?ip=119.72.198.210&amp;id=2487636&amp;acc=OA&amp;key=BF13D071DEA4D3F3B0AA4BA89B4BCA5B&amp;CFID=172417999&amp;CFTOKEN=20689885&amp;__acm__=1378782056_5a16e280ca3058cd06f535a4740ad6be">pdf</a>)</p>
<p>ニュース配信サービスがいかに小さくて多様なニュース記事を提示するかという話。
カテゴリに対してたかだかp個ずつニュース記事を選択してdiversityを最大化するのだけど、その制約をpartition matroidで表現している。&nbsp;記事集合の選択にはdiversityがある程度上がるなら文書をどんどん入れ替えるgreedyなアプローチをとっているのだけど、最悪でも一番高いdiversityの1/2以上であることを保証してくれる。</p>
<p>ペアワイズの距離を定義して、その総和をdiversityとしているのだけどそのペアワイズの距離が少し変わった形をしている。
これは1/2近似であることを証明する時に必要な性質をもっているため。
この式をgeneralized Jaccard distanceと呼んでいて、重み付きの要素をもつ集合間の距離を測るときに用いることができる。
今まで見たことがなかったのだけど、（この式はよくあるものなのかという質問もいただき）調べてみたら<a href="http://theory.stanford.edu/~sergei/papers/soda10-jaccard.pdf">他の論文</a>でもJaccard距離の一般的な表現として登場しているのでこの論文で定義されたものではないみたい。</p>
<p>人手の評価もおこない、diversityを考慮しない場合よりもdiversityを考慮した文書集合の方が観たいと答えた人の割合が多いという結果になった。</p>
<p>関数の定義が書かれていなかったり、average&nbsp;distanceと書いてある評価指標が距離の総和を取っているだけの式に見えたり、Googleの中の人じゃないと分からないことを書いていたり、読むときに少し障壁を感じた。</p>
<h2>発表資料</h2>
<p><div align="center">
<iframe class="scribd_iframe_embed" src="//www.scribd.com/embeds/166900012/content?start_page=1&view_mode=slideshow&access_key=key-2nk8dys4z67mwblosm6o&show_recommendations=false" data-auto-height="false" data-aspect-ratio="1.29971181556196" scrolling="no" id="doc_26933" width="610" height="500" frameborder="0"></iframe>
</div></p>
<h2>議論</h2>
<p>大事なことだと思ったので発表時に頂いたコメントを自分なりにまとめた。&nbsp;自分の解釈が間違っているかもしれないので、もし間違っていたらご指摘ください。</p>
<ul>
<li>diversityに価値があることはなんとなくわかるけど、diversityを考慮していないものと考慮したものを比べても意味ないのでは</li>
<li>diversityを良くしたら本当にユーザにとってためになるものが提供できるのか<ul>
<li>極論するとランダムな文書集合で満足するユーザがいるかもしれない</li>
</ul>
</li>
<li>diversityにも色々あるし、diversityの良さは人によって違うのでは<ul>
<li>色々なdiversityと人間の評価の相関とか調べると面白いかも</li>
</ul>
</li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2013-09-10T00:00:00+0800"></abbr> on <time datetime="2013-09-10" class="date" itemprop="datePublished">10 Sep 2013</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2013/8/active-sampling-for-entity-matching.html" title="Active Sampling for Entity Matching (KDD 2012)を読んだ" itemprop="url">Active Sampling for Entity Matching (KDD 2012)を読んだ</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/paper.html" rel="tag">paper</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p>proceeding (<a href="http://ilpubs.stanford.edu:8090/1036/1/main.pdf">pdf</a>),
slide (<a href="http://shrdocs.com/presentations/9266/index.html">html</a>),
journal (<a href="http://ilpubs.stanford.edu:8090/1056/1/acmsmall-main.pdf">pdf</a>)</p>
<p><span class="caps">KDD</span> 2012の時点では元々Yahoo! Researchにいた著者らがjournalでは所属がみんなばらばらになっているので興味があって調べてみたけど、
マリッサ・メイヤーのYahoo! <span class="caps">CEO</span>就任は<a href="http://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%AA%E3%83%83%E3%82%B5%E3%83%BB%E3%83%A1%E3%82%A4%E3%83%A4%E3%83%BC">2012年7月17日</a>、<span class="caps">KDD</span> 2012は<a href="http://kdd2012.sigkdd.org/">2012年8月中旬</a>、
おそらくその後にjournalを出しているのでマリッサ・メイヤーの就任は転職に影響したのだろうかという
余計な詮索をしていた。
journalのpublish dateはMarch 2010となっているけどreferenceにはそれ以降の論文もあるし、&nbsp;これは2010に出たjournalではないらしくて時系列がどうなっているのか混乱した。</p>
<h2>概要</h2>
<p>entity matchingでは正例に対して負例がとても多く、学習にはprecisionがしきい値以上であるような
制約を満たすようにrecallを最大化するactive learningアルゴリズムが提案されている。
ただ先行研究のアルゴリズムはlabel complexity、computational complexityともに高いので
提案手法では近似的にprecision制約付きのrecall問題を解く方法を提案してそれが先行研究&nbsp;に比べて早く、しかも精度もよく学習できることを示している。</p>
<h2>発表資料</h2>
<div align="center">
<iframe class="scribd_iframe_embed" src="http://www.scribd.com/embeds/157827725/content?start_page=1&view_mode=slideshow&access_key=key-1si7srgey3zm82empzuw&show_recommendations=false" data-auto-height="false" data-aspect-ratio="1.29971181556196" scrolling="no" id="doc_66221" width="700" height="500" frameborder="0"></iframe>
</div>

<p>以下メモ。</p>
<h2>Convex hull&nbsp;algorithm</h2>
<p><div align="center">
    <img src="http://farm6.staticflickr.com/5547/9425716409_040e6eba48.jpg" width="500" height="375">
</div>
precisionの制約付きrecall最大化問題を解きたいのだけど、制約があると面倒なのでラグランジュの未定乗数法
のようにして問題から制約を取り除く。
また分類器の空間Hは次元数に対して指数的に増加するのでそこで探索するのを避けて、分類器を
recall、precisionの空間に写像して、写像した空間P={(X(h), y(h)):h∈H}で探索をおこなう。
探索には二分探索を用い反復的に0-1 lossを最小化する問題をactive learningアルゴリズムによって解いている。
ここで、active learningはどんなものでも良くてblack&nbsp;boxとして扱うことが出来る。</p>
<h2>Rejection sampling&nbsp;algorithm</h2>
<p>black boxの学習をおこなう前に呼び出されるアルゴリズム。
気持ちを理解するには<a href="http://www.machinedlearnings.com/2012/01/cost-sensitive-binary-classification.html">Machined Learnings: Cost-Sensitive Binary Classification and Active Learning</a>が詳しい。
要約すると分類器の学習にはfalse positiveやfalse nagativeに対してどちらをより優先して
少なくするような重み付けをした目的関数を最適化する方法があるのだが、この重みはラベル
が付いていないサンプルに関しては人間にラベルの問い合わせをおこなわないとできない (正解
が正例、 負例のどちらかがわからないとα、1-αのどちらを掛けたらよいか決められない) 。
今の状況では、active learningのアルゴリズムがラベルの問い合わせをおこなったサンプル
についてのみ正解のラベルがわかっている。そこで、ラベルの問い合わせをしたサンプルのみ
正例の場合は確率α、負例の場合は確率1-αで訓練データとして扱い、そうでなければ棄却をする。&nbsp;棄却されなかったサンプルの集合の期待値を計算するともとの目的関数と同じになる。</p>
<p>この方法はラベルがわかっている場合には馬鹿馬鹿しい方法に見えるけど、ラベルが一部しか&nbsp;見えない場合には現実的な方法である。</p>
<h2>合わせて読みたい</h2>
<p><a href="http://conditional.github.io/blog/2013/08/03/joint-modeling-of-a-matrix-with-associated-text-via-latent-binary-features/">コンピュータが政治をする時代(あるいは，行列とテキストの結合モデル)について - a lonely&nbsp;miner</a></p>
</div>

<div>Posted <abbr class="timeago" title="2013-08-03T00:00:00+0800"></abbr> on <time datetime="2013-08-03" class="date" itemprop="datePublished">03 Aug 2013</time></div>
</article><!-- /.post -->
<br><br><br>

</section>

<div align="center">
<a class="next"
    href="/blog/pages/3/index.html">
    &laquo; Older
</a>
&nbsp;&nbsp;

<a class="prev"
    href="/blog/index.html">
    Newer &raquo;
</a></div>
        <br>
                        </article>

                <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-20414370-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>    </body>
</html>