<!doctype html>
<html lang="ja">
    <head>
        <link href="http://fonts.googleapis.com/css?family=Anton" rel="stylesheet" type="text/css">
        
<title>tma15.com</title>

        <meta charset="utf-8" />
        <link rel="stylesheet" href="/media/css/style.css">
        <link rel="stylesheet" href="/media/css/pygments.css">
        <link rel="shortcut icon" href="/media/img/background.jpg">
        <!--[if lt IE 9]>
        <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js">
        </script>
        <![endif]-->
    </head>
    <body id="blog">
        <header>
            <hgroup>
              <h1>Now is better than never.</h1>
              <h3>Although never is often better than right now.</h3>
            </hgroup>
        </header>
        <nav>
                                <ul>
<li><a href="/index.html">Home</a></li><li><a href="/about/index.html">About</a></li><li><a href="/blog/index.html">Blog</a></li></ul>
        </nav>
        <article id="content">
        
            <h1><a href="http://tma15.github.com/blog/2013/3/scalable-coordinate-descent-approaches-to-parallel-matrix-factorization-for-recommender-systems.html" class="title"><font color="white">Scalable Coordinate Descent Approaches to Parallel Matrix Factorization for Recommender Systems (ICDM 2012)</font></a></h1>
<p>proceeding: <a href="http://www.cs.utexas.edu/~cjhsieh/icdm-pmf.pdf">pdf</a></p>
<p>発表資料</p>
<iframe class="scribd_iframe_embed" src="http://www.scribd.com/embeds/131932827/content?start_page=1&view_mode=slideshow&access_key=key-hgbknpzu7xixmb9bkaf" data-auto-height="false" data-aspect-ratio="1.29971181556196" scrolling="no" id="doc_16367" width="700" height="550" frameborder="0"></iframe>

<p>2013-03-23</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/giving-presentaions.html" class="title"><font color="white">Giving presentations</font></a></h1>
<p><a href="http://www.amazon.co.jp/Writing-Computer-Science-Justin-Zobel/dp/1852338024">Writing for Computer Science</a> のメモ</p>
<iframe class="scribd_iframe_embed" src="http://www.scribd.com/embeds/126837452/content?start_page=1&view_mode=slideshow&access_key=key-18r6gyvswmhjnapds9dz" data-auto-height="false" data-aspect-ratio="1.29936305732484" scrolling="no" id="doc_32667" width="700" height="550" frameborder="0"></iframe>

<p>2013-02-23</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/robust-disambiguation-of-named-entities-in-text.html" class="title"><font color="white">Robust Disambiguation of Named Entities in Text (EMNLP 2011)</font></a></h1>
<p>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Furstenau, Manfred Pinkal,
Marc Spaniol, Bilyana Taneva, Stefan Thater, Gerhard Weikum</p>
<p>proceeding: <a href="http://www.aclweb.org/anthology-new/D/D11/D11-1072.pdf">pdf</a></p>
<h2>解いている問題</h2>
<ul>
<li>Named entity disambiguationをする</li>
<li>Collective disambiguationは、意味的に似た文脈に現れるentityを含むmentionがあるときにはうまくいく</li>
<li>mentionが短かったり、あまり関連しないトピックについてのものだとうまくいかない
<ul></li>
<li>e.g. MadridでManchesterとBarcelonaの試合があった</li>
<li>Madridは本当はLOCATIONだけど、ORGANIZATIONと判定される
</ul></li>
</ul>
<h2>アプローチ</h2>
<ul>
<li>priorとcontext similarityとcoherenceの3つの要素の線形結合からなる関数をもとに、重み付きエッジからなるグラフをつくる
<ul></li>
<li>priorは、mentionに含まれる表現が一般的にentity e_jである確率</li>
<li>context similarityはmentionとentityの文脈類似度</li>
<li>coherenceは他のmentionのentityとの意味的な近さ
<ul></li>
<li>Wikipediaの二つの記事にともにリンクを張っている記事の数をもとにした指標
</ul>
</ul></li>
<li>グラフの中からサブグラフを選択
<ul></li>
<li>サブグラフは、一つのmentionが一つのentityとエッジをもつ</li>
<li>サブグラフは、ノードに貼られたエッジの重みの総和(weigted degree)の最小値を最大化するようにつくる</li>
<li>サブグラフに含まれるエッジの重みの総和を最大化するシンプルな戦略は支配的なentityがあるとうまくいかない
<ul></li>
<li>Michael Jordanみたいな支配的なentityがあるとlong tailに位置するentity disambiguationがうまくいかない
</ul>
</ul></li>
<li>サブグラフの選択は、NP困難なので近似的なアルゴリズムをつかって問題を解く</li>
<li>アルゴリズムは反復的にweighted degreeが小さなentity nodeを削除する</li>
<li>
<p>ただし、必ずすべてのmentionがいずれかのentityとエッジを一つ持つようにする
<ul>
こうすると準最適な解に陥ることがあるので前処理でmentionとの距離が遠いentityは削除
</ul></p>
</li>
<li>
<p>prior, context similarity, coherenceの3つの要素をうまいこと使ってrobustなモデルになっているらしい</p>
</li>
</ul>
<p>2013-02-16</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/togakushi.html" class="title"><font color="white">Togakushi</font></a></h1>
<p><a href="http://www.flickr.com/photos/85431668@N05/8466317921/" title="Untitled by tma15, on Flickr"><img src="http://farm9.staticflickr.com/8521/8466317921_d1a2397cfd_c.jpg" width="800" height="800" alt="Untitled"></a></p>
<p>2013-02-12</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/joint-inference-of-named-entity-recognition-and-normalization-for-tweets.html" class="title"><font color="white">Joint Inference of Named Entity Recognition and Normalization for Tweets (ACL 2012)</font></a></h1>
<p>Xiaohua Liu, Ming Zhou, Furu Wei, Zhongyang Fu, Xiangyang Zhou</p>
<p>proceeding: <a href="http://www.aclweb.org/anthology-new/P/P12/P12-1055.pdf">pdf</a></p>
<h2>解いている問題</h2>
<p>tweet (英語のtweetに限定) の集合が与えられたときに</p>
<ul>
<li>tweetに対して固有表現を指しているテキストを同定し，あらかじめ決められたラベル  を割り当てる．</li>
<li>これらの同定されたテキストに対して名寄せをおこなう．
<ul></li>
<li>名寄せは，一番単語数が多い表現にまとめる</li>
<li>最大の単語数の表現が複数あればWikipediaにある表現を採用</li>
<li>PERSONと識別された三つの表現"Gaga", "Lady Gaaaga", "Lady Gaga"は"Lady Gaga"にまとめる．
</ul></li>
</ul>
<h2>アプローチ</h2>
<ul>
<li>固有表現認識 (NER) モデルの学習の際に，固有表現の名寄せ (NEN) モデルの学習も同時に行うことでお互いの精度を上げる
<ul></li>
<li>tweetは，エンティティに対していろいろな表現をされる．</li>
<li>e.g. "Anne Gronloh"というエンティティには"Mw.,Gronloh", "Anneke Kronloh", "Mevrouw G"など
</ul></li>
<li>"... Alex's jokes. ..."と"... Alex Russo was like..."という二つのtweet
<ul></li>
<li>NERモデルにより"Alex"と"Alex Russo"がともにPERSONであることが識別できれば，NENモデルは"Alex"を"Alex Russo"に名寄せできる．
</ul></li>
<li>" ... she knew Burger King when ..."と".. I'm craving all sorts of food: mcdonalds, burger king, ..."という二つのtweet
<ul></li>
<li>NENモデルが"Burger King"と'burger king"が別のエンティティを指していると識別できればNERモデルはこれらに異なるラベルを割り当てられる．
</ul></li>
<li>学習にはCRFを用いる
<ul></li>
<li>skip-chain CRFと似たモデルだけど，tweet mのi番目の単語とtweet nのj番目の単語が同じエンティティを指しているかを表すnormalization変数があるのが違う．</li>
<li>ラベルは</li>
<li>一つ目のtweetに含まれる"Gaga"と二つ目のtweetに含まれる"Lady Gaga"にPERSONが割り当てられ，一つ目のtweetに含まれる"Gaga"と二つ目のtweetに含まれる"Gaga"が同一のエンティティを指していると識別できれば"Gaga"と"Lady Gaga"は同じものを指している</li>
<li>(CRFの復習) 重みを更新するときの，対数裕度関数を重み変数λで偏微分したときに二つの項がでてくる．</li>
<li>初項は正解となるラベルが与えられたときの，素性関数kの訓練データに対しての合計値</li>
<li>第二項は現在のパラメータによって決定されるモデルによる素性関数kの期待値の合計値</li>
<li>初項が第二項よりも大きいほど，重みλ_kは大きくなるし，初項が第二項よりも小さいほど重みλ_kは小さくなる．</li>
<li>skip-chainなので，素性関数は隣り合ったラベルの組み合わせに加えて，隣り合っていないラベルの組み合わせも見ることができるし，このモデルでは他のツイートの単語につくラベルとの関係も見る．
</ul></li>
</ul>
<p><strong>複数のtweetを同時に考慮することの利点</strong></p>
<ul>
<li>"... Bobby Shaw you don't invite the wind..."と"... I own yah! Loool bobby shaw..."
<ul></li>
<li>"Bobby Shaw"をPERSONと識別することは比較的簡単．</li>
<li>一つ目のtweetの"you"が，二つ目のtweetの'bobby shaw"がPERSONであることの手がかりとなる．
</ul></li>
</ul>
<p><strong>ラベルの候補の絞り込み</strong></p>
<ul>
<li>外部資源から固有表現を取ってきて辞書を作っておく．</li>
<li>tweetの中に，辞書に含まれる固有表現の一部と一致していれば，ラベルの候補の集合へその固有表現のラベルを加える
<ul></li>
<li>"new york"という句が出てきたとき，辞書にある"New York City"と"New York Times"と一致する．</li>
<li>"new"には，"B-LOCATION", "B-ORGANIZATION"，"york"には"I-LOCATION", "I-ORGANIZATION"がラベルの候補の集合にそれぞれ追加される．
</ul></li>
<li>ラベルの候補の集合へひとつでもラベルが追加されていれば，y^i_mはこのラベルの候補の集合のみしか考えない</li>
</ul>
<p><strong>normalization変数zもルールである程度決めてしまう</strong></p>
<ul>
<li>同じtweet mで，表層的に同じ語があれば，それらは同じエンティティについて述べていると考え，z^_=1とする．</li>
<li>tweet mとtweet nのcos類似度が0.8以上なら，すべてi, jに対してのz^_=1</li>
<li>tweet mとtweet nのcos類似度が0.3以下なら，すべてi, jに対してのz^_=0</li>
</ul>
<p><strong>素性</strong></p>
<ul>
<li>大文字かどうか，接頭辞，接尾辞，ストップワードかどうかなど</li>
<li>基本形，out-of-vocabularyかどうか，ハッシュタグかどうかなど</li>
<li>ラベル候補の絞り込み時にラベル候補の集合に何か追加されているかどうか，一番追加されているラベルは何か</li>
</ul>
<h2>感想・疑問点</h2>
<ul>
<li>Discussionで，エラーの大半がスラング，略語だと書かれているけど，これを解決することで提案手法がTwitterのデータを扱う上での強みとなりそうだと思った．</li>
</ul>
<p>2013-02-06</p>

<p><br><br><div class="bottom_article_nav">
<div class="prev"> &lt;<a href="http://tma15.github.com/blog/page/2/index.html">older</a></div>
</div>
<div class="center"><a href="/blog/archive.html">archives</a></div></p>
            <p></p>

            
        </article>

        <aside>
        <p>Created by <a href="http://tma15.github.com">tma15</a></p>
        </aside>

                    </body>
</html>