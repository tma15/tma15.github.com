<!doctype html>
<html lang="en">
    <head>
        <link href="http://fonts.googleapis.com/css?family=Anton" rel="stylesheet" type="text/css">
        <title>tma15.com </title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="/media/css/style.css">
        <link rel="stylesheet" href="/media/css/pygments.css">
        <link rel="shortcut icon" href="/media/img/background.jpg">
        <!--[if lt IE 9]>
        <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js">
        </script>
        <![endif]-->
    </head>
    <body id="blog">
        <header>
            <hgroup>
              <h1>Now is better than never.</h1>
              <h3>Although never is often better than right now.</h3>
            </hgroup>
        </header>
        <nav>
                                <ul>
<li><a href="/index.html">Home</a></li><li><a href="/about/index.html">About</a></li><li><a href="/blog/index.html">Blog</a></li></ul>
        </nav>
        <article id="content">
        
            <h1><a href="http://tma15.github.com/blog/2013/2/giving-presentaions.html" class="title"><font color="white">Giving presentations</font></a></h1>
<p><a href="http://www.amazon.co.jp/Writing-Computer-Science-Justin-Zobel/dp/1852338024">Writing for Computer Science</a> のメモ</p>
<iframe class="scribd_iframe_embed" src="http://www.scribd.com/embeds/126837452/content?start_page=1&view_mode=slideshow&access_key=key-18r6gyvswmhjnapds9dz" data-auto-height="false" data-aspect-ratio="1.29936305732484" scrolling="no" id="doc_32667" width="600" height="500" frameborder="0"></iframe>

<p>2013-02-23</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/robust-disambiguation-of-named-entities-in-text.html" class="title"><font color="white">Robust Disambiguation of Named Entities in Text (EMNLP 2011)</font></a></h1>
<p>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Furstenau, Manfred Pinkal,
Marc Spaniol, Bilyana Taneva, Stefan Thater, Gerhard Weikum</p>
<p>proceeding: <a href="http://www.aclweb.org/anthology-new/D/D11/D11-1072.pdf">pdf</a></p>
<h2>解いている問題</h2>
<ul>
<li>Named entity disambiguationをする</li>
<li>Collective disambiguationは、意味的に似た文脈に現れるentityを含むmentionがあるときにはうまくいく</li>
<li>mentionが短かったり、あまり関連しないトピックについてのものだとうまくいかない
<ul></li>
<li>e.g. MadridでManchesterとBarcelonaの試合があった</li>
<li>Madridは本当はLOCATIONだけど、ORGANIZATIONと判定される
</ul></li>
</ul>
<h2>アプローチ</h2>
<ul>
<li>priorとcontext similarityとcoherenceの3つの要素の線形結合からなる関数をもとに、重み付きエッジからなるグラフをつくる
<ul></li>
<li>priorは、mentionに含まれる表現が一般的にentity e_jである確率</li>
<li>context similarityはmentionとentityの文脈類似度</li>
<li>coherenceは他のmentionのentityとの意味的な近さ
<ul></li>
<li>Wikipediaの二つの記事にともにリンクを張っている記事の数をもとにした指標
</ul>
</ul></li>
<li>グラフの中からサブグラフを選択
<ul></li>
<li>サブグラフは、一つのmentionが一つのentityとエッジをもつ</li>
<li>サブグラフは、ノードに貼られたエッジの重みの総和(weigted degree)の最小値を最大化するようにつくる</li>
<li>サブグラフに含まれるエッジの重みの総和を最大化するシンプルな戦略は支配的なentityがあるとうまくいかない
<ul></li>
<li>Michael Jordanみたいな支配的なentityがあるとlong tailに位置するentity disambiguationがうまくいかない
</ul>
</ul></li>
<li>サブグラフの選択は、NP困難なので近似的なアルゴリズムをつかって問題を解く</li>
<li>アルゴリズムは反復的にweighted degreeが小さなentity nodeを削除する</li>
<li>
<p>ただし、必ずすべてのmentionがいずれかのentityとエッジを一つ持つようにする
<ul>
こうすると準最適な解に陥ることがあるので前処理でmentionとの距離が遠いentityは削除
</ul></p>
</li>
<li>
<p>prior, context similarity, coherenceの3つの要素をうまいこと使ってrobustなモデルになっているらしい</p>
</li>
</ul>
<p>2013-02-16</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/togakushi.html" class="title"><font color="white">Togakushi</font></a></h1>
<p><a href="http://www.flickr.com/photos/85431668@N05/8466317921/" title="Untitled by tma15, on Flickr"><img src="http://farm9.staticflickr.com/8521/8466317921_d1a2397cfd_c.jpg" width="800" height="800" alt="Untitled"></a></p>
<p>2013-02-12</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/joint-inference-of-named-entity-recognition-and-normalization-for-tweets.html" class="title"><font color="white">Joint Inference of Named Entity Recognition and Normalization for Tweets (ACL 2012)</font></a></h1>
<p>Xiaohua Liu, Ming Zhou, Furu Wei, Zhongyang Fu, Xiangyang Zhou</p>
<p>proceeding: <a href="http://www.aclweb.org/anthology-new/P/P12/P12-1055.pdf">pdf</a></p>
<h2>解いている問題</h2>
<p>tweet (英語のtweetに限定) の集合が与えられたときに</p>
<ul>
<li>tweetに対して固有表現を指しているテキストを同定し，あらかじめ決められたラベル {PERSON, ORGANIZATION, PRODUCT, LOCATION} を割り当てる．</li>
<li>これらの同定されたテキストに対して名寄せをおこなう．
<ul></li>
<li>名寄せは，一番単語数が多い表現にまとめる</li>
<li>最大の単語数の表現が複数あればWikipediaにある表現を採用</li>
<li>PERSONと識別された三つの表現"Gaga", "Lady Gaaaga", "Lady Gaga"は"Lady Gaga"にまとめる．
</ul></li>
</ul>
<h2>アプローチ</h2>
<ul>
<li>固有表現認識 (NER) モデルの学習の際に，固有表現の名寄せ (NEN) モデルの学習も同時に行うことでお互いの精度を上げる
<ul></li>
<li>tweetは，エンティティに対していろいろな表現をされる．</li>
<li>e.g. "Anne Gronloh"というエンティティには"Mw.,Gronloh", "Anneke Kronloh", "Mevrouw G"など
</ul></li>
<li>"... Alex's jokes. ..."と"... Alex Russo was like..."という二つのtweet
<ul></li>
<li>NERモデルにより"Alex"と"Alex Russo"がともにPERSONであることが識別できれば，NENモデルは"Alex"を"Alex Russo"に名寄せできる．
</ul></li>
<li>" ... she knew Burger King when ..."と".. I'm craving all sorts of food: mcdonalds, burger king, ..."という二つのtweet
<ul></li>
<li>NENモデルが"Burger King"と'burger king"が別のエンティティを指していると識別できればNERモデルはこれらに異なるラベルを割り当てられる．
</ul></li>
<li>学習にはCRFを用いる
<ul></li>
<li>skip-chain CRFと似たモデルだけど，tweet mのi番目の単語とtweet nのj番目の単語が同じエンティティを指しているかを表すnormalization変数があるのが違う．</li>
<li>ラベルは{B, I, L, O, U}</li>
<li>一つ目のtweetに含まれる"Gaga"と二つ目のtweetに含まれる"Lady Gaga"にPERSONが割り当てられ，一つ目のtweetに含まれる"Gaga"と二つ目のtweetに含まれる"Gaga"が同一のエンティティを指していると識別できれば"Gaga"と"Lady Gaga"は同じものを指している</li>
<li>(CRFの復習) 重みを更新するときの，対数裕度関数を重み変数λで偏微分したときに二つの項がでてくる．</li>
<li>初項は正解となるラベルが与えられたときの，素性関数kの訓練データに対しての合計値</li>
<li>第二項は現在のパラメータによって決定されるモデルによる素性関数kの期待値の合計値</li>
<li>初項が第二項よりも大きいほど，重みλ_kは大きくなるし，初項が第二項よりも小さいほど重みλ_kは小さくなる．</li>
<li>skip-chainなので，素性関数は隣り合ったラベルの組み合わせに加えて，隣り合っていないラベルの組み合わせも見ることができるし，このモデルでは他のツイートの単語につくラベルとの関係も見る．
</ul></li>
</ul>
<p><strong>複数のtweetを同時に考慮することの利点</strong></p>
<ul>
<li>"... Bobby Shaw you don't invite the wind..."と"... I own yah! Loool bobby shaw..."
<ul></li>
<li>"Bobby Shaw"をPERSONと識別することは比較的簡単．</li>
<li>一つ目のtweetの"you"が，二つ目のtweetの'bobby shaw"がPERSONであることの手がかりとなる．
</ul></li>
</ul>
<p><strong>ラベルの候補の絞り込み</strong></p>
<ul>
<li>外部資源から固有表現を取ってきて辞書を作っておく．</li>
<li>tweetの中に，辞書に含まれる固有表現の一部と一致していれば，ラベルの候補の集合へその固有表現のラベルを加える
<ul></li>
<li>"new york"という句が出てきたとき，辞書にある"New York City"と"New York Times"と一致する．</li>
<li>"new"には，"B-LOCATION", "B-ORGANIZATION"，"york"には"I-LOCATION", "I-ORGANIZATION"がラベルの候補の集合にそれぞれ追加される．
</ul></li>
<li>ラベルの候補の集合へひとつでもラベルが追加されていれば，y^i_mはこのラベルの候補の集合のみしか考えない</li>
</ul>
<p><strong>normalization変数zもルールである程度決めてしまう</strong></p>
<ul>
<li>同じtweet mで，表層的に同じ語があれば，それらは同じエンティティについて述べていると考え，z^{ij}_{mm}=1とする．</li>
<li>tweet mとtweet nのcos類似度が0.8以上なら，すべてi, jに対してのz^{ij}_{mn}=1</li>
<li>tweet mとtweet nのcos類似度が0.3以下なら，すべてi, jに対してのz^{ij}_{mn}=0</li>
</ul>
<p><strong>素性</strong></p>
<ul>
<li>大文字かどうか，接頭辞，接尾辞，ストップワードかどうかなど</li>
<li>基本形，out-of-vocabularyかどうか，ハッシュタグかどうかなど</li>
<li>ラベル候補の絞り込み時にラベル候補の集合に何か追加されているかどうか，一番追加されているラベルは何か</li>
</ul>
<h2>感想・疑問点</h2>
<ul>
<li>Discussionで，エラーの大半がスラング，略語だと書かれているけど，これを解決することで提案手法がTwitterのデータを扱う上での強みとなりそうだと思った．</li>
</ul>
<p>2013-02-06</p>

<h1><br><br><a href="http://tma15.github.com/blog/2013/2/named-entity-disambiguation-in-streaming-data.html" class="title"><font color="white">Named Entity Disambiguation in Streaming Data (ACL 2012)</font></a></h1>
<p>Alexandre Davis, Adriano Veloso, Algigran S. da Silva, Wagner Meira Jr., Alberto H. F. Laender</p>
<p>proceeding: <a href="http://www.aclweb.org/anthology-new/P/P12/P12-1086.pdf">pdf</a></p>
<h2>解いている問題</h2>
<p>名詞nを含む短いテキストが、あるエンティティeのことを指しているか、指していないかを当てる二値分類問題。</p>
<p>課題</p>
<ul>
<li>Twitterのようなmicro-blogのテキストは単語の数が少なく、暗号のように書かれていることもあるため、固有表現を認識することが難しい</li>
<li>テキストの単語の数の少なさから、エンティティの周辺に共通して現れる文脈から特徴を学習することが難しい</li>
<li>テキストが次々と流れてくるため、テキストを処理するために外部知識を参照していると処理が間に合わない</li>
<li>テキストが次々とやってきて、テキストの傾向も変わるのでモデルがすぐにデータに合わなくなってしまう</li>
</ul>
<h2>提案手法のモチベーション</h2>
<ul>
<li>外部知識を参照している余裕がないなら、ストリーム中の（ラベルなしの）大量のテキストから得られる情報を使う。</li>
<li>ラベルなしのテキストを負例として学習すると、負例の多さからモデルが過学習をおこし、大量のfalse-negativeが出てしまうおそれがある。
<ul></li>
<li>正例を作ることは比較的簡単だが、負例を作るのはコストがかかる。
</ul></li>
<li>なので、EMアルゴリズムを使って二値分類器を反復的に洗練させるのがこの論文のアイディア。</li>
<li>具体的には、ラベルなしの事例が負例である確率を計算してラベル付きデータとして訓練データを増やす。</li>
<li>このラベル付きの事例は各ステップでラベルを変更することができる。</li>
<li>どの事例がどちらのラベルになるかは、最終的には収束して、観測データに最もフィットしたラベルに落ち着くことが期待される。</li>
</ul>
<h2>曖昧性解消のアプローチ</h2>
<p><strong>（良くない）シンプルな正例の作り方の例</strong></p>
<ul>
<li>Twitter中である会社と関連したアカウントあり、このアカウントのプロフィールに書かれたメッセージは、その会社名を含むメッセージである可能性がある。</li>
<li>こんな感じで正例を集める方法が考えられるが、このやり方はfalse-positiveがないことを保証していない。
<ul></li>
<li>つまり、本当はその会社のことを言及したメッセージではないのに、そのアカウントのメッセージなので正例とみなされていまう可能性がある。
</ul></li>
<li>このようにして作成された訓練データを用いて学習したモデルの性能はそんなに上がることが期待できない。</li>
</ul>
<p><strong>ラベルなしの事例の信頼性を上げて、訓練データとして扱うことでモデルの性能を上げる</strong></p>
<ul>
<li>ラベルなしの事例を扱うコストは、人手のアノテーションでラベル付きの事例を作成するコストより低い。</li>
<li>具体的には、EMアルゴリズムを使う</li>
</ul>
<p><strong>訓練データの初期状態としてありうる二つのパターン</strong></p>
<ul>
<li>訓練データは真に正例の事例と、大量のラベルなしの事例からなる
<ul></li>
<li>ラベルなしのデータは最初、負例とみなされるのでfalse-negativeな事例を含む可能性がある
</ul></li>
<li>訓練データはおそらく正例の事例と、大量のラベルなしの事例からなる
<ul></li>
<li>正例は真に正例という保証はないので、false-positiveな事例を含む可能性がある</li>
<li>ラベルなしのデータは最初、負例とみなされるのでfalse-negativeな事例を含む可能性がある
</ul></li>
</ul>
<p><strong>E-step</strong></p>
<ul>
<li>訓練データ中のすべての事例に、{正例、負例}のそれぞれの場合で閾値以上、あるいは以下であった場合に正例あるいは負例を割り当てる</li>
<li>具体的には事例xが負例である確率α(x, -)が閾値α^x_{min}と等しいかそれより小さければ、xは正例となり、大きければ負例となる
<ul></li>
<li>α^x_{min}は、事例ごとに決定されるパラメータ
</ul></li>
</ul>
<p><strong>M-step</strong></p>
<ul>
<li>分類器Rを更新、訓練データのすべての事例に負例である確率α(x, -)を割り当てる</li>
</ul>
<p><strong>分類器R</strong></p>
<ul>
<li>ある単語の集合が正例に現れやすいか、負例に現れやすいかを学習する。</li>
<li>このルール（単語の集合）の信頼性を、頻度をもとに計算して、事例が負である確率を、集めたルールの集合の重み付きの投票のような感じで計算する。</li>
<li>ラベルのtransitでは、ラベル付きデータから、ランダムに正例をいくつか抜き出して、残りをラベルなしのデータとみなしている。</li>
<li>分類器の更新は、すべての事例のlabel transitionを終えてから行うよりも、各事例のlabel transitionを終えるごとに行うほうがいい結果だった。</li>
<li>また、label transition operationは負例を正例にする操作に加え、正例を負例にする操作もできるようにしたほうがいい結果だった。</li>
<li>SVMの代わりにLazy Associative Classifiersの変種を使うことで、速度がかなり早くなった。</li>
</ul>
<h2>疑問点</h2>
<ul>
<li>最初に選ぶ少数の正例によって精度がどれくらい変わるのだろうと思った (できあがるモデルがどれくらい初期値に依存するのか)</li>
<li>α^x_{min}は、正例と負例のバランスがよくなるように決定しているが、正例と負例のバランスはちょうどいいという仮定は直感にあっているのか
（ある単語のパターンでは負例になりやすいとかそういうことではない？）</li>
</ul>
<p>2013-02-01</p>

<p><br><br><div class="bottom_article_nav">
<div class="prev"> &lt;<a href="http://tma15.github.com/blog/page/2/index.html">older</a></div>
</div>
<div class="center"><a href="/blog/archive.html">archives</a></div></p>
            <p></p>

            
        </article>

        <aside>
        <p>Created by <a href="http://tma15.github.com">tma15</a></p>
        </aside>

                    </body>
</html>