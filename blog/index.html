<!doctype html>
<html lang="ja">
    <head>
        <link href="http://fonts.googleapis.com/css?family=Anton" rel="stylesheet" type="text/css">
        <link href='http://fonts.googleapis.com/css?family=Inconsolata' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Bubblegum+Sans' rel='stylesheet' type='text/css'>
        <title>Blog
 | Now is better than never.</title>
        <meta charset="utf-8" />
        <link href='http://fonts.googleapis.com/css?family=Permanent+Marker' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="/media/css/font-awesome.css">
        <link rel="stylesheet" href="/media/css/style.css">
        <link rel="stylesheet" href="/media/css/pygments.css">
        <link rel="shortcut icon" href="/media/img/background.jpg">
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }
            });
        </script>
        <script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
        <!--[if lt IE 9]>
        <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js">
        </script>
        <![endif]-->
    </head>
    <body >
        <header>
            <hgroup>
              <h1>Now is better than never.</h1>
              <h3>Although never is often better than right now.</h3>
            </hgroup>
        </header>
        <nav>
                                <ul>
<li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/blog">Blog</a></li><li><a href="/blog/archive.html">Archive</a></li></ul>
        </nav>
        <article id="content">
                                            <section class="posts">

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2015/02/21.html" title="Dropoutの実装で気になって調べたこと" itemprop="url">Dropoutの実装で気になって調べたこと</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/machine_learning.html" rel="tag">machine_learning</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p>Dropout層は学習時と予測時にforwardの処理が異なる。ここでは学習時と予測時では処理がどう異なるかは書かずに、メジャーどころのライブラリではどのように実装されているかを簡単に調べたことをメモ書き程度に書く。処理がどう異なるかに興味がある人は参考にある論文を読むと分かりやすい。</p>
<p><a href="http://caffe.berkeleyvision.org/">Caffe</a>だと、今学習しているのか、予測しているのかのphaseをsingletonクラスを使ってグローバルに参照できるようにしている。なので、おそらく外から見たら異なるクラスの層と同じようにふるまうことができる。</p>
<ul>
<li><a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/dropout_layer.cpp#L40">Caffeのdropout_layer.cpp</a></li>
<li><a href="https://github.com/BVLC/caffe/blob/master/include/caffe/common.hpp#L97">Caffeの設定を参照できるようなsingletonクラス</a></li>
</ul>
<p>ちなみに、上記のsingletonクラスで<span class="caps">CPU</span>を使うのか、<span class="caps">GPU</span>を使うのかの切り替えもやっている。一方、<a href="http://torch.ch/">torch</a>では層ごとにモード{training,&nbsp;evaluate}を切り替えるようにしているようだ。なので、Dropout層を使うときはモードの切り替えを忘れないようにしないといけないはず。</p>
<ul>
<li><a href="https://github.com/torch/nn/blob/master/Module.lua#L84">Module.lua</a></li>
<li><a href="https://github.com/torch/nn/blob/master/doc/module.md#training">training</a></li>
<li><a href="https://github.com/torch/nn/blob/master/doc/module.md#evaluate">evaluate</a></li>
</ul>
<p>ユニットをランダムに消すようなことをしない一般的な層と同じように使えるようにするにはCaffeのような書き方をしたほうがよいのだろうか。</p>
<h3>参考</h3>
<ul>
<li><a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">Dropout: A Simple Way to Prevent Neural Networks from&nbsp;Overfitting</a></li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2015-02-21T00:00:00+0800"></abbr> on <time datetime="2015-02-21" class="date" itemprop="datePublished">21 Feb 2015</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2015/01/add-comment.html" title="コメント欄を付けた" itemprop="url">コメント欄を付けた</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/diary.html" rel="tag">diary</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p><a href="https://disqus.com/"><span class="caps">DISQUS</span></a>を使ってこのブログにコメント欄をつけてみた。</p>
</div>

<div>Posted <abbr class="timeago" title="2015-01-17T00:00:00+0800"></abbr> on <time datetime="2015-01-17" class="date" itemprop="datePublished">17 Jan 2015</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2015/01/cykfordependencyparsing.html" title="CYKアルゴリズムで係り受け解析" itemprop="url">CYKアルゴリズムで係り受け解析</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/nlp.html" rel="tag">nlp</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p><span class="caps">CYK</span>アルゴリズムは文脈自由文法を解析するためのものであるので、係り受け解析に適用するには、係り受け解析結果を文脈自由文法のような木で表現する。
具体的には参考資料の23ページにあるような変換をする。
例えば「私は / ピザを / 食べる」という文節で(&#8220;/&#8221;を堺に)区切られた文があって、「私は」が「食べる」、「ピザを」が「食べる」をそれぞれ修飾しているとき、「食べる」=&gt;「私は」「食べる」のような導出に変換してやることで係り受け関係を木で表現できる。
一番良い木を推定するには、テーブルTの各セルに係り受けのスコアの最大値を記憶しておいて、T[0, N]からバックトラックする (Nは文節の数)。&nbsp;ただしこの解析ではO(n^5)の時間がかかる。</p>
<h2>参考</h2>
<ul>
<li><a href="http://stp.lingfil.uu.se/~nivre/docs/ACLslides.pdf">Dependency Parsing Tutorial at <span class="caps">COLING</span>-<span class="caps">ACL</span>&nbsp;2006</a></li>
</ul>
</div>

<div>Posted <abbr class="timeago" title="2015-01-14T00:00:00+0800"></abbr> on <time datetime="2015-01-14" class="date" itemprop="datePublished">14 Jan 2015</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2015/01/cykmemo.html" title="CYKアルゴリズム" itemprop="url">CYKアルゴリズム</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/nlp.html" rel="tag">nlp</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p>明けましておめでとうございます。</p>
<p>確率的言語モデルを読んで文脈自由文法に対する構文解析手法である<span class="caps">CYK</span>アルゴリズムのところを読んだ (<a href="https://github.com/tma15/nlppractice/blob/master/cyk.py">ソースコード</a>)。
動的計画法。
表TのT[0, N-1]に&#8221;S&#8221;があれば与えられた文法からこの文は導出可能。
文&#8221;I eat pizza with Maria&#8221;&nbsp;を文脈自由文法で表すと、曖昧性があるため二つの木が導出できる。</p>
<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="nv">$python</span> cyk.py<br />I eat pizza with Maria<br />   N |    S |    S |      |    S<br />     |    V |  S,V |      |  S,V<br />     |      |    N |      |    N<br />     |      |      |    P |   <span class="caps">PP</span><br />     |      |      |      |    N<br />    --l &lt;N&gt; -- I 0<br />  --r &lt;V&gt; <br />        --l &lt;V&gt; -- eat 1<br />        --r &lt;N&gt; <br />            --l &lt;N&gt; -- pizza 2<br />          --r &lt;<span class="caps">PP</span>&gt; <br />               --l &lt;P&gt; -- with 3<br />               --r &lt;N&gt; -- Maria 4<br />--<br />  --l &lt;S&gt; <br />        --l &lt;N&gt; -- I 0<br />      --r &lt;V&gt; <br />            --l &lt;V&gt; -- eat 1<br />            --r &lt;N&gt; -- pizza 2<br />  --r &lt;<span class="caps">PP</span>&gt; <br />       --l &lt;P&gt; -- with 3<br />       --r &lt;N&gt; -- Maria 4<br />--<br /></pre></div><br /></figure></div>

<h2>参考</h2>
<div align="center">
<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=FFFFFF&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=takuya6315-22&o=9&p=8&l=as1&m=amazon&f=ifr&ref=qf_sp_asin_til&asins=4130654047" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>
</div>
</div>

<div>Posted <abbr class="timeago" title="2015-01-10T00:00:00+0800"></abbr> on <time datetime="2015-01-10" class="date" itemprop="datePublished">10 Jan 2015</time></div>
</article><!-- /.post -->
<br><br><br>

<article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1><a class="title" href="/blog/2014/12/read-question-answering-using-enhanced-lexical-semantic-models.html" title="Question Answering Using Enhanced Lexical Semantic Models (ACL2013) を読んだ" itemprop="url">Question Answering Using Enhanced Lexical Semantic Models (ACL2013) を読んだ</a></h1>

<div class="tags" itemprop="keywords">
Tags:
<a href="/blog/tags/nlp.html" rel="tag">nlp</a> 
<a href="/blog/tags/paper.html" rel="tag">paper</a> 
</div>

<div class="entry" itemprop="articleBody">
        <p>Question Answering Using Enhanced Lexical Semantic Models (<a href="http://www.aclweb.org/anthology/P13-1171">pdf</a>)</p>
<p>Wen-tau Yih, Ming-Wei Chang, Christopher Meek and Andrzej Pastusiak, Microsoft Research, <span class="caps">ACL</span>&nbsp;2013</p>
<h2>導入</h2>
<ul>
<li>自然文の質問文を入力として受け付けて、解答として適切な文の選択(answer sentence selection)をして出力する<ul>
<li>単に名詞を解答として選択して出力するよりも、文脈が付いていたほうが根拠が分かるし、ユーザにとっては価値があるから</li>
</ul>
</li>
<li>answer sentence selectionは質問文と文書中の文とのマッチングの問題と考えられる<ul>
<li>単語の表層形のマッチングを単純な方法だと精度はそんなに上がらない</li>
<li>深い意味解析をしたり構文木の編集距離 (Tree Edit&nbsp;Distance)をしている研究もあるが、計算コストが高い</li>
<li>なのでこの研究では浅い意味解析を頑張ってanswer sentence selectionの性能を上げることに焦点を当てる<ul>
<li>浅い意味解析は上位下位語や同義語などを識別するlexical&nbsp;sematics</li>
</ul>
</li>
</ul>
</li>
<li>この論文ではlatent word-alignment structureとしてanswer sentence&nbsp;selectionを定式化する</li>
</ul>
<h2>この論文の貢献</h2>
<ul>
<li>色々なlexical semanticを組み合わせれば、学習アルゴリズムなどに関係なくanswer sentence&nbsp;selectionシステムの性能を上げられる</li>
<li>lexical word-alignment structureは、非構造なモデルよりも高い性能を出せるが、両方のモデルにlexical&nbsp;semanticsを入れた場合、性能の差は小さくなる</li>
<li>計算コストを下げたいなら、lexical&nbsp;semanticsを使ってシンプルなモデルを使うこともできる</li>
</ul>
<h2>問題設定</h2>
<p>教師あり学習でanswer sentence selectionに取り組む。学習時は質問文qと、それに関連するラベル付きの文(yi,&nbsp;si)のリストが与えられるので、それを学習データとしてパラメータを学習。yiは1であればsiは正解の文、0であれば不正解の文を表す。予測時は未知の文に対し、文が正解である確率を予測し、yiとする。</p>
<p>実際には文が正解であるかどうかではなく、文が質問文と意味的にマッチするかどうかを学習する。この論文では質問文と文の間には隠れ構造hが存在すると仮定する。隠れ構造hは質問文の単語と文の単語が対応するかどうかを表したバイナリのベクトル。</p>
<p>文を構文木で表現する先行研究もあるが、導入部分での理由から、この論文では浅い意味解析により文を表現する。</p>
<h2>lexical semantic&nbsp;models</h2>
<p>表層系のみのマッチングでは微妙なので言語資源を作成する。</p>
<h3>類義語と反義語</h3>
<p>Polarity-Inducing latent semantic analysis (<span class="caps">PILSA</span>)&nbsp;modelを使う。シソーラス(文書と単語のtfidf行列?)を入力として、<span class="caps">SVD</span>でd行n列の行列を構築する。dは類義語や反義語のクラスタの数を表す。nは語彙の数。二つの単語を表す列のコサインが正であれば、その単語は類義語、負であれば反義語とみなす。</p>
<h3>上位語下位語</h3>
<p>WordNetはカバレッジが低いので、<a href="http://research.microsoft.com/en-us/projects/probase/">Probase</a>を使う。ある単語が別の単語の下位語である確率を保持している。</p>
<h3>意味的な単語の類似度</h3>
<p>商用のサーチエンジンのクリックデータを使ってSiamese newural&nbsp;networkモデルを学習。入力はクエリとクリックしたページのタイトルの対の集合。ある文字列（クエリ）がどの文字列(クリックされたページのタイトル)と対応するかを表す行列を学習する。ページのタイトルを表す行ベクトルは密になるように圧縮されている。</p>
<h2>分類器の学習</h2>
<h3>Bag-of-Wordsモデル</h3>
<p>logistic regressionとboosted decision&nbsp;treeを用いる。</p>
<h3>隠れ構造モデル</h3>
<p>構造的なモデルではLatent-<span class="caps">SVM</span>の一種である<span class="caps">LCLR</span>を用いる。目的関数 (単語間の意味的類似度)&nbsp;を最大化する隠れ構造hを選択して、損失項を最小化するように重みを更新するのを繰り返す。隠れ構造hがどの単語とどの単語の対応を見るかを制御している。隠れ構造は、「文のある単語は少なくとも質問文中の1つ以上の単語と対応していなければならない」、「質問文中の単語は文中のいずれかの単語と対応していなければならない」、というような制約を付与して整数計画法により選択する。</p>
<h3>素性</h3>
<p>すべての素性は単語の<span class="caps">IDF</span>で重み付け</p>
<ul>
<li>表層的な単語のマッチング</li>
<li>WordNet:&nbsp;同じsynsetに属する、上位語下位語、反義語関係にある</li>
<li>lexical semantics:&nbsp;上記実数値</li>
<li><span class="caps">NE</span>:&nbsp;単語が同じタイプの固有表現の一部である</li>
<li>answer type checking:&nbsp;質問文が<span class="caps">WH</span>を接頭辞とする単語から始まる場合のルール。Whoで始まれば、Personな<span class="caps">NE</span>と対応するみたいなもの。</li>
</ul>
<h2>結果</h2>
<p>リッチな言語資源を使うほど、どの分類器でも<span class="caps">MRR</span>、<span class="caps">MAP</span>が向上。</p>
<h2>所感</h2>
<p>複雑なアルゴリズムでやるよりも言語資源をリッチにして計算コストを減らすのは良さそうと思ったので、<span class="caps">LCLR</span>とlogistic&nbsp;regressionでどれくらい差が出るのか気になった。文間の単語の対応くらいだと問題はそれほど大きくないかもしれないけど、整数計画法のソルバーは早いものが有償だったりするので、そういったことを考えると分類器で複雑なことをするよりも言語資源を前処理でガッと作っておくほうが現実的な気がした。</p>
</div>

<div>Posted <abbr class="timeago" title="2014-12-03T00:00:00+0800"></abbr> on <time datetime="2014-12-03" class="date" itemprop="datePublished">03 Dec 2014</time></div>
</article><!-- /.post -->
<br><br><br>

</section>

<div align="center">
<a class="next"
    href="/blog/pages/2/index.html">
    &laquo; Older
</a>
&nbsp;&nbsp;

</div>
        <br>
                                </article>

                <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-20414370-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>    </body>
</html>