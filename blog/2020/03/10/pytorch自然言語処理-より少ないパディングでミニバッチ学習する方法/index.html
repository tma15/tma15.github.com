<!DOCTYPE html>
<html lang="ja">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.67.0 with theme Tranquilpeak 0.4.7-BETA">
<meta name="author" content="Takuya Makino">
<meta name="keywords" content="pytorch, nlp, machine_learning">
<meta name="description" content="
ニューラルネットワークの学習には、複数の事例 (たとえば単語の系列) に対して並列に損失関数を計算し、得られた勾配に基づいてパラメータを更新するミニバッチ学習が用いられます。自然言語処理において、ミニバッチ学習時は単語の系列を同じ長さにそろえて処理します。これはニューラルネットワーク内での計算において、データが密行列として扱われることが多いためです。
この長さをそろえる処理はパディングといわれています。
当然ながら、ミニバッチ内で系列の長さが不ぞろいなほど、パディングによって追加される疑似的な単語が増えるため、本来不要な計算が増えます。また、ミニバッチを表す密行列が大きいほど、計算にかかる時間が大きくなります。
本記事ではPyTorchにおける実装において、系列の長さが近い事例でミニバッチを作成することで、不要なパディングをできるだけ減らし、ミニバッチを表す密行列の大きさを小さくする方法を紹介します。">


<meta property="og:description" content="
ニューラルネットワークの学習には、複数の事例 (たとえば単語の系列) に対して並列に損失関数を計算し、得られた勾配に基づいてパラメータを更新するミニバッチ学習が用いられます。自然言語処理において、ミニバッチ学習時は単語の系列を同じ長さにそろえて処理します。これはニューラルネットワーク内での計算において、データが密行列として扱われることが多いためです。
この長さをそろえる処理はパディングといわれています。
当然ながら、ミニバッチ内で系列の長さが不ぞろいなほど、パディングによって追加される疑似的な単語が増えるため、本来不要な計算が増えます。また、ミニバッチを表す密行列が大きいほど、計算にかかる時間が大きくなります。
本記事ではPyTorchにおける実装において、系列の長さが近い事例でミニバッチを作成することで、不要なパディングをできるだけ減らし、ミニバッチを表す密行列の大きさを小さくする方法を紹介します。">
<meta property="og:type" content="article">
<meta property="og:title" content="[PyTorch][自然言語処理] より少ないパディングでミニバッチ学習する方法">
<meta name="twitter:title" content="[PyTorch][自然言語処理] より少ないパディングでミニバッチ学習する方法">
<meta property="og:url" content="https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/">
<meta property="twitter:url" content="https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/">
<meta property="og:site_name" content="Now is better than never.">
<meta property="og:description" content="
ニューラルネットワークの学習には、複数の事例 (たとえば単語の系列) に対して並列に損失関数を計算し、得られた勾配に基づいてパラメータを更新するミニバッチ学習が用いられます。自然言語処理において、ミニバッチ学習時は単語の系列を同じ長さにそろえて処理します。これはニューラルネットワーク内での計算において、データが密行列として扱われることが多いためです。
この長さをそろえる処理はパディングといわれています。
当然ながら、ミニバッチ内で系列の長さが不ぞろいなほど、パディングによって追加される疑似的な単語が増えるため、本来不要な計算が増えます。また、ミニバッチを表す密行列が大きいほど、計算にかかる時間が大きくなります。
本記事ではPyTorchにおける実装において、系列の長さが近い事例でミニバッチを作成することで、不要なパディングをできるだけ減らし、ミニバッチを表す密行列の大きさを小さくする方法を紹介します。">
<meta name="twitter:description" content="
ニューラルネットワークの学習には、複数の事例 (たとえば単語の系列) に対して並列に損失関数を計算し、得られた勾配に基づいてパラメータを更新するミニバッチ学習が用いられます。自然言語処理において、ミニバッチ学習時は単語の系列を同じ長さにそろえて処理します。これはニューラルネットワーク内での計算において、データが密行列として扱われることが多いためです。
この長さをそろえる処理はパディングといわれています。
当然ながら、ミニバッチ内で系列の長さが不ぞろいなほど、パディングによって追加される疑似的な単語が増えるため、本来不要な計算が増えます。また、ミニバッチを表す密行列が大きいほど、計算にかかる時間が大きくなります。
本記事ではPyTorchにおける実装において、系列の長さが近い事例でミニバッチを作成することで、不要なパディングをできるだけ減らし、ミニバッチを表す密行列の大きさを小さくする方法を紹介します。">
<meta property="og:locale" content="ja">

  
    <meta property="article:published_time" content="2020-03-10T16:50:53">
  
  
    <meta property="article:modified_time" content="2020-03-10T16:50:53">
  
  
  
    
      <meta property="article:section" content="pytorch">
    
      <meta property="article:section" content="nlp">
    
      <meta property="article:section" content="machine_learning">
    
  
  
    
      <meta property="article:tag" content="pytorch">
    
      <meta property="article:tag" content="nlp">
    
      <meta property="article:tag" content="machine_learning">
    
  


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@tma15">


  <meta name="twitter:creator" content="@tma15">






  <meta property="og:image" content="https://tma15.github.io/img/2020/pytorch-logo.png">
  <meta property="twitter:image" content="https://tma15.github.io/img/2020/pytorch-logo.png">





  <meta property="og:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">


    <title>[PyTorch][自然言語処理] より少ないパディングでミニバッチ学習する方法</title>

    <link rel="icon" href="https://tma15.github.io/favicon.png">
    

    

    <link rel="canonical" href="https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/">

    
    <script type="text/javascript" async
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
          });
    </script>


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
          (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-5663917297524414",
                  enable_page_level_ads: true
                });
    </script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://tma15.github.io/css/style-twzjdbqhmnnacqs0pwwdzcdbt8yhv8giawvjqjmyfoqnvazl0dalmnhdkvp7.min.css" />
    
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-20414370-4', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://tma15.github.io/">Now is better than never.</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://tma15.github.io/#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=90" alt="プロフィール画像" />
      
    
    </a>
  

  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
           (adsbygoogle = window.adsbygoogle || []).push({
                         google_ad_client: "ca-pub-5663917297524414",
                         enable_page_level_ads: true
                    });
  </script>
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://tma15.github.io/#about">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
        </a>
        <h4 class="sidebar-profile-name">Takuya Makino</h4>
        
          <h5 class="sidebar-profile-bio">自然言語処理の研究開発者。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、Python、C++に関する記事が多めです。</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">ホーム</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">タグ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">アーカイブ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">プロフィール</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/tma15" target="_blank" rel="noopener">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/inquiry">
    
      
      
      <span class="sidebar-button-desc">お問い合わせ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/privacy-policy">
    
      
      
      <span class="sidebar-button-desc">プライバシーポリシー</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>

      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle"
      style="display:block; text-align:center;"
      data-ad-layout="in-article"
      data-ad-format="fluid"
      data-ad-client="ca-pub-5663917297524414"
      data-ad-slot="8357823829"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

    <h3 style="color:white">最近の投稿</h3>
    <ul >
    
    <li ><a href="https://tma15.github.io/blog/2020/04/26/pytorchversion1.5%E3%81%A7tpu%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/" class="sidebar-button-link" style="color:white">【PyTorch】Version1.5でTPUを利用する方法</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/04/19/python%E8%87%AA%E4%BD%9C%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%83%B3%E3%82%B0%E6%96%B9%E6%B3%95/" class="sidebar-button-link" style="color:white">【Python】自作ライブラリのパッケージング方法</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/04/12/git%E3%83%96%E3%83%A9%E3%83%B3%E3%83%81%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AB%E4%BD%BF%E3%81%86%E4%BE%BF%E5%88%A9%E3%81%AA%E6%A9%9F%E8%83%BD/" class="sidebar-button-link" style="color:white">【Git】ブランチを作成して開発するときに使う便利な機能</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/04/07/pythonzip-zip_longest%E3%81%AE%E9%81%95%E3%81%84%E5%90%8C%E3%81%98%E9%95%B7%E3%81%95%E3%81%AE%E5%85%A5%E5%8A%9B%E3%82%92%E5%89%8D%E6%8F%90%E3%81%A8%E3%81%97%E3%81%9Fzip_longest%E3%81%AE%E4%BD%BF%E7%94%A8/" class="sidebar-button-link" style="color:white">【Python】zip, zip_longestの違い、同じ長さの入力を前提としたzip_longestの使用</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/" class="sidebar-button-link" style="color:white">【PyTorch】限られたメモリにおける大きなバッチサイズでの学習</a></li>
    
    </ul>

      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle"
      style="display:block; text-align:center;"
      data-ad-layout="in-article"
      data-ad-format="fluid"
      data-ad-client="ca-pub-5663917297524414"
      data-ad-slot="8357823829"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      [PyTorch][自然言語処理] より少ないパディングでミニバッチ学習する方法
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-03-10T16:50:53&#43;09:00">
        
  
  
  
  
    2020-03-10
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


</div>
          

          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              

<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5663917297524414"
     data-ad-slot="8357823829"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>ニューラルネットワークの学習には、複数の事例 (たとえば単語の系列) に対して並列に損失関数を計算し、得られた勾配に基づいてパラメータを更新するミニバッチ学習が用いられます。自然言語処理において、ミニバッチ学習時は単語の系列を同じ長さにそろえて処理します。これはニューラルネットワーク内での計算において、データが密行列として扱われることが多いためです。
この長さをそろえる処理はパディングといわれています。
当然ながら、ミニバッチ内で系列の長さが不ぞろいなほど、パディングによって追加される疑似的な単語が増えるため、本来不要な計算が増えます。また、ミニバッチを表す密行列が大きいほど、計算にかかる時間が大きくなります。
本記事ではPyTorchにおける実装において、系列の長さが近い事例でミニバッチを作成することで、不要なパディングをできるだけ減らし、ミニバッチを表す密行列の大きさを小さくする方法を紹介します。</p>
<h2 id="table-of-contents">目次</h2><nav id="TableOfContents">
  <ul>
    <li><a href="#自然言語処理におけるミニバッチ作成時のパディング">自然言語処理におけるミニバッチ作成時のパディング</a></li>
    <li><a href="#ミニバッチ学習">ミニバッチ学習</a>
      <ul>
        <li><a href="#無作為に事例を選択してミニバッチを作成">無作為に事例を選択してミニバッチを作成</a></li>
        <li><a href="#系列の長さでソートしてミニバッチを作成">系列の長さでソートしてミニバッチを作成</a></li>
      </ul>
    </li>
    <li><a href="#パディングの数を比較">パディングの数を比較</a></li>
    <li><a href="#まとめ">まとめ</a></li>
  </ul>
</nav>
<p>本記事で計算しているコードはPyTorch1.4.0を利用しています。</p>
<h2 id="自然言語処理におけるミニバッチ作成時のパディング">自然言語処理におけるミニバッチ作成時のパディング</h2>
<p>二つの単語系列 <code>[1, 2, 3, 4, 5]</code> と <code>[1, 2]</code> をまとめて一つのミニバッチを作成することを考えます。
このとき、パディングは、ミニバッチ内の各単語系列に対して、最長の単語系列長になるように、単語系列の末尾に疑似的な単語 (ここでは<code>0</code>) を追加してミニバッチ内のすべての単語系列が同じ長さとなるようにします。
最長の単語系列長は <code>5</code> なので、 <code>[1, 2]</code> に対して、 <code>0</code> を3つ末尾に追加します。
PyTorchで実装するとたとえば以下のように記述できます。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch

x <span style="color:#f92672">=</span> [torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]), torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>])]
x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>rnn<span style="color:#f92672">.</span>pad_sequence(x, batch_first<span style="color:#f92672">=</span>True)
</code></pre></div><p>得られる結果は以下の通りです。</p>
<pre><code>tensor([[1, 2, 3, 4, 5],
        [1, 2, 0, 0, 0]])
</code></pre><h2 id="ミニバッチ学習">ミニバッチ学習</h2>
<p>ニューラルネットワークを学習する際は、学習データから指定した数だけ事例を選択し、選択した事例集合に対してパディングを適用します。
ここで、どのような基準で事例を選択するかを考える必要がありますが、良く用いられるのは、無作為に事例を選択する方法です。
無作為に事例を選択するのは、ミニバッチがデータの順序などの偏りが無くなるようにすることで、ニューラルネットワークが偏った学習をしないように意図したものです。
この方法の問題のひとつは選択された事例の単語系列長のばらつきが大きいと、パディングによって追加される単語が多くなり、計算にかかる時間が多くなるということです。</p>
<p>まず、良く用いられる無作為に事例を選択することでミニバッチを作成する方法と、できるだけパディングによって追加する単語を減らす作成方法を紹介します。</p>
<p>以降では5つの事例に対してバッチサイズ2でミニバッチを作成することを考えます。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>

data <span style="color:#f92672">=</span> [torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>]),
        torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]),
        torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>]),
        torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>]),
        torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">8</span>])]
</code></pre></div><p>またパディングを適用する関数を以下の様に定義しておきます。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">collate_fn</span>(batch):
    x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>rnn<span style="color:#f92672">.</span>pad_sequence(batch, batch_first<span style="color:#f92672">=</span>True)
    <span style="color:#66d9ef">return</span> x
</code></pre></div><h3 id="無作為に事例を選択してミニバッチを作成">無作為に事例を選択してミニバッチを作成</h3>
<p>無作為に事例を選択してミニバッチを作成する方法は以下の様に実装できます。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">    data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
            data,
            batch_size<span style="color:#f92672">=</span>batch_size,
            shuffle<span style="color:#f92672">=</span>True,
            collate_fn<span style="color:#f92672">=</span>collate_fn)

    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>):
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Epoch:&#39;</span>, epoch)

        <span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> data_loader:
            <span style="color:#66d9ef">print</span>(batch)
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;---&#39;</span>)
</code></pre></div><p>結果は以下の通りです。</p>
<pre><code>Epoch: 0
tensor([[1, 2, 3, 4, 5, 6, 0, 0],
        [1, 2, 3, 4, 5, 6, 7, 8]])
---
tensor([[1, 2, 0, 0, 0],
	[1, 2, 3, 4, 5]])
---
tensor([[1, 2, 3, 4]])
---
Epoch: 1
tensor([[1, 2, 0, 0, 0],
	[1, 2, 3, 4, 5]])
---
tensor([[1, 2, 3, 4, 0, 0, 0, 0],
	[1, 2, 3, 4, 5, 6, 7, 8]])
---
tensor([[1, 2, 3, 4, 5, 6]])
---
</code></pre>

<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5663917297524414"
     data-ad-slot="8357823829"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h3 id="系列の長さでソートしてミニバッチを作成">系列の長さでソートしてミニバッチを作成</h3>
<p>次に単語系列長が近い事例でミニバッチを作成する方法は次の様に実装できます。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_batch_sampler</span>(data, batch_size):
    indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>arange(len(data))<span style="color:#f92672">.</span>tolist()
    sorted_indices <span style="color:#f92672">=</span> sorted(indices, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> idx: len(data[idx]))

    batch_indices <span style="color:#f92672">=</span> []
        start <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        end <span style="color:#f92672">=</span> min(start <span style="color:#f92672">+</span> batch_size, len(data))
        <span style="color:#66d9ef">while</span> True:
            batch_indices<span style="color:#f92672">.</span>append(sorted_indices[start: end])

            <span style="color:#66d9ef">if</span> end <span style="color:#f92672">&gt;=</span> len(data):
                <span style="color:#66d9ef">break</span>

            start <span style="color:#f92672">=</span> end
            end <span style="color:#f92672">=</span> min(start <span style="color:#f92672">+</span> batch_size, len(data))

    <span style="color:#66d9ef">return</span> batch_indices


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">length_sorted_data_loader</span>(data, batch_size):
    batch_sampler <span style="color:#f92672">=</span> create_batch_sampler(data, batch_size)

    num_token <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    num_pad <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>):
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Epoch:&#39;</span>, epoch)

        random<span style="color:#f92672">.</span>shuffle(batch_sampler)
        data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
            data,
            batch_sampler<span style="color:#f92672">=</span>batch_sampler,
            collate_fn<span style="color:#f92672">=</span>collate_fn)

        <span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> data_loader:
            <span style="color:#66d9ef">print</span>(batch)
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;---&#39;</span>)
</code></pre></div><p>無作為に事例を選択する方法とは異なり、まず事例を単語系列長でデータのインデックスをソートし、ソートされたインデックスに対して、先頭から順にミニバッチサイズだけ事例を選択し、 <code>batch_sampler</code> を <code>create_batch_sampler</code> から作成します。 <code>batch_sampler</code> は各エポックの最初に無作為に並び替えて <code>torch.utils.data.DataLoader</code> の引数に渡されます。</p>
<p>結果は以下の様になります。</p>
<pre><code>Epoch: 0
tensor([[1, 2, 3, 4, 5, 6, 7, 8]])
---
tensor([[1, 2, 3, 4, 5, 0],
        [1, 2, 3, 4, 5, 6]])
---
tensor([[1, 2, 0, 0],
	[1, 2, 3, 4]])
---
Epoch: 1
tensor([[1, 2, 3, 4, 5, 0],
	[1, 2, 3, 4, 5, 6]])
---
tensor([[1, 2, 0, 0],
	[1, 2, 3, 4]])
---
tensor([[1, 2, 3, 4, 5, 6, 7, 8]])
---
</code></pre><p>無作為に事例を選択する方法と異なり、ミニバッチ内の事例は常に同じではあるものの、ミニバッチの順序が無作為になるようなミニバッチ作成ができます。
単語系列長が近い事例でミニバッチを作成するため、無作為に事例を選択する方法と比較して、<code>0</code>の数が少なくなる傾向にあることが分かります。</p>
<h2 id="パディングの数を比較">パディングの数を比較</h2>
<p>本来ならGPU上でのニューラルネットワークの学習時間を計測すべきですが、簡単のため、パディングの数にどれくらい差が出るか比較してみます。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> random

<span style="color:#f92672">import</span> numpy
<span style="color:#f92672">import</span> torch


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">collate_fn</span>(batch):
    x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>rnn<span style="color:#f92672">.</span>pad_sequence(batch, batch_first<span style="color:#f92672">=</span>True)
    <span style="color:#66d9ef">return</span> x


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_batch_sampler</span>(data, batch_size):
    indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>arange(len(data))<span style="color:#f92672">.</span>tolist()
    sorted_indices <span style="color:#f92672">=</span> sorted(indices, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> idx: len(data[idx]))

    batch_indices <span style="color:#f92672">=</span> []
    start <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    end <span style="color:#f92672">=</span> min(start <span style="color:#f92672">+</span> batch_size, len(data))
    <span style="color:#66d9ef">while</span> True:

        batch_indices<span style="color:#f92672">.</span>append(sorted_indices[start: end])

        <span style="color:#66d9ef">if</span> end <span style="color:#f92672">&gt;=</span> len(data):
            <span style="color:#66d9ef">break</span>

        start <span style="color:#f92672">=</span> end
        end <span style="color:#f92672">=</span> min(start <span style="color:#f92672">+</span> batch_size, len(data))

    <span style="color:#66d9ef">return</span> batch_indices


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">length_sorted_data_loader</span>(data, batch_size):
    batch_sampler <span style="color:#f92672">=</span> create_batch_sampler(data, batch_size)

    num_token <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    num_pad <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
        random<span style="color:#f92672">.</span>shuffle(batch_sampler)
        data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
            data,
            batch_sampler<span style="color:#f92672">=</span>batch_sampler,
            collate_fn<span style="color:#f92672">=</span>collate_fn)

        <span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> data_loader:
            num_token <span style="color:#f92672">+=</span> (batch <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
            num_pad <span style="color:#f92672">+=</span> batch<span style="color:#f92672">.</span>eq(<span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;num_token&#39;</span>, num_token, <span style="color:#e6db74">&#39;num_pad&#39;</span>, num_pad)


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">random_sample_data_loader</span>(data, batch_size):
    data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
        data,
        batch_size<span style="color:#f92672">=</span>batch_size,
        shuffle<span style="color:#f92672">=</span>True,
        collate_fn<span style="color:#f92672">=</span>collate_fn)

    num_token <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    num_pad <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
        <span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> data_loader:
            num_token <span style="color:#f92672">+=</span> (batch <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
            num_pad <span style="color:#f92672">+=</span> batch<span style="color:#f92672">.</span>eq(<span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;num_token&#39;</span>, num_token, <span style="color:#e6db74">&#39;num_pad&#39;</span>, num_pad)


<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
    batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>

    data <span style="color:#f92672">=</span> [torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>]),
            torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]),
            torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>]),
            torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>]),
            torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">8</span>])]

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Random sample&#39;</span>)
    random_sample_data_loader(data, batch_size)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Length sorted&#39;</span>)
    length_sorted_data_loader(data, batch_size)
</code></pre></div><p>結果は以下の様になります。</p>
<pre><code>Random sample
num_token 2500 num_pad 580
Length sorted
num_token 2500 num_pad 300
</code></pre><p>無作為に事例を選択する方法と比較して、単語系列長が近い事例でミニバッチを作成したほうが、パディングによって追加される単語数が少なくなっていることが分かります。
もちろんパディングの数は学習にかかるエポック数や単語系列長のばらつきによりますが、上記の設定だとパディングの数が半分に減っています。</p>
<h2 id="まとめ">まとめ</h2>
<p>本記事ではニューラルネットワークにおける自然言語処理において、単語系列長が近い事例でミニバッチを作成することでパディングによって追加される単語数を減らす実装方法をPyTorchを使って説明しました。
単語系列長が近い事例でミニバッチを作成する方法はFacebookが公開しているニューラルネットワークのsequence-to-sequence実装 <a href="https://arxiv.org/pdf/1904.01038.pdf">fairseq</a> でも実装されており、より学習時間を短縮する方法の一つとして活用できます。</p>
              

              <br>
              <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
              <ins class="adsbygoogle"
              style="display:block; text-align:center;"
              data-ad-layout="in-article"
              data-ad-format="fluid"
              data-ad-client="ca-pub-5663917297524414"
              data-ad-slot="8357823829"></ins>
              <script>
              (adsbygoogle = window.adsbygoogle || []).push({});
              </script>
    
              

<h3>関連記事</h3>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/">
          [PyTorch] Datasetの読み込みにかかるメモリ消費量を節約する
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-03-08T16:04:11&#43;09:00">
        
  
  
  
  
    2020-03-08
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>









  </div>
  
    <a href="https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/pytorch-logo.png"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2019/09/04/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%87%BA%E5%8A%9B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E6%A4%9C%E7%B4%A2%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%95%E3%81%9B%E3%82%8B%E6%96%B9%E6%B3%95/">
          ニューラルネットの出力ベクトルを二値化して検索を高速化させる方法
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-09-04T18:19:54&#43;09:00">
        
  
  
  
  
    2019-09-04
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/acl2019">acl2019</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/paper">paper</a>
    
  

  </div>


    </div>









  </div>
  
    <a href="https://tma15.github.io/blog/2019/09/04/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%87%BA%E5%8A%9B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E6%A4%9C%E7%B4%A2%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%95%E3%81%9B%E3%82%8B%E6%96%B9%E6%B3%95/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2019/learning-to-compress.PNG"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2017/07/29/kaggle%E5%88%9D%E5%8F%82%E5%8A%A0%E8%A8%98%E9%8C%B2/">
          Kaggle初参加記録
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2017-07-29T15:30:01&#43;09:00">
        
  
  
  
  
    2017-07-29
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/kaggle">kaggle</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>









  </div>
  
</article>

</div>
<br>

<div class="box">

  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2016/09/04/early-update%E3%81%AF%E5%8F%8E%E6%9D%9F%E3%81%8C%E4%BF%9D%E8%A8%BC%E3%81%95%E3%82%8C%E3%82%8B/">
          Early updateは収束が保証される
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2016-09-04T11:00:13&#43;09:00">
        
  
  
  
  
    2016-09-04
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/paper">paper</a>
    
  

  </div>


    </div>









  </div>
  
</article>

</div>
<br>

<div class="box">

  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2016/08/28/adaboost%E3%81%8B%E3%82%89large-margin-distribution-machine%E3%81%AE%E6%B5%81%E3%82%8C/">
          AdaBoostからLarge Margin Distribution Machineの流れ
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2016-08-28T18:59:58&#43;09:00">
        
  
  
  
  
    2016-08-28
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>









  </div>
  
</article>

</div>
<br>




            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">タグ</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/pytorch/">pytorch</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/nlp/">nlp</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/machine_learning/">machine_learning</a>

                  </div>
                
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/" data-tooltip="[Colab] Googleの無料GPU環境を使うための準備">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">次</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/" data-tooltip="[PyTorch] Datasetの読み込みにかかるメモリ消費量を節約する">
              
                  <span class="hide-xs hide-sm text-small icon-mr">前</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#table-of-contents">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2020 Takuya Makino. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="1">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/" data-tooltip="[Colab] Googleの無料GPU環境を使うための準備">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">次</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/" data-tooltip="[PyTorch] Datasetの読み込みにかかるメモリ消費量を節約する">
              
                  <span class="hide-xs hide-sm text-small icon-mr">前</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#table-of-contents">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="1">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Ftma15.github.io%2Fblog%2F2020%2F03%2F10%2Fpytorch%25E8%2587%25AA%25E7%2584%25B6%25E8%25A8%2580%25E8%25AA%259E%25E5%2587%25A6%25E7%2590%2586-%25E3%2582%2588%25E3%2582%258A%25E5%25B0%2591%25E3%2581%25AA%25E3%2581%2584%25E3%2583%2591%25E3%2583%2587%25E3%2582%25A3%25E3%2583%25B3%25E3%2582%25B0%25E3%2581%25A7%25E3%2583%259F%25E3%2583%258B%25E3%2583%2590%25E3%2583%2583%25E3%2583%2581%25E5%25AD%25A6%25E7%25BF%2592%25E3%2581%2599%25E3%2582%258B%25E6%2596%25B9%25E6%25B3%2595%2F">
          <i class="fa fa-twitter"></i><span>Twitterで共有</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
    
    <h4 id="about-card-name">Takuya Makino</h4>
    
      <div id="about-card-bio">自然言語処理の研究開発者。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、Python、C++に関する記事が多めです。</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        自然言語処理の研究開発に従事
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Kanagawa, Japan
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://tma15.github.io/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://tma15.github.io/js/script-pcw6v3xilnxydl1vddzazdverrnn9ctynvnxgwho987mfyqkuylcb1nlt.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
  




    
  </body>
</html>

