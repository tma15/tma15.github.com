<!DOCTYPE html>
<html lang="ja">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.110.0 with theme Tranquilpeak 0.4.7-BETA">
<meta name="author" content="Takuya Makino">
<meta name="keywords" content="neural_network, nlp, pytorch, python, google-colab, machine_learning">
<meta name="description" content="単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。
本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。">
<meta name="viewport" content="width=device-width,initial-scale=1.0">


<meta property="og:description" content="単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。
本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。">
<meta property="og:type" content="article">
<meta property="og:title" content="[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)">
<meta name="twitter:title" content="[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)">
<meta property="og:url" content="https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
<meta property="twitter:url" content="https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
<meta property="og:site_name" content="Now is better than never.">
<meta property="og:description" content="単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。
本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。">
<meta name="twitter:description" content="単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。
本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。">
<meta property="og:locale" content="ja">

  
    <meta property="article:published_time" content="2020-03-15T15:24:03">
  
  
    <meta property="article:modified_time" content="2020-03-15T15:24:03">
  
  
  
    
      <meta property="article:section" content="neural_network">
    
      <meta property="article:section" content="nlp">
    
      <meta property="article:section" content="pytorch">
    
      <meta property="article:section" content="python">
    
      <meta property="article:section" content="google-colab">
    
      <meta property="article:section" content="machine_learning">
    
  
  
    
      <meta property="article:tag" content="neural_network">
    
      <meta property="article:tag" content="nlp">
    
      <meta property="article:tag" content="pytorch">
    
      <meta property="article:tag" content="python">
    
      <meta property="article:tag" content="google-colab">
    
      <meta property="article:tag" content="machine_learning">
    
  


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@tma15">


  <meta name="twitter:creator" content="@tma15">






  <meta property="og:image" content="https://tma15.github.io/img/2020/03/15/lstm-lm.png">
  <meta property="twitter:image" content="https://tma15.github.io/img/2020/03/15/lstm-lm.png">





  <meta property="og:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">


    <title>[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)</title>

    <link rel="icon" href="https://tma15.github.io/favicon.png">
    

    

    <link rel="canonical" href="https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">

    
    <script type="text/javascript" async
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
          });
    </script>


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
          (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-5663917297524414",
                  enable_page_level_ads: true
                });
    </script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://tma15.github.io/css/style-twzjdbqhmnnacqs0pwwdzcdbt8yhv8giawvjqjmyfoqnvazl0dalmnhdkvp7.min.css" />
    
    
      
        <link rel="stylesheet"  href="https://tma15.github.io/css/mystyle.css">
      
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-20414370-4', 'auto');
	
	ga('send', 'pageview');
}
</script>
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="5">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://tma15.github.io/">Now is better than never.</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://tma15.github.io/#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=90" alt="プロフィール画像" />
      
    
    </a>
  


  
  
  
  
  
  
  

  
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-10778777140"></script>
  <script>
      window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'AW-10778777140');
  </script>
</header>

      <nav id="sidebar" data-behavior="5">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://tma15.github.io/#about">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
        </a>
        <h4 class="sidebar-profile-name">Takuya Makino</h4>
        
          <h5 class="sidebar-profile-bio">自然言語処理の研究開発に従事しています。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、プログラミング、日々の生活について扱います。詳細は<a href="https://tma15.github.io/about/">プロフィール</a>を御覧ください。</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">ホーム</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">タグ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">アーカイブ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">プロフィール</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/inquiry">
    
      
      
      <span class="sidebar-button-desc">お問い合わせ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/privacy-policy">
    
      
      
      <span class="sidebar-button-desc">プライバシーポリシー</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  
    <br>

      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle"
      style="display:block; text-align:center;"
      data-ad-layout="in-article"
      data-ad-format="fluid"
      data-ad-client="ca-pub-5663917297524414"
      data-ad-slot="8357823829"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

  </div>
</nav>

      

      <div id="main" data-behavior="5"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      [自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-03-15T15:24:03&#43;09:00">
        
  
  
  
  
    2020-03-15
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/google-colab">google-colab</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


</div>
          

          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>単語の系列 (たとえば文や文書) に対して確率を割り当てるようなモデルは言語モデルと呼ばれています。
古くはN-gram言語モデルが用いられました。
最近ではより広い文脈を考慮したり、単語スパースネスの問題に対処できるニューラルネットワークに基づく言語モデル (ニューラル言語モデル) が良く用いられます。
ニューラル言語モデルは文書分類、情報抽出、機械翻訳などの自然言語処理の様々なタスクで用いられます。
本記事ではコード付きでLSTMに基づく言語モデルおよびその学習方法を説明します。
本記事を読むことで、LSTMに基づく言語モデルの概要、学習の流れを理解できます。</p>
<h2 id="table-of-contents">目次</h2><nav id="TableOfContents">
  <ul>
    <li><a href="#語彙">語彙</a></li>
    <li><a href="#lstmに基づく言語モデル">LSTMに基づく言語モデル</a></li>
    <li><a href="#言語モデルの学習における処理手順">言語モデルの学習における処理手順</a>
      <ul>
        <li><a href="#前処理-語彙の構築と単語をindexへ変換">前処理 (語彙の構築と単語をindexへ変換)</a></li>
        <li><a href="#学習部分-truncated-backpropagation-through-time">学習部分 (Truncated Backpropagation Through Time)</a></li>
      </ul>
    </li>
    <li><a href="#おわり">おわり</a></li>
  </ul>
</nav>
<p>本記事で掲載しているコードは以下のようにライブラリを利用します。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> collections 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> shutil
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span></code></pre></div><p>またPyTorchは1.4.0を利用しています。</p>
<h2 id="語彙">語彙</h2>
<p>ニューラル言語モデルを実装するにあたり、モデルが扱う単語の集合 (語彙) を扱うクラスを作成します。
このクラスは単語を対応するindexに変換したり、その逆の処理をするために用います。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Vocabulary</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>index2item <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>item2index <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __len__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> len(self<span style="color:#f92672">.</span>item2index)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __contains__(self, item):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> item <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>item2index<span style="color:#f92672">.</span>keys()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add_item</span>(self, item):
</span></span><span style="display:flex;"><span>        index <span style="color:#f92672">=</span> len(self<span style="color:#f92672">.</span>item2index)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>index2item<span style="color:#f92672">.</span>append(item)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>item2index[item] <span style="color:#f92672">=</span> index
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_item</span>(self, index):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>index2item[index]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_index</span>(self, item):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>item2index[item]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">save</span>(self, vocab_file):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(vocab_file, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>item2index:
</span></span><span style="display:flex;"><span>                print(word, file<span style="color:#f92672">=</span>f)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">@classmethod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load</span>(cls, vocab_file):
</span></span><span style="display:flex;"><span>        vocab <span style="color:#f92672">=</span> cls()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(vocab_file) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> f:
</span></span><span style="display:flex;"><span>                word <span style="color:#f92672">=</span> line<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>                vocab<span style="color:#f92672">.</span>item2index[word] <span style="color:#f92672">=</span> len(vocab<span style="color:#f92672">.</span>item2index)
</span></span><span style="display:flex;"><span>                vocab<span style="color:#f92672">.</span>index2item<span style="color:#f92672">.</span>append(word)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> vocab
</span></span></code></pre></div>

<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5663917297524414"
     data-ad-slot="8357823829"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="lstmに基づく言語モデル">LSTMに基づく言語モデル</h2>
<p>言語モデルは単語列 $(x_1, x_2, &hellip;, x_n)$ に対して生成確率 $p(x_1, x_2, &hellip;, x_n)$を割り当てます。
生成確率は以下のように分解することができます。</p>
<p>$$
\begin{eqnarray}
p(x_1,&hellip;, x_n) &amp;=&amp; p(x_1|h_1) p(x_2|h_2) p(x_3|h_3) &hellip; p(x_n|h_n) \\\
&amp;=&amp; \Pi_{k=1}^{n} p(x_k|h_{k})
\end{eqnarray}
$$</p>
<p>$p(x_k|h_k)$ は隠れ状態 $h_k$ が与えられたときの単語 $x_k$ の生成確率を表すものとします。
また $p(x_k|h_k)$ は以下のように計算します。</p>
<p>$$
p(x_k|h_k) = \frac{\exp(w_{x_k} h_k)}{\sum_{\bar{x}} \exp(w_{\bar{x}} h_k)}
$$</p>
<p>$h_t$ はLSTMによって計算された文脈情報のようなもので、直前のLSTMの出力を用いて再帰的に計算します。この式はsoftmax関数と呼ばれています。$w$は学習対象のパラメータです。</p>
<p>$$
h_k, c_k = f(e_{x_{k-1}}, h_{k-1}, c_{k-1})
$$</p>
<p>$f$ はLSTMの隠れ状態を計算する関数とします。
$e_{x_{k-1}}$ は$x_{k-1}$ に対して割り当てる分散表現とします。</p>
<p>LSTMに基づく言語モデルの概要図は以下のようになります。
まず単語を対応する分散表現に変換します (Embedding)。
次に、LSTMへ分散表現と、直前のLSTMの出力を入力し、現在の出力を得ます (LSTM)。
LSTMの出力に基づいて、語彙に登録されている単語数の次元に線形変換します (Linear)。
最後に、正解の単語の負の対数尤度を計算します (CrossEntropy)。</p>

 
  
  
  
  
    
      
    
  
    
      
    
  
    
  

 
  
  
  
  
    
  
    
      
    
  

<div class="figure right" >
  
    <a class="fancybox" href="https://tma15.github.io/img/2020/03/15/lstm-lm.png" title="LSTMに基づく言語モデルの概要図" data-fancybox-group="">
  
    <img class="fig-img" src="https://tma15.github.io/img/2020/03/15/lstm-lm.png"  alt="LSTMに基づく言語モデルの概要図">
  
    </a>
  
   
    <span class="caption">LSTMに基づく言語モデルの概要図</span>
  
</div>

  <div style="clear:both;"></div>

<p>PyTorchで実装するのは非常に簡単で、単語列を与えて、softmax層で確率として正規化する直前の値までを計算するのは3行でかけます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">LanguageModel</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(
</span></span><span style="display:flex;"><span>            self,
</span></span><span style="display:flex;"><span>            vocab,
</span></span><span style="display:flex;"><span>            dim_emb<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>,
</span></span><span style="display:flex;"><span>            dim_hid<span style="color:#f92672">=</span><span style="color:#ae81ff">256</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>vocab <span style="color:#f92672">=</span> vocab
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embed <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Embedding(len(vocab), dim_emb)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>rnn <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>LSTM(dim_emb, dim_hid, batch_first<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>out <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(dim_hid, len(vocab))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, state<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>embed(x)
</span></span><span style="display:flex;"><span>        x, (h, c) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>rnn(x, state)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>out(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x, (h, c)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate</span>(self, start<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>, max_len<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> start <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            start <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>choice(self<span style="color:#f92672">.</span>vocab<span style="color:#f92672">.</span>index2item)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        idx <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>embed<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>new_full(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>vocab<span style="color:#f92672">.</span>get_index(start),
</span></span><span style="display:flex;"><span>            dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long)
</span></span><span style="display:flex;"><span>        decoded <span style="color:#f92672">=</span> [start]
</span></span><span style="display:flex;"><span>        state <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        unk <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;unk&gt;&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(max_len):
</span></span><span style="display:flex;"><span>            x, state <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>forward(idx, state)
</span></span><span style="display:flex;"><span>            x[:, :, unk] <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>float(<span style="color:#e6db74">&#39;inf&#39;</span>)
</span></span><span style="display:flex;"><span>            idx <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(x, dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            word <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>vocab<span style="color:#f92672">.</span>get_item(idx<span style="color:#f92672">.</span>item())
</span></span><span style="display:flex;"><span>            decoded<span style="color:#f92672">.</span>append(word)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(decoded)
</span></span></code></pre></div><h2 id="言語モデルの学習における処理手順">言語モデルの学習における処理手順</h2>
<p>ニューラルネットワークの実装よりも大変なのが実際にデータを読みこんで学習処理を実施する箇所です。</p>
<h3 id="前処理-語彙の構築と単語をindexへ変換">前処理 (語彙の構築と単語をindexへ変換)</h3>
<p>前処理では語彙を構築して、単語列をindexの列に変換する処理を実装します。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Preprocessor</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(
</span></span><span style="display:flex;"><span>            self,
</span></span><span style="display:flex;"><span>            data_file,
</span></span><span style="display:flex;"><span>            bin_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;data-bin&#39;</span>,
</span></span><span style="display:flex;"><span>            vocab_file <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;vocab&#39;</span>,
</span></span><span style="display:flex;"><span>            n_max_word<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>,
</span></span><span style="display:flex;"><span>            num_token_per_file<span style="color:#f92672">=</span><span style="color:#ae81ff">1000000</span>,
</span></span><span style="display:flex;"><span>            force_preprocess<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>data_file <span style="color:#f92672">=</span> data_file
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>vocab_file <span style="color:#f92672">=</span> vocab_file
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>n_max_word <span style="color:#f92672">=</span> n_max_word
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_token_per_file <span style="color:#f92672">=</span> num_token_per_file
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bin_dir <span style="color:#f92672">=</span> bin_dir
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>force_preprocess <span style="color:#f92672">=</span> force_preprocess
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">run</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>force_preprocess:
</span></span><span style="display:flex;"><span>            vocab <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_build_vocab()
</span></span><span style="display:flex;"><span>            shutil<span style="color:#f92672">.</span>rmtree(self<span style="color:#f92672">.</span>bin_dir)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>_binarize_text(vocab)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(self<span style="color:#f92672">.</span>vocab_file):
</span></span><span style="display:flex;"><span>            vocab <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_build_vocab()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            vocab <span style="color:#f92672">=</span> Vocabulary<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;vocab&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(self<span style="color:#f92672">.</span>bin_dir):
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>_binarize_text(vocab)
</span></span></code></pre></div><p>語彙の構築は以下の関数で実装します。
パディング用の特殊単語、語彙に登録されていない単語 (未知語) を表す単語および出現頻度が高い上位の単語集合を語彙とします。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_build_vocab</span>(self):
</span></span><span style="display:flex;"><span>        counter <span style="color:#f92672">=</span> collections<span style="color:#f92672">.</span>Counter()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(self<span style="color:#f92672">.</span>data_file) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> f:
</span></span><span style="display:flex;"><span>                words <span style="color:#f92672">=</span> line<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>split()
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> words:
</span></span><span style="display:flex;"><span>                    counter[word] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        vocab <span style="color:#f92672">=</span> Vocabulary()
</span></span><span style="display:flex;"><span>        vocab<span style="color:#f92672">.</span>add_item(<span style="color:#e6db74">&#39;&lt;pad&gt;&#39;</span>)
</span></span><span style="display:flex;"><span>        vocab<span style="color:#f92672">.</span>add_item(<span style="color:#e6db74">&#39;&lt;unk&gt;&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> word, _ <span style="color:#f92672">in</span> counter<span style="color:#f92672">.</span>most_common(self<span style="color:#f92672">.</span>n_max_word <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span>):
</span></span><span style="display:flex;"><span>            vocab<span style="color:#f92672">.</span>add_item(word)
</span></span><span style="display:flex;"><span>        vocab<span style="color:#f92672">.</span>save(self<span style="color:#f92672">.</span>vocab_file)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> vocab
</span></span></code></pre></div><p>単語列をindexの列に変換する処理は以下の関数で実装します。
ある程度行数が多いデータは、分割して保存するようにします。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_binarize_text</span>(self, vocab):
</span></span><span style="display:flex;"><span>        data <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        unk <span style="color:#f92672">=</span> vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;unk&gt;&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(self<span style="color:#f92672">.</span>bin_dir):
</span></span><span style="display:flex;"><span>            os<span style="color:#f92672">.</span>makedirs(self<span style="color:#f92672">.</span>bin_dir)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        num_file <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        num_token <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(self<span style="color:#f92672">.</span>data_file) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            lines <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> f:
</span></span><span style="display:flex;"><span>                lines<span style="color:#f92672">.</span>append(line)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            random<span style="color:#f92672">.</span>shuffle(lines)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> lines:
</span></span><span style="display:flex;"><span>                words <span style="color:#f92672">=</span> line<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>split()
</span></span><span style="display:flex;"><span>                indices <span style="color:#f92672">=</span> [vocab<span style="color:#f92672">.</span>get_index(word) <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> vocab
</span></span><span style="display:flex;"><span>                           <span style="color:#66d9ef">else</span> unk <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> words]
</span></span><span style="display:flex;"><span>                data <span style="color:#f92672">+=</span> indices
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                num_token <span style="color:#f92672">+=</span> len(indices)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> len(data) <span style="color:#f92672">&gt;=</span> self<span style="color:#f92672">.</span>num_token_per_file:
</span></span><span style="display:flex;"><span>                    data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(data)
</span></span><span style="display:flex;"><span>                    torch<span style="color:#f92672">.</span>save(data, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>bin_dir<span style="color:#e6db74">}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{</span>num_file<span style="color:#e6db74">}</span><span style="color:#e6db74">.pt&#39;</span>)
</span></span><span style="display:flex;"><span>                    num_file <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                    batch <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(self<span style="color:#f92672">.</span>bin_dir):
</span></span><span style="display:flex;"><span>            os<span style="color:#f92672">.</span>makedirs(self<span style="color:#f92672">.</span>bin_dir)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(data)
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>save(data, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>bin_dir<span style="color:#e6db74">}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{</span>num_file<span style="color:#e6db74">}</span><span style="color:#e6db74">.pt&#39;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Data size: </span><span style="color:#e6db74">{</span>num_token<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>また保存したデータは以下のように読み込んで使います。
ここでは指定されたindexに対応するファイルのデータを読み込んで返すだけです。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Dataset</span>(torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, data_dir):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>filenames <span style="color:#f92672">=</span> [os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(data_dir, p) <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> os<span style="color:#f92672">.</span>listdir(data_dir)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __len__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> len(self<span style="color:#f92672">.</span>filenames)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __getitem__(self, index):
</span></span><span style="display:flex;"><span>        tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(self<span style="color:#f92672">.</span>filenames[index])
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> tensor
</span></span></code></pre></div><h3 id="学習部分-truncated-backpropagation-through-time">学習部分 (Truncated Backpropagation Through Time)</h3>
<p>学習時は以下のような負の対数尤度を損失関数 $L$ として得られた勾配に基づいて言語モデルのパラメータ $\theta$ を学習します。
負の対数尤度が小さくなるほど、学習データ中の単語列に対して高い生成確率を割り当てることができます。</p>
<p>$$
\begin{eqnarray}
L(\theta) &amp;=&amp; -\log p(x_1, …, x_n) \\\
&amp;=&amp; - \sum_{k=1}^{n} \log p(x_k|h_{k})
\end{eqnarray}
$$</p>
<p>単語列が長いほど、保持しなければならない勾配の数が大きくなり、消費メモリの増加や計算速度の低下につながります。
実用的には、単語列の先頭から末尾まですべてを一度に処理してパラメータを更新せず、単語列を部分的に処理してパラメータを更新します。
具体的にはTruncated Backpropagation Through Time (TBPTT) という方法でLSTMに基づく言語モデルを学習します。 以下にTBPTTの概要図を示します。
<br></p>

 
  
  
  
  
    
      
    
  
    
      
    
  
    
  

 
  
  
  
  
    
  
    
      
    
  

<div class="figure right" >
  
    <a class="fancybox" href="https://tma15.github.io/img/2020/03/15/tbptt.png" title="TBPTTの概要図。枠線単位で損失を計算してパラメータを更新する。LSTMの隠れ状態は直前の出力で初期化しますが、その出力はパラメータ更新の対象にはなりません。" data-fancybox-group="">
  
    <img class="fig-img" src="https://tma15.github.io/img/2020/03/15/tbptt.png"  alt="TBPTTの概要図。枠線単位で損失を計算してパラメータを更新する。LSTMの隠れ状態は直前の出力で初期化しますが、その出力はパラメータ更新の対象にはなりません。">
  
    </a>
  
   
    <span class="caption">TBPTTの概要図。枠線単位で損失を計算してパラメータを更新する。LSTMの隠れ状態は直前の出力で初期化しますが、その出力はパラメータ更新の対象にはなりません。</span>
  
</div>

  <div style="clear:both;"></div>

<p>単語列の長さが5の事例に対して、固定長の長さ2で単語列を分割し、先頭から順に部分列を対象に損失を計算し、得られた勾配に基づいてパラメータを更新します。直前のLSTMの隠れ状態は、直前の部分列のLSTMの出力を用います。この出力は、現在の部分列を用いてパラメータを更新する際の対象とはなりません。このように処理することで、単語列を分割して処理することができるため、消費メモリの増加や計算速度の低下を改善することができます。</p>


<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5663917297524414"
     data-ad-slot="8357823829"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">collate_fn</span>(batch):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> batch[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">LanguageModelTrainer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(
</span></span><span style="display:flex;"><span>            self,
</span></span><span style="display:flex;"><span>            model,
</span></span><span style="display:flex;"><span>            optimizer,
</span></span><span style="display:flex;"><span>            data_dir,
</span></span><span style="display:flex;"><span>            device,
</span></span><span style="display:flex;"><span>            max_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>            batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span>,
</span></span><span style="display:flex;"><span>            log_interval<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>,
</span></span><span style="display:flex;"><span>            sequence_length<span style="color:#f92672">=</span><span style="color:#ae81ff">250</span>,
</span></span><span style="display:flex;"><span>            clip<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>optimizer <span style="color:#f92672">=</span> optimizer
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>device <span style="color:#f92672">=</span> device
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_epochs <span style="color:#f92672">=</span> max_epochs
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>batch_size <span style="color:#f92672">=</span> batch_size
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>log_interval <span style="color:#f92672">=</span> log_interval
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>clip <span style="color:#f92672">=</span> clip
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>sequence_length <span style="color:#f92672">=</span> sequence_length
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dataset <span style="color:#f92672">=</span> Dataset(data_dir)
</span></span></code></pre></div><p>TBPTTを実装しているのは以下の箇所です。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train</span>(self):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;Run trainer&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        pad <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;pad&gt;&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>dataset,
</span></span><span style="display:flex;"><span>            shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>            collate_fn<span style="color:#f92672">=</span>collate_fn,
</span></span><span style="display:flex;"><span>            num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        start_at <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(self<span style="color:#f92672">.</span>max_epochs):
</span></span><span style="display:flex;"><span>            loss_epoch <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.</span>
</span></span><span style="display:flex;"><span>            num_token <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            step <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> data_loader:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># batchfy</span>
</span></span><span style="display:flex;"><span>                num_batch <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>) <span style="color:#f92672">//</span> self<span style="color:#f92672">.</span>batch_size
</span></span><span style="display:flex;"><span>                data <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>narrow(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, num_batch <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>batch_size)
</span></span><span style="display:flex;"><span>                batch <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>view(self<span style="color:#f92672">.</span>batch_size, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                state <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> seen_batch, i <span style="color:#f92672">in</span> enumerate(range(<span style="color:#ae81ff">0</span>, batch<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>), self<span style="color:#f92672">.</span>sequence_length), start<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>                    e <span style="color:#f92672">=</span> min(i <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>sequence_length, batch<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>                    batch_i <span style="color:#f92672">=</span> batch[:, i: e]
</span></span><span style="display:flex;"><span>                    batch_i <span style="color:#f92672">=</span> batch_i<span style="color:#f92672">.</span>to(self<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>                    step <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    input_i <span style="color:#f92672">=</span> batch_i[:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>                    target_i <span style="color:#f92672">=</span> batch_i[:, <span style="color:#ae81ff">1</span>:]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    x, (h, c) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(input_i, state)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    vocab_size <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>                    num_token_i <span style="color:#f92672">=</span> (target_i <span style="color:#f92672">!=</span> pad)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                    loss <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>nll_loss(
</span></span><span style="display:flex;"><span>                        F<span style="color:#f92672">.</span>log_softmax(x, dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>contiguous()<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, vocab_size),
</span></span><span style="display:flex;"><span>                        target_i<span style="color:#f92672">.</span>contiguous()<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>                        reduction<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sum&#39;</span>,
</span></span><span style="display:flex;"><span>                        ignore_index<span style="color:#f92672">=</span>pad)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    self<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    loss<span style="color:#f92672">.</span>div(num_token_i)<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>clip_grad_norm_(self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>parameters(), self<span style="color:#f92672">.</span>clip)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    self<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>                    num_token <span style="color:#f92672">+=</span> num_token_i
</span></span><span style="display:flex;"><span>                    loss_epoch <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                    h <span style="color:#f92672">=</span> h<span style="color:#f92672">.</span>clone()<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>                    c <span style="color:#f92672">=</span> c<span style="color:#f92672">.</span>clone()<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>                    state <span style="color:#f92672">=</span> (h, c)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">if</span> step <span style="color:#f92672">%</span> self<span style="color:#f92672">.</span>log_interval <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                        elapsed <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start_at
</span></span><span style="display:flex;"><span>                        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;epoch:</span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74"> step:</span><span style="color:#e6db74">{</span>step<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>                              <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; loss:</span><span style="color:#e6db74">{</span>loss_epoch<span style="color:#f92672">/</span>num_token<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>                              <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; elapsed:</span><span style="color:#e6db74">{</span>elapsed<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            loss_epoch <span style="color:#f92672">/=</span> num_token
</span></span><span style="display:flex;"><span>            ppl <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>exp(loss_epoch)
</span></span><span style="display:flex;"><span>            elapsed <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start_at
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#39;-&#39;</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">50</span>)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;epoch:</span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74"> loss:</span><span style="color:#e6db74">{</span>loss_epoch<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39; ppl:</span><span style="color:#e6db74">{</span>ppl<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> elapsed:</span><span style="color:#e6db74">{</span>elapsed<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>            decoded <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>generate()
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Sampled: </span><span style="color:#e6db74">{</span>decoded<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#39;-&#39;</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">50</span>)
</span></span></code></pre></div><p>以下の関数を実装し、Google Colaboratoryで実行します。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">run_trainer</span>(
</span></span><span style="display:flex;"><span>        train_file,
</span></span><span style="display:flex;"><span>        max_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>,
</span></span><span style="display:flex;"><span>        batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>,
</span></span><span style="display:flex;"><span>        bin_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;data-bin&#39;</span>,
</span></span><span style="display:flex;"><span>        device<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cuda:0&#39;</span>,
</span></span><span style="display:flex;"><span>        force_preprocess<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    preprocessor <span style="color:#f92672">=</span> Preprocessor(
</span></span><span style="display:flex;"><span>        train_file,
</span></span><span style="display:flex;"><span>        bin_dir<span style="color:#f92672">=</span>bin_dir,
</span></span><span style="display:flex;"><span>        force_preprocess<span style="color:#f92672">=</span>force_preprocess)
</span></span><span style="display:flex;"><span>    preprocessor<span style="color:#f92672">.</span>run()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    vocab <span style="color:#f92672">=</span> Vocabulary<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;vocab&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Vocabulary size: </span><span style="color:#e6db74">{</span>len(vocab)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> LanguageModel(vocab)
</span></span><span style="display:flex;"><span>    print(model)
</span></span><span style="display:flex;"><span>    optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>parameters())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    trainer <span style="color:#f92672">=</span> LanguageModelTrainer(
</span></span><span style="display:flex;"><span>        model,
</span></span><span style="display:flex;"><span>        optimizer,
</span></span><span style="display:flex;"><span>        bin_dir,
</span></span><span style="display:flex;"><span>        device,
</span></span><span style="display:flex;"><span>        max_epochs<span style="color:#f92672">=</span>max_epochs,
</span></span><span style="display:flex;"><span>        batch_size<span style="color:#f92672">=</span>batch_size)
</span></span><span style="display:flex;"><span>    trainer<span style="color:#f92672">.</span>train()
</span></span></code></pre></div><p>上記のプログラムを <code>lm.py</code> に記述し、Google Driveにアップロードします。
ただし、ColabからGoogle Driveがマウントできていて、アップロード先は、ここではja-language-modelというフォルダとします。
Colabのセルには以下を記述し、実行します。</p>
<p>データのダウンロードは以下の記述を実行します。</p>
<pre tabindex="0"><code>!cd drive/My Drive/ja-language-model/
!wget https://s3-ap-northeast-1.amazonaws.com/dev.tech-sketch.jp/chakki/public/ja.text8.zip
!unzip ja.text8.zip
</code></pre><p>学習には以下の記述を実行します。</p>
<pre tabindex="0"><code>import sys; sys.path.append(&#39;drive/My Drive/ja-language-model&#39;)
import lm
lm.run_trainer(&#39;drive/My Drive/ja-language-model/ja.text8&#39;)
</code></pre><p>実行すると以下のように学習が進みます。</p>
<pre tabindex="0"><code>Run trainer
epoch:0 step:200 loss:5.63 elapsed:55.05
epoch:0 step:400 loss:5.20 elapsed:110.60
epoch:0 step:600 loss:4.98 elapsed:166.52
epoch:0 step:800 loss:4.84 elapsed:223.03
epoch:0 step:1000 loss:4.73 elapsed:279.79
--------------------------------------------------
epoch:0 loss:4.70 ppl:110.11 elapsed:296.12
Sampled: なお 「 」 「 私 」 と 述べ て いる 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある 。 この よう な もの で ある
--------------------------------------------------
epoch:1 step:200 loss:4.15 elapsed:353.53
epoch:1 step:400 loss:4.11 elapsed:410.61
epoch:1 step:600 loss:4.08 elapsed:467.49
epoch:1 step:800 loss:4.05 elapsed:524.66
epoch:1 step:1000 loss:4.02 elapsed:581.87
--------------------------------------------------
epoch:1 loss:4.01 ppl:55.29 elapsed:598.35
Sampled: タックル ., 市 うがっ ) が 、 この よう な もの で ある 。 この よう な もの は 、 「 私 の 中 で は ない 」 と 述べ て いる 。 また 、 「 私 は 、 「 私 の 」 と 述べ て いる 。 また 、 「 私 は 、 「 私 の 」 と 述べ て いる 。 また 、 「 私 は 、 「 私 の 」 と 述べ て いる 。 また 、 「 私 は 、 「 私 の 」 と 述べ て いる 。 また 、 「 私 は 、 「 私
--------------------------------------------------

...

epoch:14 step:200 loss:3.31 elapsed:4317.59
epoch:14 step:400 loss:3.31 elapsed:4375.43
epoch:14 step:600 loss:3.31 elapsed:4433.01
epoch:14 step:800 loss:3.30 elapsed:4490.79
epoch:14 step:1000 loss:3.30 elapsed:4548.64
--------------------------------------------------
epoch:14 loss:3.30 ppl:27.20 elapsed:4565.25
Sampled: 事項 公卿 導い 重ねる 後 休 号 （ 明治 元年 ） に は 、 「 第 二 次 世界 大戦 の 第 二 次 世界 大戦 の 第 二 次 世界 大戦 の 第 二 次 世界 大戦 の 第 二 次 世界 大戦 の 第 二 次 世界 大戦 の 終戦 後 、 陸軍 士官 学校 （ 現 ・ 海軍 ） の 前身 ） に 入隊 し た 。 1945 年 （ 昭和 20 年 ） 、 第 二 次 世界 大戦 の 終戦 により 、 1945 年 （ 昭和 20 年 ） に は 陸軍 航空 隊 （ 現
--------------------------------------------------
</code></pre><p>規模が大きいデータで時間をかけた学習を実施していないため、生成されるテキストはまだ自然ではありませんが、言語モデルの評価尺度のひとつであるperplexityが少しずつ低下しているのがわかります。</p>
<h2 id="おわり">おわり</h2>
<p>本記事ではLSTMに基づく言語モデルの概要およびその学習方法のひとつであるTruncated Backpropagation Through Timeをコード付きで説明しました。
日本語のテキストを用いてColab上で学習し、生成結果を確認しました。</p>
<p>本記事で掲載したプログラムは<a href="https://github.com/tma15/lstm-lm">ここ</a>にアップロードしてあります。</p>
<p><a href="//af.moshimo.com/af/c/click?a_id=2804718&amp;p_id=54&amp;pc_id=54&amp;pl_id=616&amp;url=https%3A%2F%2Fitem.rakuten.co.jp%2Fbooxstore%2Fbk-4839970254%2F&amp;m=http%3A%2F%2Fm.rakuten.co.jp%2Fbooxstore%2Fi%2F12384087%2F" rel="nofollow" referrerpolicy="no-referrer-when-downgrade"><img src="//thumbnail.image.rakuten.co.jp/@0_mall/booxstore/cabinet/00979/bk4839970254.jpg?_ex=128x128" alt="" style="border: none;" /><br />つくりながら学ぶ！PyTorchによる発展ディープラーニング／小川雄太郎【3000円以上送料無料】</a><img src="//i.moshimo.com/af/i/impression?a_id=2804718&amp;p_id=54&amp;pc_id=54&amp;pl_id=616" alt="" width="1" height="1" style="border: 0px;" /></p>
              

              <br>
              <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
              <ins class="adsbygoogle"
              style="display:block; text-align:center;"
              data-ad-layout="in-article"
              data-ad-format="fluid"
              data-ad-client="ca-pub-5663917297524414"
              data-ad-slot="8357823829"></ins>
              <script>
              (adsbygoogle = window.adsbygoogle || []).push({});
              </script>
    
              

<h3>関連記事</h3>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/">
          [PyTorch][自然言語処理] より少ないパディングでミニバッチ学習する方法
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-03-10T16:50:53&#43;09:00">
        
  
  
  
  
    2020-03-10
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2020/03/10/pytorch%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-%E3%82%88%E3%82%8A%E5%B0%91%E3%81%AA%E3%81%84%E3%83%91%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/pytorch-logo.png" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/">
          [PyTorch] Datasetの読み込みにかかるメモリ消費量を節約する
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-03-08T16:04:11&#43;09:00">
        
  
  
  
  
    2020-03-08
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2020/03/08/pytorch-dataset%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%AB%E3%81%8B%E3%81%8B%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E6%B6%88%E8%B2%BB%E9%87%8F%E3%82%92%E7%AF%80%E7%B4%84%E3%81%99%E3%82%8B/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/pytorch-logo.png" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/">
          [Colab] Googleの無料GPU環境を使うための準備
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-03-11T15:05:37&#43;09:00">
        
  
  
  
  
    2020-03-11
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/google-colab">google-colab</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/gpu">gpu</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/google-colab.png" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2019/09/04/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%87%BA%E5%8A%9B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E6%A4%9C%E7%B4%A2%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%95%E3%81%9B%E3%82%8B%E6%96%B9%E6%B3%95/">
          ニューラルネットの出力ベクトルを二値化して検索を高速化させる方法
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-09-04T18:19:54&#43;09:00">
        
  
  
  
  
    2019-09-04
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/acl2019">acl2019</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/paper">paper</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2019/09/04/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%87%BA%E5%8A%9B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E6%A4%9C%E7%B4%A2%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%95%E3%81%9B%E3%82%8B%E6%96%B9%E6%B3%95/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2019/learning-to-compress.PNG" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2013/11/10/scikit-learn%E3%81%AE%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%8A%E3%82%A4%E3%83%BC%E3%83%96%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E/">
          scikit-learnのソースコードリーディング（ナイーブベイズ分類）
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2013-11-10T00:00:00Z">
        
  
  
  
  
    2013-11-10
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/scikit-learn">scikit-learn</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2013/11/10/scikit-learn%E3%81%AE%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%89%E3%83%AA%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%8A%E3%82%A4%E3%83%BC%E3%83%96%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/scikit-learn-logo-thumb.png" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>




              <h3>最近の記事</h3>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2023/01/30/huggingface/datasets%E8%A4%87%E6%95%B0%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%82%92%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%A6%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%99%E3%82%8B/">
          【huggingface/datasets】複数のデータセットを組み合わせてサンプリングする 
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2023-01-30T15:08:57&#43;09:00">
        
  
  
  
  
    2023-01-30
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/huggingface">huggingface</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2023/01/30/huggingface/datasets%E8%A4%87%E6%95%B0%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%82%92%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%A6%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%99%E3%82%8B/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/huggingface.png" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2023/01/28/pythonpre-commit%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%82%B3%E3%83%9F%E3%83%83%E3%83%88%E5%89%8D%E3%81%AB%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E8%87%AA%E5%8B%95%E6%A4%9C%E6%9F%BB%E3%81%99%E3%82%8B/">
          【Python】pre-commitを使ってコミット前にプログラムを自動検査する
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2023-01-28T15:51:28&#43;09:00">
        
  
  
  
  
    2023-01-28
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/git">git</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/pre-commit">pre-commit</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2023/01/28/pythonpre-commit%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%82%B3%E3%83%9F%E3%83%83%E3%83%88%E5%89%8D%E3%81%AB%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E8%87%AA%E5%8B%95%E6%A4%9C%E6%9F%BB%E3%81%99%E3%82%8B/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/pre-commit.png" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2023/01/08/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%83%95%E3%83%AA%E3%83%BC%E3%81%A7%E4%BD%BF%E3%81%88%E3%82%8B%E5%A4%A7%E8%A6%8F%E6%A8%A1%E3%81%AA%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9/">
          【自然言語処理】フリーで使える大規模な日本語テキストコーパス
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2023-01-08T15:31:24&#43;09:00">
        
  
  
  
  
    2023-01-08
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2023/01/08/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%83%95%E3%83%AA%E3%83%BC%E3%81%A7%E4%BD%BF%E3%81%88%E3%82%8B%E5%A4%A7%E8%A6%8F%E6%A8%A1%E3%81%AA%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/books-gcb8377b8a_640.jpg" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2022/12/31/pythonpoetry%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E7%AE%A1%E7%90%86/">
          【Python】Poetryを使ったパッケージ管理
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2022-12-31T09:33:01&#43;09:00">
        
  
  
  
  
    2022-12-31
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/poetry">poetry</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2022/12/31/pythonpoetry%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E7%AE%A1%E7%90%86/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/poetry.png" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2022/12/29/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86a-general-language-assistant-as-a-laboratory-for-alignment%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/">
          【自然言語処理】A General Language Assistant as a Laboratory for Alignment【論文紹介】
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2022-12-29T10:05:49&#43;09:00">
        
  
  
  
  
    2022-12-29
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>
  </div>
  
    <a href="https://tma15.github.io/blog/2022/12/29/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86a-general-language-assistant-as-a-laboratory-for-alignment%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2022/12/cyberpunk-g0f0a64c80_640.jpg" width="100%"/>
      </div>
    </a>
  
</article>

</div>
<br>


            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">タグ</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/neural_network/">neural_network</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/nlp/">nlp</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/pytorch/">pytorch</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/python/">python</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/google-colab/">google-colab</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/machine_learning/">machine_learning</a>

                  </div>
                
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/22/flask-blueprint%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%82%A2%E3%83%97%E3%83%AA%E9%96%8B%E7%99%BA%E3%81%AE%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88/" data-tooltip="[Flask] Blueprintを使ったアプリ開発のテンプレート">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">次</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/" data-tooltip="[Colab] Googleの無料GPU環境を使うための準備">
              
                  <span class="hide-xs hide-sm text-small icon-mr">前</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#table-of-contents">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2023 Takuya Makino. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/22/flask-blueprint%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%82%A2%E3%83%97%E3%83%AA%E9%96%8B%E7%99%BA%E3%81%AE%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88/" data-tooltip="[Flask] Blueprintを使ったアプリ開発のテンプレート">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">次</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/" data-tooltip="[Colab] Googleの無料GPU環境を使うための準備">
              
                  <span class="hide-xs hide-sm text-small icon-mr">前</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#table-of-contents">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="5">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Ftma15.github.io%2Fblog%2F2020%2F03%2F15%2F%25E8%2587%25AA%25E7%2584%25B6%25E8%25A8%2580%25E8%25AA%259E%25E5%2587%25A6%25E7%2590%2586-lstm%25E3%2581%25AB%25E5%259F%25BA%25E3%2581%25A5%25E3%2581%258F%25E8%25A8%2580%25E8%25AA%259E%25E3%2583%25A2%25E3%2583%2587%25E3%2583%25AB%25E3%2581%25AE%25E5%25AD%25A6%25E7%25BF%2592-pytorch%25E3%2582%25B3%25E3%2583%25BC%25E3%2583%2589%25E4%25BB%2598%25E3%2581%258D%2F">
          <i class="fa fa-twitter"></i><span>Twitterで共有</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
    
    <h4 id="about-card-name">Takuya Makino</h4>
    
      <div id="about-card-bio">自然言語処理の研究開発に従事しています。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、プログラミング、日々の生活について扱います。詳細は<a href="https://tma15.github.io/about/">プロフィール</a>を御覧ください。</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        自然言語処理の研究開発に従事
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Kanagawa, Japan
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://tma15.github.io/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://tma15.github.io/js/script-pcw6v3xilnxydl1vddzazdverrnn9ctynvnxgwho987mfyqkuylcb1nlt.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
  




    
  </body>
</html>

