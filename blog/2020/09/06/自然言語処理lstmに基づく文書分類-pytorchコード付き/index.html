<!DOCTYPE html>
<html lang="ja">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.67.0 with theme Tranquilpeak 0.4.7-BETA">
<meta name="author" content="Takuya Makino">
<meta name="keywords" content="nlp, python, pytorch, neural_network, machine_learning, google-colab">
<meta name="description" content="本記事では日本語を対象としたLSTMに基づく文書分類モデルをPyTorchコード付きで紹介します。
以前、LSTMを用いた言語モデルについて紹介しました (
[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)
)
が、ニューラルネットワークを用いた自然言語処理の応用例として文書分類のほうがイメージしやすそうなので、こちらについても紹介したいと思います。
実験にはライブドアコーパスから作成した、記事の見出しに対して9つのカテゴリのうち、どれか1つが付与されたデータを使います。
本記事を読むことで日本語を対象に、ニューラルネットワークを活用した自然言語処理の概要を知ることができます。
また、PyTorchで事前学習済みの単語分散表現を扱う方法も紹介しています。">


<meta property="og:description" content="本記事では日本語を対象としたLSTMに基づく文書分類モデルをPyTorchコード付きで紹介します。
以前、LSTMを用いた言語モデルについて紹介しました (
[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)
)
が、ニューラルネットワークを用いた自然言語処理の応用例として文書分類のほうがイメージしやすそうなので、こちらについても紹介したいと思います。
実験にはライブドアコーパスから作成した、記事の見出しに対して9つのカテゴリのうち、どれか1つが付与されたデータを使います。
本記事を読むことで日本語を対象に、ニューラルネットワークを活用した自然言語処理の概要を知ることができます。
また、PyTorchで事前学習済みの単語分散表現を扱う方法も紹介しています。">
<meta property="og:type" content="article">
<meta property="og:title" content="【自然言語処理】LSTMに基づく文書分類 (PyTorchコード付き)">
<meta name="twitter:title" content="【自然言語処理】LSTMに基づく文書分類 (PyTorchコード付き)">
<meta property="og:url" content="https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
<meta property="twitter:url" content="https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
<meta property="og:site_name" content="Now is better than never.">
<meta property="og:description" content="本記事では日本語を対象としたLSTMに基づく文書分類モデルをPyTorchコード付きで紹介します。
以前、LSTMを用いた言語モデルについて紹介しました (
[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)
)
が、ニューラルネットワークを用いた自然言語処理の応用例として文書分類のほうがイメージしやすそうなので、こちらについても紹介したいと思います。
実験にはライブドアコーパスから作成した、記事の見出しに対して9つのカテゴリのうち、どれか1つが付与されたデータを使います。
本記事を読むことで日本語を対象に、ニューラルネットワークを活用した自然言語処理の概要を知ることができます。
また、PyTorchで事前学習済みの単語分散表現を扱う方法も紹介しています。">
<meta name="twitter:description" content="本記事では日本語を対象としたLSTMに基づく文書分類モデルをPyTorchコード付きで紹介します。
以前、LSTMを用いた言語モデルについて紹介しました (
[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)
)
が、ニューラルネットワークを用いた自然言語処理の応用例として文書分類のほうがイメージしやすそうなので、こちらについても紹介したいと思います。
実験にはライブドアコーパスから作成した、記事の見出しに対して9つのカテゴリのうち、どれか1つが付与されたデータを使います。
本記事を読むことで日本語を対象に、ニューラルネットワークを活用した自然言語処理の概要を知ることができます。
また、PyTorchで事前学習済みの単語分散表現を扱う方法も紹介しています。">
<meta property="og:locale" content="ja">

  
    <meta property="article:published_time" content="2020-09-06T09:46:04">
  
  
    <meta property="article:modified_time" content="2020-09-06T09:46:04">
  
  
  
    
      <meta property="article:section" content="nlp">
    
      <meta property="article:section" content="python">
    
      <meta property="article:section" content="pytorch">
    
      <meta property="article:section" content="neural_network">
    
      <meta property="article:section" content="machine_learning">
    
      <meta property="article:section" content="google-colab">
    
  
  
    
      <meta property="article:tag" content="nlp">
    
      <meta property="article:tag" content="python">
    
      <meta property="article:tag" content="pytorch">
    
      <meta property="article:tag" content="neural_network">
    
      <meta property="article:tag" content="machine_learning">
    
      <meta property="article:tag" content="google-colab">
    
  


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@tma15">


  <meta name="twitter:creator" content="@tma15">






  <meta property="og:image" content="https://tma15.github.io/img/2020/09/06/document-classification.png">
  <meta property="twitter:image" content="https://tma15.github.io/img/2020/09/06/document-classification.png">





  <meta property="og:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=640">


    <title>【自然言語処理】LSTMに基づく文書分類 (PyTorchコード付き)</title>

    <link rel="icon" href="https://tma15.github.io/favicon.png">
    

    

    <link rel="canonical" href="https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">

    
    <script type="text/javascript" async
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
          });
    </script>


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
          (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-5663917297524414",
                  enable_page_level_ads: true
                });
    </script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://tma15.github.io/css/style-twzjdbqhmnnacqs0pwwdzcdbt8yhv8giawvjqjmyfoqnvazl0dalmnhdkvp7.min.css" />
    
    
      
        <link rel="stylesheet"  href="https://tma15.github.io/css/mystyle.css">
      
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-20414370-4', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://tma15.github.io/">Now is better than never.</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://tma15.github.io/#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=90" alt="プロフィール画像" />
      
    
    </a>
  

  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
           (adsbygoogle = window.adsbygoogle || []).push({
                         google_ad_client: "ca-pub-5663917297524414",
                         enable_page_level_ads: true
                    });
  </script>
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://tma15.github.io/#about">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
        </a>
        <h4 class="sidebar-profile-name">Takuya Makino</h4>
        
          <h5 class="sidebar-profile-bio">自然言語処理の研究開発に従事しています。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、Python、C++に関する記事が多めです。詳細は<a href="https://tma15.github.io/about/">プロフィール</a>を御覧ください。</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">ホーム</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">タグ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">アーカイブ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">プロフィール</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/inquiry">
    
      
      
      <span class="sidebar-button-desc">お問い合わせ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/privacy-policy">
    
      
      
      <span class="sidebar-button-desc">プライバシーポリシー</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://tma15.github.io/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>

      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle"
      style="display:block; text-align:center;"
      data-ad-layout="in-article"
      data-ad-format="fluid"
      data-ad-client="ca-pub-5663917297524414"
      data-ad-slot="8357823829"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

    <h3 style="color:white">最近の投稿</h3>
    <ul >
    
    <li ><a href="https://tma15.github.io/blog/2020/12/12/%E6%9B%B8%E8%A9%95who-you-are%E3%83%95%E3%83%BC%E3%83%A6%E3%83%BC%E3%82%A2%E3%83%BC%E5%90%9B%E3%81%AE%E7%9C%9F%E3%81%AE%E8%A8%80%E8%91%89%E3%81%A8%E8%A1%8C%E5%8B%95%E3%81%93%E3%81%9D%E3%81%8C%E5%9B%B0%E9%9B%A3%E3%82%92%E7%94%9F%E3%81%8D%E6%8A%9C%E3%81%8F%E3%83%81%E3%83%BC%E3%83%A0%E3%82%92%E3%81%A4%E3%81%8F%E3%82%8B/" class="sidebar-button-link" style="color:white; list-style:none;">【書評】Who You Are（フーユーアー）君の真の言葉と行動こそが困難を生き抜くチームをつくる</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/11/22/pythonmecab%E3%81%AEtagger%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%82%92%E6%8C%81%E3%81%A4%E5%8D%98%E8%AA%9E%E5%88%86%E5%89%B2%E5%99%A8%E3%82%92pickle%E3%81%A7%E4%BF%9D%E5%AD%98%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/" class="sidebar-button-link" style="color:white; list-style:none;">【Python】MeCabのTaggerオブジェクトを持つ単語分割器をpickleで保存する方法</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/11/21/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86scikit-learn%E3%81%A7tfidf%E3%81%A8%E3%81%9D%E3%82%8C%E4%BB%A5%E5%A4%96%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%82%92%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%82%8B/" class="sidebar-button-link" style="color:white; list-style:none;">【自然言語処理】scikit-learnでtfidfとそれ以外の特徴量を組み合わせる</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/11/14/pythonargparse%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9-%E5%85%A5%E9%96%80%E7%B7%A8/" class="sidebar-button-link" style="color:white; list-style:none;">【Python】argparseの使い方 (入門編)</a></li>
    
    <li ><a href="https://tma15.github.io/blog/2020/10/31/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%AB%E7%89%B9%E5%8C%96%E3%81%97%E3%81%9Fpython%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%92%E4%BD%9C%E3%82%8A%E5%A7%8B%E3%82%81%E3%81%BE%E3%81%97%E3%81%9F%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%BB%E3%81%BC%E4%B8%8D%E8%A6%81%E3%81%A7%E4%BD%BF%E3%81%88%E3%81%BE%E3%81%99/" class="sidebar-button-link" style="color:white; list-style:none;">【自然言語処理】文書分類に特化したPythonライブラリを作り始めました【プログラムほぼ不要で使えます】</a></li>
    
    </ul>

      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle"
      style="display:block; text-align:center;"
      data-ad-layout="in-article"
      data-ad-format="fluid"
      data-ad-client="ca-pub-5663917297524414"
      data-ad-slot="8357823829"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      【自然言語処理】LSTMに基づく文書分類 (PyTorchコード付き)
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-09-06T09:46:04&#43;09:00">
        
  
  
  
  
    2020-09-06
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/google-colab">google-colab</a>
    
  

  </div>


</div>
          

          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>本記事では日本語を対象としたLSTMに基づく文書分類モデルをPyTorchコード付きで紹介します。
以前、LSTMを用いた言語モデルについて紹介しました (
<a href="https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">[自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)</a>
)
が、ニューラルネットワークを用いた自然言語処理の応用例として文書分類のほうがイメージしやすそうなので、こちらについても紹介したいと思います。
実験にはライブドアコーパスから作成した、記事の見出しに対して9つのカテゴリのうち、どれか1つが付与されたデータを使います。
本記事を読むことで日本語を対象に、ニューラルネットワークを活用した自然言語処理の概要を知ることができます。
また、PyTorchで事前学習済みの単語分散表現を扱う方法も紹介しています。</p>


<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5663917297524414"
     data-ad-slot="8357823829"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="table-of-contents">目次</h2><nav id="TableOfContents">
  <ul>
    <li><a href="#本記事で利用するpythonモジュール">本記事で利用するPythonモジュール</a></li>
    <li><a href="#文書分類モデル">文書分類モデル</a></li>
    <li><a href="#データ前処理">データ前処理</a></li>
    <li><a href="#モデル学習">モデル学習</a></li>
    <li><a href="#評価">評価</a></li>
    <li><a href="#おわり">おわり</a></li>
  </ul>
</nav>
<h2 id="本記事で利用するpythonモジュール">本記事で利用するPythonモジュール</h2>
<ul>
<li>gensim 3.8.3</li>
<li>mecab-python3 0.996.1</li>
<li>numpy 1.16.2</li>
<li>pytorch 1.5.0</li>
<li>scikit-learn 0.22.1</li>
</ul>
<h2 id="文書分類モデル">文書分類モデル</h2>
<p>文書分類モデルは以下のような構成にしました。</p>

 
  
  
  
  
    
      
    
  
    
      
    
  
    
  

 
  
  
  
  
    
  
    
      
    
  

<div class="figure center" >
  
    <a class="fancybox" href="https://tma15.github.io/img/2020/09/06/document-classification.png" title="LSTMに基づく文書分類モデルの概要図" data-fancybox-group="">
  
    <img class="fig-img" src="https://tma15.github.io/img/2020/09/06/document-classification.png"  alt="LSTMに基づく文書分類モデルの概要図">
  
    </a>
  
   
    <span class="caption">LSTMに基づく文書分類モデルの概要図</span>
  
</div>

  <div style="clear:both;"></div>

<p>まず、入力文を単語分割します。
次に、得られた単語を二種類の分散表現へ変換します。
一つは学習対象となる分散表現で、もう一つは事前学習した分散表現とします。
事前学習した分散表現に関しては文書分類モデルの学習時は学習対象としないようにします。
得られた分散表現を入力として双方向LSTM (BiLSTM) から先頭の単語と末尾の単語に対する隠れ状態を取得します<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。
また各単語に対して得られたBiLSTMの隠れ状態を対象にプーリングを適用してベクトルを取得します<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。
最後に、文に対して得られた複数のベクトルの結合を入力として、文書カテゴリに対するスコアを予測します。</p>
<p>分散表現を学習対象のものと、事前学習済みのものに分けたのは、ライブドアコーパスから作成した学習データのサイズがそれほど大きくないため、テストデータに出現する単語を十分にカバーできない可能性があるのと、十分に分散表現を学習できない可能性があるためです。</p>
<p>分散表現を2つに分けることで、そのコーパスに依存した分散表現は学習しつつも、巨大なラベルなしコーパスから学習した分散表現を利用するため、精度改善が期待されます。</p>
<p>プーリングは画像認識における畳み込みニューラルネットワークで利用されることが多い印象を持つかもしれませんが、自然言語処理でも使われることがあります。</p>
<p>今回のような文書分類では、文全体の特徴に加えて、局所的な特徴 (特定の単語や句)  が分類精度に寄与することが考えられます。たとえばスマートフォンという単語が出現すればIT関係のカテゴリに分類される、など。
このような局所的な特徴も考慮するために、プーリングも適用しています。</p>
<p>上記の図をPyTorchで実装したものが以下になります。
LSTMは学習時に<a href="https://arxiv.org/pdf/1708.02182.pdf">Weight drop</a> を適用しています。
Weight dropに関するモジュールは<a href="https://pytorchnlp.readthedocs.io/en/latest/index.html">PyTorch-NLP</a>を参考にしています。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_weight_drop</span>(module, weights, dropout):
    <span style="color:#66d9ef">for</span> name_w <span style="color:#f92672">in</span> weights:
        w <span style="color:#f92672">=</span> getattr(module, name_w)
        <span style="color:#66d9ef">del</span> module<span style="color:#f92672">.</span>_parameters[name_w]
        module<span style="color:#f92672">.</span>register_parameter(name_w <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;_raw&#39;</span>, torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Parameter(w))

    original_module_forward <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>forward

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(<span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs):
        <span style="color:#66d9ef">for</span> name_w <span style="color:#f92672">in</span> weights:
            raw_w <span style="color:#f92672">=</span> getattr(module, name_w <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;_raw&#39;</span>)
            w <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>dropout(raw_w, p<span style="color:#f92672">=</span>dropout, training<span style="color:#f92672">=</span>module<span style="color:#f92672">.</span>training)
            setattr(module, name_w, w)

        <span style="color:#66d9ef">return</span> original_module_forward(<span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs)

    setattr(module, <span style="color:#e6db74">&#39;forward&#39;</span>, forward)


<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WeightDrop</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(self, module, weights, dropout<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>):
        super(WeightDrop, self)<span style="color:#f92672">.</span>__init__()
        _weight_drop(module, weights, dropout)
        self<span style="color:#f92672">.</span>forward <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>forward


<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WeightDropLSTM</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>LSTM):
    <span style="color:#66d9ef">def</span> __init__(self, <span style="color:#f92672">*</span>args, weight_dropout<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>, weight_names_to_drop<span style="color:#f92672">=</span>[], <span style="color:#f92672">**</span>kwargs):
        super()<span style="color:#f92672">.</span>__init__(<span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs)
        _weight_drop(self, weight_names_to_drop, weight_dropout)


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">loss_fn</span>(model, batch):
    <span style="color:#66d9ef">return</span> F<span style="color:#f92672">.</span>nll_loss(
        torch<span style="color:#f92672">.</span>log_softmax(model(batch), dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>),
        batch[<span style="color:#e6db74">&#39;label&#39;</span>]
    )


<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Classifier</span>(torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(
        self,
        feature_vocab,
        category_vocab,
        embedding_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>,
        embedding_path<span style="color:#f92672">=</span>None,
        hidden_size<span style="color:#f92672">=</span><span style="color:#ae81ff">256</span>,
        num_layers<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
        weight_dropout<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>,
        <span style="color:#f92672">**</span>kwargs,
    ):
        super()<span style="color:#f92672">.</span>__init__()

        self<span style="color:#f92672">.</span>feature_vocab <span style="color:#f92672">=</span> feature_vocab
        self<span style="color:#f92672">.</span>category_vocab <span style="color:#f92672">=</span> category_vocab

        self<span style="color:#f92672">.</span>embedding_size <span style="color:#f92672">=</span> embedding_size
        self<span style="color:#f92672">.</span>hidden_size <span style="color:#f92672">=</span> hidden_size

        self<span style="color:#f92672">.</span>embedding <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Embedding(
            len(feature_vocab),
            embedding_size,
            padding_idx<span style="color:#f92672">=</span>feature_vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;pad&gt;&#39;</span>)
        )

        self<span style="color:#f92672">.</span>key_vector <span style="color:#f92672">=</span> None
        <span style="color:#66d9ef">if</span> embedding_path:
            self<span style="color:#f92672">.</span>key_vector <span style="color:#f92672">=</span> gensim<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>KeyedVectors<span style="color:#f92672">.</span>load(
                embedding_path,
                mmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>,
            )

        self<span style="color:#f92672">.</span>num_layers <span style="color:#f92672">=</span> num_layers
        self<span style="color:#f92672">.</span>weight_names_to_drop <span style="color:#f92672">=</span> [
            f<span style="color:#e6db74">&#39;weight_hh_l{i}&#39;</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(self<span style="color:#f92672">.</span>num_layers)
        ]
        self<span style="color:#f92672">.</span>weight_names_to_drop <span style="color:#f92672">=</span> [
            f<span style="color:#e6db74">&#39;weight_hh_l{i}_reverse&#39;</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(self<span style="color:#f92672">.</span>num_layers)
        ]

        self<span style="color:#f92672">.</span>bidirectional <span style="color:#f92672">=</span> True
        self<span style="color:#f92672">.</span>lstm <span style="color:#f92672">=</span> WeightDropLSTM(
            input_size<span style="color:#f92672">=</span>embedding_size  self<span style="color:#f92672">.</span>key_vector<span style="color:#f92672">.</span>vector_size <span style="color:#66d9ef">if</span> embedding_path
                <span style="color:#66d9ef">else</span> embedding_size,
            hidden_size<span style="color:#f92672">=</span>hidden_size,
            num_layers<span style="color:#f92672">=</span>num_layers,
            bidirectional<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>bidirectional,
            weight_dropout<span style="color:#f92672">=</span>weight_dropout,
            weight_names_to_drop<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>weight_names_to_drop,
        )

        self<span style="color:#f92672">.</span>out <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(
            <span style="color:#ae81ff">8</span> <span style="color:#f92672">*</span> hidden_size,
            len(category_vocab),
            bias<span style="color:#f92672">=</span>True)

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">static_embeedding</span>(self, inputs):
        bsz <span style="color:#f92672">=</span> len(inputs[<span style="color:#e6db74">&#39;raw_words&#39;</span>])
        seq_len <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        <span style="color:#66d9ef">for</span> batch_idx <span style="color:#f92672">in</span> range(len(inputs[<span style="color:#e6db74">&#39;raw_words&#39;</span>])):
            seq_len <span style="color:#f92672">=</span> max(seq_len, len(inputs[<span style="color:#e6db74">&#39;raw_words&#39;</span>][batch_idx]))

        embed <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros((bsz, seq_len, self<span style="color:#f92672">.</span>key_vector<span style="color:#f92672">.</span>vector_size))
        <span style="color:#66d9ef">for</span> batch_idx <span style="color:#f92672">in</span> range(len(inputs[<span style="color:#e6db74">&#39;raw_words&#39;</span>])):
            <span style="color:#66d9ef">for</span> t, word <span style="color:#f92672">in</span> enumerate(inputs[<span style="color:#e6db74">&#39;raw_words&#39;</span>][batch_idx]):
                <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>key_vector:
                    embed[batch_idx, t, :] <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(
                        np<span style="color:#f92672">.</span>array(self<span style="color:#f92672">.</span>key_vector<span style="color:#f92672">.</span>get_vector(word))
                    )
        <span style="color:#66d9ef">return</span> embed

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_state_dict</span>(self, state_dict):
        state_dict <span style="color:#f92672">=</span> super()<span style="color:#f92672">.</span>load_state_dict(state_dict, strict<span style="color:#f92672">=</span>False)
        <span style="color:#66d9ef">return</span> state_dict

    <span style="color:#66d9ef">def</span> __call__(self, inputs):
        x <span style="color:#f92672">=</span> inputs[<span style="color:#e6db74">&#39;words&#39;</span>]
        bsz, seq_len <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>size()

        lengths <span style="color:#f92672">=</span> (x <span style="color:#f92672">!=</span> self<span style="color:#f92672">.</span>feature_vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;pad&gt;&#39;</span>))<span style="color:#f92672">.</span>sum(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

        <span style="color:#75715e"># (bsz, seq_len, embedding_size)</span>
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>embedding(x)

        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>key_vector:
            static_x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>static_embeedding(inputs)<span style="color:#f92672">.</span>to(inputs[<span style="color:#e6db74">&#39;words&#39;</span>]<span style="color:#f92672">.</span>device)
            x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([x, static_x], dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)

        packed <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>rnn<span style="color:#f92672">.</span>pack_padded_sequence(
            x,
            lengths,
            batch_first<span style="color:#f92672">=</span>True,
            enforce_sorted<span style="color:#f92672">=</span>False

        rnn_out, (ht, ct) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lstm(packed)
        ht <span style="color:#f92672">=</span> ht<span style="color:#f92672">.</span>view(self<span style="color:#f92672">.</span>num_layers, <span style="color:#ae81ff">2</span>, bsz, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)

        ht <span style="color:#f92672">=</span> ht[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]  <span style="color:#75715e"># (2, bsz, hidden_size)</span>
        ht <span style="color:#f92672">=</span> (
            ht<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># (bsz, 2, hidden_size)</span>
            <span style="color:#f92672">.</span>contiguous()
            <span style="color:#f92672">.</span>view(bsz, <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>hidden_size)
        )

        <span style="color:#75715e"># (bsz, seq_len, 2 * hidden_size)</span>
        x, _ <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>rnn<span style="color:#f92672">.</span>pad_packed_sequence(rnn_out, batch_first<span style="color:#f92672">=</span>True)

        <span style="color:#75715e"># (bsz, 1, 2 * hidden_size)</span>
        h_max <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>adaptive_max_pool2d(
            x<span style="color:#f92672">.</span>view(bsz, <span style="color:#ae81ff">1</span>, seq_len, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>),
            (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>hidden_size)
        )<span style="color:#f92672">.</span>squeeze(<span style="color:#ae81ff">1</span>)
        h_avg <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>adaptive_avg_pool2d(
            x<span style="color:#f92672">.</span>view(bsz, <span style="color:#ae81ff">1</span>, seq_len, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>),
            (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>hidden_size)
        )<span style="color:#f92672">.</span>squeeze(<span style="color:#ae81ff">1</span>)

        <span style="color:#75715e"># (bsz, 4 * 2 * hidden_size)</span>
        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([x[:, <span style="color:#ae81ff">0</span>], ht, h_max<span style="color:#f92672">.</span>squeeze(<span style="color:#ae81ff">1</span>), h_avg<span style="color:#f92672">.</span>squeeze(<span style="color:#ae81ff">1</span>)], dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)

        <span style="color:#75715e"># (bsz, category_size)</span>
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>out(x)
        <span style="color:#66d9ef">return</span> x
</code></pre></div><h2 id="データ前処理">データ前処理</h2>
<p>この章ではライブドアコーパスを対象とした前処理部分を紹介します。
今回は、記事の見出しを入力としてその記事のカテゴリを予測したいため、<code>read_data</code>関数から見出しとカテゴリに相当する情報を取得します。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_data</span>(data_dir):
    files <span style="color:#f92672">=</span> glob<span style="color:#f92672">.</span>glob(f<span style="color:#e6db74">&#39;{data_dir}/*/*.txt&#39;</span>)
    categories <span style="color:#f92672">=</span> []
    titles <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> fname <span style="color:#f92672">in</span> files:
        elems <span style="color:#f92672">=</span> fname<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;/&#39;</span>)
        category <span style="color:#f92672">=</span> elems[<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>]  <span style="color:#75715e"># ディレクトリ名をカテゴリとして取得</span>
        <span style="color:#66d9ef">with</span> open(fname) <span style="color:#66d9ef">as</span> f:
            next(f)
            next(f)
            title <span style="color:#f92672">=</span> next(f)<span style="color:#f92672">.</span>rstrip()  <span style="color:#75715e"># ファイルの3行目をタイトルとして取得</span>
        categories<span style="color:#f92672">.</span>append(category)
        titles<span style="color:#f92672">.</span>append(title)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;#Files:&#39;</span>, len(titles))
    <span style="color:#66d9ef">return</span> categories, titles
</code></pre></div><p>次にカテゴリと見出しを学習データ、テストデータに分割します。
その後、これらのデータに対して前処理を適用し、得られた前処理結果を保存します。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_dataset</span>(args, categories, titles):
    <span style="color:#75715e"># 学習データとテストデータに分割</span>
    categories_train, categories_test, titles_train, titles_test <span style="color:#f92672">=</span> train_test_split(
        categories,
        titles,
        random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>,
        stratify<span style="color:#f92672">=</span>categories,
    )

    <span style="color:#75715e"># 学習データとテストデータの分布を表示</span>
    dist <span style="color:#f92672">=</span> Counter(categories_train)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Training&#39;</span>)
    <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> sorted(dist<span style="color:#f92672">.</span>items(), key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">1</span>], reverse<span style="color:#f92672">=</span>True):
        <span style="color:#66d9ef">print</span>(v, k)
    <span style="color:#66d9ef">print</span>()

    dist <span style="color:#f92672">=</span> Counter(categories_test)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Test&#39;</span>)
    <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> sorted(dist<span style="color:#f92672">.</span>items(), key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">1</span>], reverse<span style="color:#f92672">=</span>True):
        <span style="color:#66d9ef">print</span>(v, k)

    <span style="color:#75715e"># カテゴリや単語をidに変換するクラスの作成</span>
    category_vocab <span style="color:#f92672">=</span> Vocabulary()
    feature_vocab <span style="color:#f92672">=</span> Vocabulary()

    feature_vocab<span style="color:#f92672">.</span>add_item(<span style="color:#e6db74">&#39;&lt;s&gt;&#39;</span>)
    feature_vocab<span style="color:#f92672">.</span>add_item(<span style="color:#e6db74">&#39;&lt;/s&gt;&#39;</span>)
    feature_vocab<span style="color:#f92672">.</span>add_item(<span style="color:#e6db74">&#39;&lt;unk&gt;&#39;</span>)
    feature_vocab<span style="color:#f92672">.</span>add_item(<span style="color:#e6db74">&#39;&lt;pad&gt;&#39;</span>)

    <span style="color:#75715e"># Create vocabularies</span>
    <span style="color:#66d9ef">for</span> category <span style="color:#f92672">in</span> categories_train:
        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> category <span style="color:#f92672">in</span> category_vocab:
            category_vocab<span style="color:#f92672">.</span>add_item(category)

    tagger <span style="color:#f92672">=</span> MeCab<span style="color:#f92672">.</span>Tagger(<span style="color:#e6db74">&#39;-Owakati&#39;</span>)

    <span style="color:#75715e"># 学習データを単語分割し、単語の頻度を取得</span>
    word_freq <span style="color:#f92672">=</span> Counter()
    titles_tokenized_train <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> title <span style="color:#f92672">in</span> titles_train:
        result <span style="color:#f92672">=</span> tagger<span style="color:#f92672">.</span>parse(title)<span style="color:#f92672">.</span>rstrip()
        words <span style="color:#f92672">=</span> result<span style="color:#f92672">.</span>split()
        word_freq<span style="color:#f92672">.</span>update(words)
        titles_tokenized_train<span style="color:#f92672">.</span>append(words)

    <span style="color:#75715e"># 単語の頻度上位vocab_size件をvocabularyに追加</span>
    <span style="color:#66d9ef">for</span> word, freq <span style="color:#f92672">in</span> sorted(
        word_freq<span style="color:#f92672">.</span>most_common(args<span style="color:#f92672">.</span>vocab_size),
        key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">1</span>],
        reverse<span style="color:#f92672">=</span>True
    ):
        feature_vocab<span style="color:#f92672">.</span>add_item(word)

    unk <span style="color:#f92672">=</span> feature_vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;unk&gt;&#39;</span>)
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_idx_data</span>(cs, ts):
        y <span style="color:#f92672">=</span> []
        X <span style="color:#f92672">=</span> []
        <span style="color:#66d9ef">for</span> category <span style="color:#f92672">in</span> cs:
            y_i <span style="color:#f92672">=</span> category_vocab<span style="color:#f92672">.</span>get_index(category)
            y<span style="color:#f92672">.</span>append(y_i)

        <span style="color:#66d9ef">for</span> title_tokenized <span style="color:#f92672">in</span> ts:
            x <span style="color:#f92672">=</span> []
            <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> title_tokenized:
                <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> feature_vocab:
                    word_idx <span style="color:#f92672">=</span> feature_vocab<span style="color:#f92672">.</span>get_index(word)
                <span style="color:#66d9ef">else</span>:
                    word_idx <span style="color:#f92672">=</span> unk
                x<span style="color:#f92672">.</span>append(word_idx)
            X<span style="color:#f92672">.</span>append(x)
        <span style="color:#66d9ef">assert</span> len(y) <span style="color:#f92672">==</span> len(X), f<span style="color:#e6db74">&#39;{len(y)} != {len(x)}&#39;</span>
        <span style="color:#66d9ef">return</span> y, X

    <span style="color:#75715e"># 学習データの単語やカテゴリ情報をidに変換する</span>
    y_train, X_train <span style="color:#f92672">=</span> create_idx_data(categories_train, titles_tokenized_train)

    <span style="color:#75715e"># テストデータの単語やカテゴリ情報をidに変換する</span>
    titles_tokenized_test <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> title <span style="color:#f92672">in</span> titles_test:
        result <span style="color:#f92672">=</span> tagger<span style="color:#f92672">.</span>parse(title)<span style="color:#f92672">.</span>rstrip()
        words <span style="color:#f92672">=</span> result<span style="color:#f92672">.</span>split()
        titles_tokenized_test<span style="color:#f92672">.</span>append(words)
    y_test, X_test <span style="color:#f92672">=</span> create_idx_data(categories_test, titles_tokenized_test)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;#Train:&#39;</span>, len(y_train), <span style="color:#e6db74">&#39;#Test:&#39;</span>, len(y_test))

    <span style="color:#75715e"># 単語およびカテゴリをIDに変換する・またその逆をおこなうオブジェクトを保存する</span>
    category_vocab<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;category.dict&#39;</span>)
    feature_vocab<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;feature.dict&#39;</span>)

    <span style="color:#66d9ef">if</span> args<span style="color:#f92672">.</span>embedding_path:
        <span style="color:#75715e"># 事前学習済み単語ベクトルが記述されたテキスト形式のファイルを読み込み、バイナリ形式で保存する</span>
        kv <span style="color:#f92672">=</span> gensim<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>KeyedVectors<span style="color:#f92672">.</span>load_word2vec_format(args<span style="color:#f92672">.</span>embedding_path)
        kv<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;embedding.bin&#39;</span>)

    <span style="color:#75715e"># 学習データおよびテストデータを保存する</span>
    torch<span style="color:#f92672">.</span>save([
        {
            <span style="color:#e6db74">&#39;label&#39;</span>: y,
            <span style="color:#e6db74">&#39;words&#39;</span>: torch<span style="color:#f92672">.</span>tensor(x, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long),
            <span style="color:#e6db74">&#39;raw_words&#39;</span>: z,
        }
        <span style="color:#66d9ef">for</span> y, x, z <span style="color:#f92672">in</span> zip(y_train, X_train, titles_tokenized_train)
    ], <span style="color:#e6db74">&#39;train.pt&#39;</span>)
    torch<span style="color:#f92672">.</span>save([
        {
            <span style="color:#e6db74">&#39;label&#39;</span>: y,
            <span style="color:#e6db74">&#39;words&#39;</span>: torch<span style="color:#f92672">.</span>tensor(x, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long),
            <span style="color:#e6db74">&#39;raw_words&#39;</span>: z,
        }
        <span style="color:#66d9ef">for</span> y, x, z <span style="color:#f92672">in</span> zip(y_test, X_test, titles_tokenized_test)
    ], <span style="color:#e6db74">&#39;test.pt&#39;</span>)


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preprocess</span>(args):
    categories, titles <span style="color:#f92672">=</span> read_data(args<span style="color:#f92672">.</span>data_dir)
    create_dataset(args, categories, titles)
</code></pre></div><p><code>preprocess</code>関数を実行すると以下のような表示が得られます。
事前学習済みの分散表現は<a href="https://github.com/singletongue/WikiEntVec">singletongue / WikiEntVec</a>で公開されている300次元のものを利用しました。</p>
<pre><code>
#Files: 7376
Training
676 sports-watch
654 dokujo-tsushin
653 it-life-hack
653 movie-enter
653 smax
649 kaden-channel
632 peachy
578 topic-news
384 livedoor-homme

Test
225 sports-watch
218 it-life-hack
218 smax
218 movie-enter
217 dokujo-tsushin
216 kaden-channel
211 peachy
193 topic-news
128 livedoor-homme
#Train: 5532 #Test: 1844
</code></pre><h2 id="モデル学習">モデル学習</h2>
<p>前処理でデータを作成したら、実際に文書分類モデルを学習します。
学習には以下の<code>train</code>関数を用います。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">collate_fn</span>(pad):
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_collate_fn</span>(samples):
        batch <span style="color:#f92672">=</span> {}
        <span style="color:#66d9ef">for</span> sample <span style="color:#f92672">in</span> sorted(samples, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: len(x[<span style="color:#e6db74">&#39;words&#39;</span>]), reverse<span style="color:#f92672">=</span>True):
            <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> sample<span style="color:#f92672">.</span>items():
                <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> k <span style="color:#f92672">in</span> batch:
                    batch[k] <span style="color:#f92672">=</span> [v]
                <span style="color:#66d9ef">else</span>:
                    batch[k]<span style="color:#f92672">.</span>append(v)
        batch[<span style="color:#e6db74">&#39;label&#39;</span>] <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(batch[<span style="color:#e6db74">&#39;label&#39;</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long)
        batch[<span style="color:#e6db74">&#39;words&#39;</span>] <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>rnn<span style="color:#f92672">.</span>pad_sequence(
            batch[<span style="color:#e6db74">&#39;words&#39;</span>],
            batch_first<span style="color:#f92672">=</span>True,
            padding_value<span style="color:#f92672">=</span>pad
        )
        <span style="color:#66d9ef">return</span> batch
    <span style="color:#66d9ef">return</span> _collate_fn


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">move_to_cuda</span>(batch, gpu):
    batch[<span style="color:#e6db74">&#39;label&#39;</span>] <span style="color:#f92672">=</span> batch[<span style="color:#e6db74">&#39;label&#39;</span>]<span style="color:#f92672">.</span>cuda(gpu)
    batch[<span style="color:#e6db74">&#39;words&#39;</span>] <span style="color:#f92672">=</span> batch[<span style="color:#e6db74">&#39;words&#39;</span>]<span style="color:#f92672">.</span>cuda(gpu)
    <span style="color:#66d9ef">return</span> batch


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train</span>(args):
    <span style="color:#75715e"># 学習時に用いたハイパーパラメータ情報を予測時に使うために保存</span>
    <span style="color:#66d9ef">with</span> open(args<span style="color:#f92672">.</span>param_file, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> f:
        param <span style="color:#f92672">=</span> vars(args)
        <span style="color:#66d9ef">del</span> param[<span style="color:#e6db74">&#39;handler&#39;</span>]
        json<span style="color:#f92672">.</span>dump(param, f, indent<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)

    <span style="color:#75715e"># 単語およびカテゴリをIDに変換するオブジェクトを読み込む</span>
    feature_vocab <span style="color:#f92672">=</span> Vocabulary<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;feature.dict&#39;</span>)
    category_vocab <span style="color:#f92672">=</span> Vocabulary<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;category.dict&#39;</span>)

    <span style="color:#75715e"># 前処理で作成した学習データを読み込む</span>
    data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;train.pt&#39;</span>)

    pad <span style="color:#f92672">=</span> feature_vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;pad&gt;&#39;</span>)

    model <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>Classifier(
        feature_vocab,
        category_vocab,
        embedding_size<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>embedding_size,
        embedding_path<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>embedding_path,
        hidden_size<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>hidden_size,
        num_layers<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>num_layers,
        weight_dropout<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>weight_dropout)

    <span style="color:#66d9ef">if</span> args<span style="color:#f92672">.</span>gpu <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>:
        model<span style="color:#f92672">.</span>cuda(args<span style="color:#f92672">.</span>gpu)
    <span style="color:#66d9ef">print</span>(model)

    optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>AdamW(model<span style="color:#f92672">.</span>parameters())
    <span style="color:#66d9ef">print</span>(optimizer)

    model<span style="color:#f92672">.</span>train()
    optimizer<span style="color:#f92672">.</span>zero_grad()

    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(args<span style="color:#f92672">.</span>max_epochs):
        loss_epoch <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.</span>
        step <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        <span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
            data,
            batch_size<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>batch_size,
            shuffle<span style="color:#f92672">=</span>True,
            collate_fn<span style="color:#f92672">=</span>collate_fn(pad),
        ):
            optimizer<span style="color:#f92672">.</span>zero_grad()

            <span style="color:#66d9ef">if</span> args<span style="color:#f92672">.</span>gpu <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>:
                batch <span style="color:#f92672">=</span> move_to_cuda(batch, args<span style="color:#f92672">.</span>gpu)

            loss <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>loss_fn(model, batch)

            loss<span style="color:#f92672">.</span>backward()
            loss_epoch <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()
            <span style="color:#66d9ef">del</span> loss

            torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>clip_grad_norm_(model<span style="color:#f92672">.</span>parameters(), args<span style="color:#f92672">.</span>clip)

            optimizer<span style="color:#f92672">.</span>step()

            step <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
        <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;epoch:{epoch+1}: loss:{loss_epoch:.5f}&#39;</span>)
    <span style="color:#75715e"># 学習した文書分類モデルを保存</span>
    torch<span style="color:#f92672">.</span>save(model<span style="color:#f92672">.</span>state_dict(), args<span style="color:#f92672">.</span>model)
</code></pre></div><p><code>del loss</code>の説明は以下の記事を御覧ください。</p>
<p><a href="https://tma15.github.io/blog/2020/08/22/pytorch%E4%B8%8D%E8%A6%81%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%9F%E8%A8%88%E7%AE%97%E3%82%B0%E3%83%A9%E3%83%95%E3%82%92%E5%89%8A%E9%99%A4%E3%81%97%E3%81%A6%E3%83%A1%E3%83%A2%E3%83%AA%E3%82%92%E7%AF%80%E7%B4%84/">【PyTorch】不要になった計算グラフを削除してメモリを節約</a></p>
<p>上記を実行すると以下のような結果が得られます。</p>
<pre><code>Classifier(
  (embedding): Embedding(13086, 50, padding_idx=3)
  (lstm): WeightDropLSTM(350, 100, bidirectional=True)
  (out): Linear(in_features=800, out_features=9, bias=True)
)
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.01
)
epoch:1: loss:322.43662
epoch:2: loss:144.89778
epoch:3: loss:87.69048
epoch:4: loss:50.57606
epoch:5: loss:27.93044
</code></pre><p>本記事ではGoogle ColabのGPUを使って実験を実施しました。
Google Colabがわからない方、利用するための準備がわからない方は以下の記事を御覧ください。</p>
<p><a href="https://tma15.github.io/blog/2020/03/11/colab-google%E3%81%AE%E7%84%A1%E6%96%99gpu%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%BF%E3%81%86%E3%81%9F%E3%82%81%E3%81%AE%E6%BA%96%E5%82%99/">[Colab] Googleの無料GPU環境を使うための準備</a></p>
<h2 id="評価">評価</h2>
<p>最後に学習済み文書分類モデルをテストデータを使って評価します。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate</span>(args):
    feature_vocab <span style="color:#f92672">=</span> Vocabulary<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;feature.dict&#39;</span>)
    category_vocab <span style="color:#f92672">=</span> Vocabulary<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;category.dict&#39;</span>)

    <span style="color:#75715e"># 学習時に保存したハイパーパラメータを読み込む</span>
    <span style="color:#66d9ef">with</span> open(args<span style="color:#f92672">.</span>param_file, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> f:
        params <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>load(f)

    model <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>Classifier(
        feature_vocab,
        category_vocab,
        <span style="color:#f92672">**</span>params)

    <span style="color:#75715e"># 学習済みパラメータを読み込む</span>
    model<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(args<span style="color:#f92672">.</span>model))
    <span style="color:#66d9ef">if</span> args<span style="color:#f92672">.</span>gpu <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>:
        model <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>cuda(args<span style="color:#f92672">.</span>gpu)

    <span style="color:#75715e"># 前処理で作成したテストデータを読み込む</span>
    test_data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;test.pt&#39;</span>)
    predictions <span style="color:#f92672">=</span> []
    targets <span style="color:#f92672">=</span> []
    model<span style="color:#f92672">.</span>eval()
    pad <span style="color:#f92672">=</span> feature_vocab<span style="color:#f92672">.</span>get_index(<span style="color:#e6db74">&#39;&lt;pad&gt;&#39;</span>)
    match <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
        <span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
            test_data,
            batch_size<span style="color:#f92672">=</span>args<span style="color:#f92672">.</span>batch_size,
            shuffle<span style="color:#f92672">=</span>False,
            collate_fn<span style="color:#f92672">=</span>collate_fn(pad),
        ):

            <span style="color:#66d9ef">if</span> args<span style="color:#f92672">.</span>gpu <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>:
                batch <span style="color:#f92672">=</span> move_to_cuda(batch, args<span style="color:#f92672">.</span>gpu)

            pred <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(model(batch), dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
            target <span style="color:#f92672">=</span> batch[<span style="color:#e6db74">&#39;label&#39;</span>]

            match <span style="color:#f92672">+=</span> (pred <span style="color:#f92672">==</span> target)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()

            predictions<span style="color:#f92672">.</span>extend(pred<span style="color:#f92672">.</span>tolist())
            targets<span style="color:#f92672">.</span>extend(target<span style="color:#f92672">.</span>tolist())

    acc <span style="color:#f92672">=</span> match <span style="color:#f92672">/</span> len(targets)
    prec, rec, fscore, _ <span style="color:#f92672">=</span> precision_recall_fscore_support(predictions, targets)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Acc&#39;</span>, acc)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;===&#39;</span>)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Category&#39;</span>, <span style="color:#e6db74">&#39;Precision&#39;</span>, <span style="color:#e6db74">&#39;Recall&#39;</span>, <span style="color:#e6db74">&#39;Fscore&#39;</span>, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>)
    <span style="color:#66d9ef">for</span> idx <span style="color:#f92672">in</span> range(len(category_vocab)):
        <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{category_vocab.get_item(idx)}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>
              f<span style="color:#e6db74">&#39;{prec[idx]:.2f}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{rec[idx]:.2f}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{fscore[idx]:.2f}&#39;</span>)
    prec, rec, fscore, _ <span style="color:#f92672">=</span> precision_recall_fscore_support(predictions, targets, average<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;micro&#39;</span>)
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;Total</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{prec:.2f}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{rec:.2f}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{fscore:.2f}&#39;</span>)
</code></pre></div><p>以下のような結果が得られました。</p>
<pre><code>Acc 0.8432754880694143
===
Category	Precision	Recall	Fscore
kaden-channel	0.93	0.92	0.93
dokujo-tsushin	0.88	0.80	0.84
it-life-hack	0.87	0.88	0.88
movie-enter	0.73	0.93	0.82
topic-news	0.94	0.68	0.79
livedoor-homme	0.71	0.75	0.73
sports-watch	0.84	0.95	0.89
smax	0.96	0.93	0.95
peachy	0.68	0.76	0.72
Total	0.84	0.84	0.84
</code></pre><p>F値で84%程度となっています<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>。
以前書いた記事は単語のtfidfを素性としたパーセプトロンをライブドアコーパスの見出し分類を紹介しました。
パーセプトロンでは約70%程度だったので、それと比較すると高い値となっています。ただし、学習データとテストデータの分割が違うので厳密には比較にはなりません。</p>
<p><a href="https://tma15.github.io/blog/2020/03/03/python-scikit-learn%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E5%85%A5%E9%96%80/">[Python] scikit-learnで学ぶパーセプトロンによる文書分類入門</a></p>
<h2 id="おわり">おわり</h2>
<p>本記事ではLSTMに基づく文書分類モデルをPyTorchコード付きで紹介しました。
また今回記載したプログラムは<a href="https://github.com/tma15/pytorch-lstm-document-classification">tma15 / pytorch-lstm-document-classification</a>にアップロードしてありますので、よければ参考にしてください。</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>BiLSTMは文の先頭から末尾に処理するLSTMと末尾から先頭に処理するLSTMの2つからなります。先頭の単語の隠れ状態は、2つのLSTMの隠れ状態の結合です。片方の隠れ状態は末尾から計算した文脈情報が含まれているため、文の情報を含んでいると考えられます。 <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>LSTM部分については<a href="https://arxiv.org/pdf/1801.06146.pdf">Universal Language Model Fine-tuning for Text Classification</a>を参考にしました。 <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>事前学習済み分散表現を使わないと、F値は72%程度でした。このことから事前学習済み分散表現を活用して未知語を減らすことが分類精度に寄与しているといえます。またプーリングを使わない場合ではF値は殆ど変わりませんでした。これは、分類対象が見出しであり、比較的単語数が少ないテキストであったため、分類精度にあまり寄与しなかった可能性があります。またweight dropも分類精度にあまり影響しませんでした。こちらも対象とするテキストが比較的短かったことが影響するかもしれません。 <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
              

              <br>
              <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
              <ins class="adsbygoogle"
              style="display:block; text-align:center;"
              data-ad-layout="in-article"
              data-ad-format="fluid"
              data-ad-client="ca-pub-5663917297524414"
              data-ad-slot="8357823829"></ins>
              <script>
              (adsbygoogle = window.adsbygoogle || []).push({});
              </script>
    
              

<h3>関連記事</h3>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
          [自然言語処理] LSTMに基づく言語モデルの学習 (PyTorchコード付き)
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-03-15T15:24:03&#43;09:00">
        
  
  
  
  
    2020-03-15
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/google-colab">google-colab</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>









  </div>
  
    <a href="https://tma15.github.io/blog/2020/03/15/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86-lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/03/15/lstm-lm.png"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/08/29/nvidia%E7%9B%B4%E4%BC%9D%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEpytorch%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%99%E3%82%8B%E3%81%8B%E3%82%82%E3%81%97%E3%82%8C%E3%81%AA%E3%81%84tips/">
          【NVIDIA直伝】あなたのPyTorchプログラムを高速化するかもしれないTips
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-08-29T13:16:11&#43;09:00">
        
  
  
  
  
    2020-08-29
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>









  </div>
  
    <a href="https://tma15.github.io/blog/2020/08/29/nvidia%E7%9B%B4%E4%BC%9D%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEpytorch%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%99%E3%82%8B%E3%81%8B%E3%82%82%E3%81%97%E3%82%8C%E3%81%AA%E3%81%84tips/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/pytorch-logo.png"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/07/19/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86scheduled-sampling%E3%81%AB%E3%82%88%E3%82%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92/">
          【自然言語処理】Scheduled samplingによるニューラル言語モデルの学習
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-07-19T13:34:44&#43;09:00">
        
  
  
  
  
    2020-07-19
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>
    
  

  </div>


    </div>









  </div>
  
    <a href="https://tma15.github.io/blog/2020/07/19/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86scheduled-sampling%E3%81%AB%E3%82%88%E3%82%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E5%AD%A6%E7%BF%92/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/07/19/scheduled-sampling.png"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/05/03/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86kaggle%E3%82%B3%E3%83%B3%E3%83%9A%E3%81%A7%E5%88%A9%E7%94%A8%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%AEtips/">
          【自然言語処理】Kaggleコンペで利用されている文書分類のtips
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-05-03T16:47:46&#43;09:00">
        
  
  
  
  
    2020-05-03
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/neural_network">neural_network</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/kaggle">kaggle</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/nlp">nlp</a>
    
  

  </div>


    </div>









  </div>
  
    <a href="https://tma15.github.io/blog/2020/05/03/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86kaggle%E3%82%B3%E3%83%B3%E3%83%9A%E3%81%A7%E5%88%A9%E7%94%A8%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%AEtips/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/Kaggle_logo.png"/>
      </div>
    </a>
  
</article>

</div>
<br>

<div class="box">

  
    
  


  

<article class="postShorten postShorten--thumbnailimg-left" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h4 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/">
          【PyTorch】限られたメモリにおける大きなバッチサイズでの学習
        </a>
      </h4>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-04-05T16:26:26&#43;09:00">
        
  
  
  
  
    2020-04-05
  


      </time>

      

    
    
  
  
    <span>カテゴリー</span>
    
      <a class="category-link" href="https://tma15.github.io/categories/pytorch">pytorch</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/machine_learning">machine_learning</a>, 
    
      <a class="category-link" href="https://tma15.github.io/categories/python">python</a>
    
  

  </div>


    </div>









  </div>
  
    <a href="https://tma15.github.io/blog/2020/04/05/pytorch%E9%99%90%E3%82%89%E3%82%8C%E3%81%9F%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%A4%A7%E3%81%8D%E3%81%AA%E3%83%90%E3%83%83%E3%83%81%E3%82%B5%E3%82%A4%E3%82%BA%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="https://tma15.github.io/img/2020/pytorch-logo.png"/>
      </div>
    </a>
  
</article>

</div>
<br>




            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">タグ</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/nlp/">nlp</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/python/">python</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/pytorch/">pytorch</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/neural_network/">neural_network</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/machine_learning/">machine_learning</a>

  <a class="tag tag--primary tag--small" href="https://tma15.github.io/tags/google-colab/">google-colab</a>

                  </div>
                
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/09/13/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%AD%A6%E7%BF%92%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90%E4%BD%9C%E6%A5%AD%E3%82%92%E5%8A%B9%E7%8E%87%E5%8C%96%E3%81%99%E3%82%8B%E8%83%BD%E5%8B%95%E5%AD%A6%E7%BF%92oss%E3%81%BE%E3%81%A8%E3%82%81/" data-tooltip="【機械学習】学習データ作成作業を効率化する能動学習OSSまとめ">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">次</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/08/29/nvidia%E7%9B%B4%E4%BC%9D%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEpytorch%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%99%E3%82%8B%E3%81%8B%E3%82%82%E3%81%97%E3%82%8C%E3%81%AA%E3%81%84tips/" data-tooltip="【NVIDIA直伝】あなたのPyTorchプログラムを高速化するかもしれないTips">
              
                  <span class="hide-xs hide-sm text-small icon-mr">前</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#table-of-contents">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2020 Takuya Makino. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="1">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/09/13/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%AD%A6%E7%BF%92%E3%83%87%E3%83%BC%E3%82%BF%E4%BD%9C%E6%88%90%E4%BD%9C%E6%A5%AD%E3%82%92%E5%8A%B9%E7%8E%87%E5%8C%96%E3%81%99%E3%82%8B%E8%83%BD%E5%8B%95%E5%AD%A6%E7%BF%92oss%E3%81%BE%E3%81%A8%E3%82%81/" data-tooltip="【機械学習】学習データ作成作業を効率化する能動学習OSSまとめ">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">次</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://tma15.github.io/blog/2020/08/29/nvidia%E7%9B%B4%E4%BC%9D%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AEpytorch%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%99%E3%82%8B%E3%81%8B%E3%82%82%E3%81%97%E3%82%8C%E3%81%AA%E3%81%84tips/" data-tooltip="【NVIDIA直伝】あなたのPyTorchプログラムを高速化するかもしれないTips">
              
                  <span class="hide-xs hide-sm text-small icon-mr">前</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://tma15.github.io/blog/2020/09/06/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86lstm%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E-pytorch%E3%82%B3%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#table-of-contents">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="1">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Ftma15.github.io%2Fblog%2F2020%2F09%2F06%2F%25E8%2587%25AA%25E7%2584%25B6%25E8%25A8%2580%25E8%25AA%259E%25E5%2587%25A6%25E7%2590%2586lstm%25E3%2581%25AB%25E5%259F%25BA%25E3%2581%25A5%25E3%2581%258F%25E6%2596%2587%25E6%259B%25B8%25E5%2588%2586%25E9%25A1%259E-pytorch%25E3%2582%25B3%25E3%2583%25BC%25E3%2583%2589%25E4%25BB%2598%25E3%2581%258D%2F">
          <i class="fa fa-twitter"></i><span>Twitterで共有</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/dfef3d85434946d893b00f14fa3b80ed?s=110" alt="プロフィール画像" />
    
    <h4 id="about-card-name">Takuya Makino</h4>
    
      <div id="about-card-bio">自然言語処理の研究開発に従事しています。自然言語処理に関する研究から製品化に向けた開発に興味を持っています。本ブログでは自然言語処理、機械学習、Python、C++に関する記事が多めです。詳細は<a href="https://tma15.github.io/about/">プロフィール</a>を御覧ください。</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        自然言語処理の研究開発に従事
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Kanagawa, Japan
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://tma15.github.io/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://tma15.github.io/js/script-pcw6v3xilnxydl1vddzazdverrnn9ctynvnxgwho987mfyqkuylcb1nlt.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
  




    
  </body>
</html>

