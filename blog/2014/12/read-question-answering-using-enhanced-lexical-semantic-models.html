<!doctype html>
<html lang="ja">
    <head>
        <link href="http://fonts.googleapis.com/css?family=Anton" rel="stylesheet" type="text/css">
        <link href='http://fonts.googleapis.com/css?family=Inconsolata' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Bubblegum+Sans' rel='stylesheet' type='text/css'>
        <title>Question Answering Using Enhanced Lexical Semantic Models (ACL2013) を読んだ | Now is better than never.</title>
        <meta charset="utf-8" />
        <link href='http://fonts.googleapis.com/css?family=Permanent+Marker' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="/media/css/font-awesome.css">
        <link rel="stylesheet" href="/media/css/style.css">
        <link rel="stylesheet" href="/media/css/pygments.css">
        <link rel="shortcut icon" href="/media/img/background.jpg">
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }
            });
        </script>
        <script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
        <!--[if lt IE 9]>
        <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js">
        </script>
        <![endif]-->
    </head>
    <body >
        <header>
            <hgroup>
              <h1>Now is better than never.</h1>
              <h3>Although never is often better than right now.</h3>
            </hgroup>
        </header>
        <nav>
                                <ul>
<li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/blog">Blog</a></li><li><a href="/blog/archive.html">Archive</a></li></ul>
        </nav>
        <article id="content">
                    <h1>Question Answering Using Enhanced Lexical Semantic Models (ACL2013) を読んだ</h1>
              <div class="tags">
        Tags:
            <a class="small" href="/blog/tags/nlp.html">nlp</a>&nbsp;
            <a class="small" href="/blog/tags/paper.html">paper</a>&nbsp;
            <br>
  </div>
            <p>Question Answering Using Enhanced Lexical Semantic Models (<a href="http://www.aclweb.org/anthology/P13-1171">pdf</a>)</p>
<p>Wen-tau Yih, Ming-Wei Chang, Christopher Meek and Andrzej Pastusiak, Microsoft Research, ACL 2013</p>
<h2>導入</h2>
<ul>
<li>自然文の質問文を入力として受け付けて、解答として適切な文の選択(answer sentence selection)をして出力する<ul>
<li>単に名詞を解答として選択して出力するよりも、文脈が付いていたほうが根拠が分かるし、ユーザにとっては価値があるから</li>
</ul>
</li>
<li>answer sentence selectionは質問文と文書中の文とのマッチングの問題と考えられる<ul>
<li>単語の表層形のマッチングを単純な方法だと精度はそんなに上がらない</li>
<li>深い意味解析をしたり構文木の編集距離 (Tree Edit Distance)をしている研究もあるが、計算コストが高い</li>
<li>なのでこの研究では浅い意味解析を頑張ってanswer sentence selectionの性能を上げることに焦点を当てる<ul>
<li>浅い意味解析は上位下位語や同義語などを識別するlexical sematics</li>
</ul>
</li>
</ul>
</li>
<li>この論文ではlatent word-alignment structureとしてanswer sentence selectionを定式化する</li>
</ul>
<h2>この論文の貢献</h2>
<ul>
<li>色々なlexical semanticを組み合わせれば、学習アルゴリズムなどに関係なくanswer sentence selectionシステムの性能を上げられる</li>
<li>lexical word-alignment structureは、非構造なモデルよりも高い性能を出せるが、両方のモデルにlexical semanticsを入れた場合、性能の差は小さくなる</li>
<li>計算コストを下げたいなら、lexical semanticsを使ってシンプルなモデルを使うこともできる</li>
</ul>
<h2>問題設定</h2>
<p>教師あり学習でanswer sentence selectionに取り組む。学習時は質問文qと、それに関連するラベル付きの文(yi, si)のリストが与えられるので、それを学習データとしてパラメータを学習。yiは1であればsiは正解の文、0であれば不正解の文を表す。予測時は未知の文に対し、文が正解である確率を予測し、yiとする。</p>
<p>実際には文が正解であるかどうかではなく、文が質問文と意味的にマッチするかどうかを学習する。この論文では質問文と文の間には隠れ構造hが存在すると仮定する。隠れ構造hは質問文の単語と文の単語が対応するかどうかを表したバイナリのベクトル。</p>
<p>文を構文木で表現する先行研究もあるが、導入部分での理由から、この論文では浅い意味解析により文を表現する。</p>
<h2>lexical semantic models</h2>
<p>表層系のみのマッチングでは微妙なので言語資源を作成する。</p>
<h3>類義語と反義語</h3>
<p>Polarity-Inducing latent semantic analysis (PILSA) modelを使う。シソーラス(文書と単語のtfidf行列?)を入力として、SVDでd行n列の行列を構築する。dは類義語や反義語のクラスタの数を表す。nは語彙の数。二つの単語を表す列のコサインが正であれば、その単語は類義語、負であれば反義語とみなす。</p>
<h3>上位語下位語</h3>
<p>WordNetはカバレッジが低いので、<a href="http://research.microsoft.com/en-us/projects/probase/">Probase</a>を使う。ある単語が別の単語の下位語である確率を保持している。</p>
<h3>意味的な単語の類似度</h3>
<p>商用のサーチエンジンのクリックデータを使ってSiamese newural networkモデルを学習。入力はクエリとクリックしたページのタイトルの対の集合。ある文字列（クエリ）がどの文字列(クリックされたページのタイトル)と対応するかを表す行列を学習する。ページのタイトルを表す行ベクトルは密になるように圧縮されている。</p>
<h2>分類器の学習</h2>
<h3>Bag-of-Wordsモデル</h3>
<p>logistic regressionとboosted decision treeを用いる。</p>
<h3>隠れ構造モデル</h3>
<p>構造的なモデルではLatent-SVMの一種であるLCLRを用いる。目的関数 (単語間の意味的類似度) を最大化する隠れ構造hを選択して、損失項を最小化するように重みを更新するのを繰り返す。隠れ構造hがどの単語とどの単語の対応を見るかを制御している。隠れ構造は、「文のある単語は少なくとも質問文中の1つ以上の単語と対応していなければならない」、「質問文中の単語は文中のいずれかの単語と対応していなければならない」、というような制約を付与して整数計画法により選択する。</p>
<h3>素性</h3>
<p>すべての素性は単語のIDFで重み付け</p>
<ul>
<li>表層的な単語のマッチング</li>
<li>WordNet: 同じsynsetに属する、上位語下位語、反義語関係にある</li>
<li>lexical semantics: 上記実数値</li>
<li>NE: 単語が同じタイプの固有表現の一部である</li>
<li>answer type checking: 質問文がWHを接頭辞とする単語から始まる場合のルール。Whoで始まれば、PersonなNEと対応するみたいなもの。</li>
</ul>
<h2>結果</h2>
<p>リッチな言語資源を使うほど、どの分類器でもMRR、MAPが向上。</p>
<h2>所感</h2>
<p>複雑なアルゴリズムでやるよりも言語資源をリッチにして計算コストを減らすのは良さそうと思ったので、LCLRとlogistic regressionでどれくらい差が出るのか気になった。文間の単語の対応くらいだと問題はそれほど大きくないかもしれないけど、整数計画法のソルバーは早いものが有償だったりするので、そういったことを考えると分類器で複雑なことをするよりも言語資源を前処理でガッと作っておくほうが現実的な気がした。</p>
        <br>
        <time datetime="2014-12-03">
    Wed, 03 Dec 2014
</time>
        <div class="bottom_article_nav">

                  <div class="next"><a href="/blog/2014/11/use-es-py.html">PythonでElasticsearchを使うときのメモ</a>
    &gt;</div>
        <div class="prev">&lt; <a href="/blog/2015/01/cykmemo.html">CYKアルゴリズム</a>
  </div>

</div>

<div class="center"><a href="/blog/archive.html">archive</a></div>
        </article>

                <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-20414370-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>    </body>
</html>