<!doctype html>
<html lang="ja">
    <head>
        <link href="http://fonts.googleapis.com/css?family=Anton" rel="stylesheet" type="text/css">
        <link href='http://fonts.googleapis.com/css?family=Inconsolata' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Bubblegum+Sans' rel='stylesheet' type='text/css'>
        <title>AdaGrad+RDAをGoで書いた | Now is better than never.</title>
        <meta charset="utf-8" />
        <link href='http://fonts.googleapis.com/css?family=Permanent+Marker' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="/media/css/font-awesome.css">
        <link rel="stylesheet" href="/media/css/style.css">
        <link rel="stylesheet" href="/media/css/pygments.css">
        <link rel="shortcut icon" href="/media/img/background.jpg">
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }
            });
        </script>
        <script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
        <!--[if lt IE 9]>
        <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js">
        </script>
        <![endif]-->
    </head>
    <body >
        <header>
            <hgroup>
              <h1>Now is better than never.</h1>
              <h3>Although never is often better than right now.</h3>
            </hgroup>
        </header>
        <nav>
                                <ul>
<li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/blog">Blog</a></li><li><a href="/blog/archive.html">Archive</a></li></ul>
        </nav>
        <article id="content">
                    <h1>AdaGrad+RDAをGoで書いた</h1>
              <div class="tags">
        Tags:
            <a class="small" href="/blog/tags/golang.html">golang</a>&nbsp;
            <br>
  </div>
            <p>論文はこちら。</p>
<p><a href="http://www.magicbroom.info/Papers/DuchiHaSi10.pdf">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p>ソースコードは<a href="https://github.com/tma15/goAdaGrad">こちら</a>。
多値分類問題にも対応できるようにした。二値分類問題と比べて<a href="http://en.wikipedia.org/wiki/Hinge_loss">ヒンジ損失</a>が少し変わる(ので重みの更新も二値分類の場合とと少し違う)。</p>
<p>データを次のように作成。</p>
<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="nv">$perl</span> -MList::Util<span class="o">=</span>shuffle -e <span class="s1">&#39;print shuffle(&lt;&gt;)&#39;</span> &lt; ../data/news20.binary &gt; news<br /><span class="nv">$head</span> -15000 news &gt; news.train<br /><span class="nv">$tail</span> -4996  news &gt; news.test<br /></pre></div><br /><figcaption>Bash</figcaption></figure></div>

<p>例えば<a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#news20.binary">このデータ</a>は素性の値が0.04くらいなので、その平均を取ると0.01よりも小さくなるため、式(24)中の右辺の第三項が0になり、ほとんどすべての重みが0になってしまう。
正則化項の重み(c)をもう少し小さくしてやると、次の結果になった(本当は論文のように交差検定をして決めてやったほうが良いけど、人手でチューニング)。</p>
<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="nv">$.</span>/adagrad -f news.train -m learn -w model -l 1 -c 0.01<br /><span class="nv">$.</span>/adagrad -f news.test -m <span class="nb">test</span> -w model -l 1 -c 0.01<br />Recall<span class="o">[</span>-1<span class="o">]</span>: 0.011142 <span class="o">(</span>28/2513<span class="o">)</span><br />Prec<span class="o">[</span>-1<span class="o">]</span>: 0.848485 <span class="o">(</span>28/33<span class="o">)</span><br />--<br />Recall<span class="o">[</span>+1<span class="o">]</span>: 0.997986 <span class="o">(</span>2478/2483<span class="o">)</span><br />Prec<span class="o">[</span>+1<span class="o">]</span>: 0.499295 <span class="o">(</span>2478/4963<span class="o">)</span><br />--<br />Acc: 0.5016012810248198<br /></pre></div><br /><figcaption>Bash</figcaption></figure></div>

<div class="codebox"><figure class="code"><div class="highlight"><pre><span class="nv">$.</span>/adagrad -f news.train -m learn -w model -l 1 -c 0.0001<br /><span class="nv">$.</span>/adagrad -f news.test -m <span class="nb">test</span> -w model<br />Recall<span class="o">[</span>+1<span class="o">]</span>: 0.836891 <span class="o">(</span>2078/2483<span class="o">)</span><br />Prec<span class="o">[</span>+1<span class="o">]</span>: 0.833200 <span class="o">(</span>2078/2494<span class="o">)</span><br />--<br />Recall<span class="o">[</span>-1<span class="o">]</span>: 0.834461 <span class="o">(</span>2097/2513<span class="o">)</span><br />Prec<span class="o">[</span>-1<span class="o">]</span>: 0.838129 <span class="o">(</span>2097/2502<span class="o">)</span><br />--<br />Acc: 0.8356685348278623<br /><span class="nv">$.</span>/adagrad -f news.train -m learn -w model -l 1 -c 0.00001<br /><span class="nv">$.</span>/adagrad -f news.test -m <span class="nb">test</span> -w model<br />Recall<span class="o">[</span>+1<span class="o">]</span>: 0.950463 <span class="o">(</span>2360/2483<span class="o">)</span><br />Prec<span class="o">[</span>+1<span class="o">]</span>: 0.946651 <span class="o">(</span>2360/2493<span class="o">)</span><br />--<br />Recall<span class="o">[</span>-1<span class="o">]</span>: 0.947075 <span class="o">(</span>2380/2513<span class="o">)</span><br />Prec<span class="o">[</span>-1<span class="o">]</span>: 0.950859 <span class="o">(</span>2380/2503<span class="o">)</span><br />--<br />Acc: 0.9487590072057646<br /></pre></div><br /><figcaption>Bash</figcaption></figure></div>

<h2>参考</h2>
<ul>
<li><a href="http://d.hatena.ne.jp/echizen_tm/20140914/1410697535">実装が簡単で高性能な線形識別器、AdaGrad+RDAの解説</a></li>
<li><a href="http://d.hatena.ne.jp/Christopher-727/20140830">AdaGrad + RDAを実装してみた</a></li>
<li><a href="https://code.google.com/p/oll/wiki/OllMainJa">OllMainJa - oll - oll: Online-Learning Library - Google Project Hosting</a></li>
<li><a href="http://d.hatena.ne.jp/sleepy_yoshi/20110916/p1">行をランダムシャッフルするワンライナー</a></li>
<li><a href="http://en.wikipedia.org/wiki/Perceptron#Multiclass_perceptron">Multiclass perceptron</a></li>
</ul>
        <br>
        <time datetime="2014-10-18">
    Sat, 18 Oct 2014
</time>
        <div class="bottom_article_nav">

                  <div class="next"><a href="/blog/2014/10/go-pa2.html">PA-IIをGoで書いた</a>
    &gt;</div>
        <div class="prev">&lt; <a href="/blog/2014/10/document-classification.html">Goで日本語の文書を前処理して分類器を学習するところまでやっ...</a>
  </div>

</div>

<div class="center"><a href="/blog/archive.html">archive</a></div>
        </article>

                <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-20414370-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>    </body>
</html>