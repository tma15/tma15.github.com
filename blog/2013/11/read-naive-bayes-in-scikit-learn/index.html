<!DOCTYPE html>
<html class="no-js" lang="en-US" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>scikit-learnのソースコードリーディング（ナイーブベイズ分類）</title>

 	
	<link href="/css/journal.css" rel="stylesheet">

 	
 	<link href="/css/style.css" rel="stylesheet">

    <link rel="alternate" type="application/atom+xml"  href="http://tma15.github.io/blog/index.xml" >
</head>
<body lang="en">
	<div class="container">
		<div class="row">
			<div class="navbar navbar-default navbar-inverse" role="navigation">
				<div class="navbar-header">
					<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
					<a class="navbar-brand" href="http://localhost:1313/">Now is better than never.</a> 
				</div>
				<div class="navbar-collapse collapse navbar-responsive-collapse">
					<ul class="nav navbar-nav navbar-right">
						<li><a href="http://localhost:1313/">Home</a></li>
						<li><a href="http://localhost:1313//about/">About</a></li>
						<li><a href="http://localhost:1313//blog/">Blog</a></li>
					</ul>
				</div>
			</div>
		</div>
	</div>


<div class="container">	
	<div class="row">
		<div class="col-md-offset-1 col-md-10">
			<h3>scikit-learnのソースコードリーディング（ナイーブベイズ分類）</h3>
				<span class="label label-primary">Sun Nov 10, 2013</span> in 
				 using tags 			 
				
					
					<a href="/tags/python">python</a>
				
					 , 
					<a href="/tags/machine_learning">machine_learning</a>
				
			</small>
		</div>
	</div>
	<div class="row">
		<div class="col-md-offset-1 col-md-10">
			<br>
			

<p>個人的にはプログラミングの勉強は写経が一番頭に入る気がする、ということで読んでいた。</p>

<h2 id="気になったところ:354c44db974ee48c03ece6648b7b14ff">気になったところ</h2>

<p>データに正規分布を仮定したときのナイーブベイズ分類器について。
平均を\(\mu\)、分散を\(\sigma^2\)としたときの正規分布は</p>

<p>\[
p(x;\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}
\]</p>

<p>これのlogをとると、
\[
\begin{split}
\log p(x;\mu, \sigma^2) &amp;= \log \{\frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}\}\\
&amp;= -\frac{1}{2}\log (2\pi \sigma^2) - \frac{(x-\mu)^2}{2\sigma^2}
\end{split}
\]</p>

<p>ナイーブベイズ分類器の対数尤度関数は、データがK次元ベクトルで表現されていて、それがN個あるとすると、</p>

<p>\[
\begin{split}
\log L(X, Y; \mu, \sigma) &amp;= \log(\prod<em>{n=1}^N p(\mathbf{x}_n, y_n))\\
&amp; = \log(\prod</em>{n=1}^N p(y<em>n)p(\mathbf{x}_n|y_n))\\
&amp; = \sum</em>{n=1}^N \log p(y<em>n) + \sum</em>{n=1}^N \log p(\mathbf{x}_n|y<em>n)\\
&amp; = \sum</em>{n=1}^N \log p(y<em>n) + \sum</em>{n=1}^N \sum<em>{k=1}^K\log p(x</em>{nk}|y<em>n)\\
&amp; = \sum</em>{n=1}^N \log p(y<em>n) + \sum</em>{n=1}^N \sum<em>{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma</em>{y<em>nk}^2) - \frac{(x</em>{nk}-\mu<em>{y_nk})^2}{2\sigma</em>{y_nk}^2}\}
\end{split}
\]</p>

<p>サンプル\(\mathbf{x}\)に対して出力される予測ラベル\(\hat{y}\)は</p>

<p>\[
\begin{split}
\hat{y} &amp;= \mathop{\arg\,\max}\limits<em>y \log p(\mathbf{x}, y)\\
&amp;= \mathop{\arg\,\max}\limits_y \log p(y)p(\mathbf{x}|y)\\
&amp; = \mathop{\arg\,\max}\limits_y \{\log p(y) + \sum</em>{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma<em>{yk}^2) - \frac{(x_k-\mu</em>{yk})^2}{2\sigma_{yk}^2}\}\}
\end{split}
\]</p>

<p>対数尤度関数をnumpyに落とすと</p>

<p><div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span style="color: #D04020">&quot;&quot;&quot;</span>
<span style="color: #D04020">sigma.shape = (n_classes, n_features)</span>
<span style="color: #D04020">mu.shape = (n_classes, n_features)</span>
<span style="color: #D04020">&quot;&quot;&quot;</span>

joint_log_likelihood <span style="color: #303030">=</span> []
<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #000000; font-weight: bold">in</span> <span style="color: #007020">range</span>(np<span style="color: #303030">.</span>size(classes)):
    <span style="color: #808080"># 事前分布の対数</span>
    log_prior <span style="color: #303030">=</span> np<span style="color: #303030">.</span>log(class_piror[i])
    <span style="color: #808080"># log p(x|y)の対数の初項</span>
    log_gauss1 <span style="color: #303030">=</span> <span style="color: #303030">-</span><span style="color: #6000E0; font-weight: bold">0.5</span> <span style="color: #303030">*</span> np<span style="color: #303030">.</span>sum(np<span style="color: #303030">.</span>log(<span style="color: #0000D0; font-weight: bold">2</span> <span style="color: #303030">*</span> np<span style="color: #303030">.</span>pi <span style="color: #303030">*</span> sigma[i, :]))
    <span style="color: #808080"># log p(x|y)の対数の第二項</span>
    log_gauss2 <span style="color: #303030">=</span> <span style="color: #303030">-</span><span style="color: #6000E0; font-weight: bold">0.5</span> <span style="color: #303030">*</span> np<span style="color: #303030">.</span>sum((X <span style="color: #303030">-</span> mu[i, :]) <span style="color: #303030">**</span> <span style="color: #0000D0; font-weight: bold">2</span> <span style="color: #303030">/</span> sigma[i, :])
    <span style="color: #808080"># クラスiの尤度のlogを取った値</span>
    joint_log_likelihood<span style="color: #303030">.</span>append(log_prior <span style="color: #303030">+</span> log_gauss1 <span style="color: #303030">+</span> log_gauss2)
</pre></div>

<br>
となる。と思っていた。ところがscikit-learnのGaussianNBの該当箇所を見て見ると、</p>

<p><div class="highlight" style="background: #ffffff"><pre style="line-height: 125%">    <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0060B0; font-weight: bold">_joint_log_likelihood</span>(<span style="color: #007020">self</span>, X):
        X <span style="color: #303030">=</span> array2d(X)
        joint_log_likelihood <span style="color: #303030">=</span> []
        <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #000000; font-weight: bold">in</span> <span style="color: #007020">range</span>(np<span style="color: #303030">.</span>size(<span style="color: #007020">self</span><span style="color: #303030">.</span>classes_)):
            jointi <span style="color: #303030">=</span> np<span style="color: #303030">.</span>log(<span style="color: #007020">self</span><span style="color: #303030">.</span>class_prior_[i])
            n_ij <span style="color: #303030">=</span> <span style="color: #303030">-</span> <span style="color: #6000E0; font-weight: bold">0.5</span> <span style="color: #303030">*</span> np<span style="color: #303030">.</span>sum(np<span style="color: #303030">.</span>log(np<span style="color: #303030">.</span>pi <span style="color: #303030">*</span> <span style="color: #007020">self</span><span style="color: #303030">.</span>sigma_[i, :])) <span style="color: #808080"># np.piの前に2がない</span>
            n_ij <span style="color: #303030">-=</span> <span style="color: #6000E0; font-weight: bold">0.5</span> <span style="color: #303030">*</span> np<span style="color: #303030">.</span>sum(((X <span style="color: #303030">-</span> <span style="color: #007020">self</span><span style="color: #303030">.</span>theta_[i, :]) <span style="color: #303030">**</span> <span style="color: #0000D0; font-weight: bold">2</span>) <span style="color: #303030">/</span>
                                 (<span style="color: #007020">self</span><span style="color: #303030">.</span>sigma_[i, :]), <span style="color: #0000D0; font-weight: bold">1</span>)
            joint_log_likelihood<span style="color: #303030">.</span>append(jointi <span style="color: #303030">+</span> n_ij)
</pre></div>
</p>

<p><br></p>

<p>数式の展開が間違えているのだろうか&hellip;。それとも2は必要ないのだろうか&hellip;。</p>

<h2 id="参考:354c44db974ee48c03ece6648b7b14ff">参考</h2>

<ul>
<li><a href="http://r9y9.github.io/blog/2013/07/28/naive-bayes-formulation/">Naive Bayesの復習（導出編）</a></li>
<li><a href="http://cs.nyu.edu/~dsontag/courses/ml12/slides/lecture17.pdf">Naïve Bayes Lecture17</a></li>
</ul>

		</div>
	</div>
	<div class="row">
		<div class="col-md-12">
			<hr>
		</div>
	</div>	
        <div id="disqus_thread"></div>
<script type="text/javascript">
     
    var disqus_shortname = 'nowisbetterthannever'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


</div>

  <div class="container">
    <div class="row col-md-12">
          <footer>
            <div>
                <p>
                    &copy; 2014  ~ Powered By <a href="http://hugo.spf13.com">Hugo</a>
                </p>
            </div>
            </footer>
        </div>
    </div>

    
    
    <script src="/js/jquery-min-2.1.1.js"></script>
    <script src="/js/bootstrap.min-3.1.1.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }
        });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-20414370-4']);
      _gaq.push(['_trackPageview']);
      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    </body>
</html>

