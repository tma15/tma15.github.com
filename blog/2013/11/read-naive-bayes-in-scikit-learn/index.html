<!DOCTYPE html>
<html class="no-js" lang="en-US" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>scikit-learnのソースコードリーディング（ナイーブベイズ分類）</title>

 	
    <link href="/css/journal.css" rel="stylesheet">

 	
    <link href="/css/style.css" rel="stylesheet">

    <link rel="alternate" type="application/atom+xml"  href="/blog/index.xml" >
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
          (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-5663917297524414",
                  enable_page_level_ads: true
                });
    </script>
</head>
<body lang="en">
	<div class="container">
		<div class="row">
			<div class="navbar navbar-default navbar-inverse" role="navigation">
				<div class="navbar-header">
					<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
					<a class="navbar-brand" href="">Now is better than never.</a> 
				</div>
				<div class="navbar-collapse collapse navbar-responsive-collapse">
					<ul class="nav navbar-nav navbar-right">
						<li><a href="">Home</a></li>
						<li><a href="/about/">About</a></li>
						<li><a href="/blog/">Blog</a></li>
					</ul>
				</div>
			</div>
		</div>
	</div>


<div class="container">	
	<div class="row">
		<div class="col-md-offset-1 col-md-10">
			<h3>scikit-learnのソースコードリーディング（ナイーブベイズ分類）</h3>
				<span class="label label-primary">Sun Nov 10, 2013</span> in 
				 using tags 			 
				
					
					<a href="/tags/python">python</a>
				
					 , 
					<a href="/tags/machine_learning">machine_learning</a>
				
			</small>
		</div>
	</div>
	<div class="row">
		<div class="col-md-offset-1 col-md-10">
			<br>
			

<p>個人的にはプログラミングの勉強は写経が一番頭に入る気がする、ということで読んでいた。</p>

<h2 id="気になったところ">気になったところ</h2>

<p>データに正規分布を仮定したときのナイーブベイズ分類器について。
平均を\(\mu\)、分散を\(\sigma^2\)としたときの正規分布は</p>

<p>\[
p(x;\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}
\]</p>

<p>これのlogをとると、
\[
\begin{split}
\log p(x;\mu, \sigma^2) &amp;= \log \{\frac{1}{\sqrt{2\pi \sigma^2}} \{\exp{-\frac{(x-\mu)^2}{2\sigma^2}}\}\}\<br />
&amp;= -\frac{1}{2}\log (2\pi \sigma^2) - \frac{(x-\mu)^2}{2\sigma^2}
\end{split}
\]</p>

<p>ナイーブベイズ分類器の対数尤度関数は、データがK次元ベクトルで表現されていて、それがN個あるとすると、</p>

<p>\[
\begin{split}
\log L(X, Y; \mu, \sigma) &amp;= \log(\prod_{n=1}^N p(\mathbf{x}_n, y<em>n))\<br />
&amp; = \log(\prod</em>{n=1}^N p(y_n)p(\mathbf{x}_n|y<em>n))\<br />
&amp; = \sum</em>{n=1}^N \log p(y<em>n) + \sum</em>{n=1}^N \log p(\mathbf{x}_n|y<em>n)\<br />
&amp; = \sum</em>{n=1}^N \log p(y<em>n) + \sum</em>{n=1}^N \sum<em>{k=1}^K\log p(x</em>{nk}|y<em>n)\<br />
&amp; = \sum</em>{n=1}^N \log p(y<em>n) + \sum</em>{n=1}^N \sum<em>{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma</em>{y<em>nk}^2) - \frac{(x</em>{nk}-\mu_{y<em>nk})^2}{2\sigma</em>{y_nk}^2}\}
\end{split}
\]</p>

<p>サンプル\(\mathbf{x}\)に対して出力される予測ラベル\(\hat{y}\)は</p>

<p>\[
\begin{split}
\hat{y} &amp;= \mathop{\arg\,\max}\limits_y \log p(\mathbf{x}, y)\<br />
&amp;= \mathop{\arg\,\max}\limits_y \log p(y)p(\mathbf{x}|y)\<br />
&amp; = \mathop{\arg\,\max}\limits<em>y \{\log p(y) + \sum</em>{k=1}^K \{-\frac{1}{2}\log (2\pi \sigma_{yk}^2) - \frac{(x<em>k-\mu</em>{yk})^2}{2\sigma_{yk}^2}\}\}
\end{split}
\]</p>

<p>対数尤度関数をnumpyに落とすと</p>

<p><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="background-color:#fff0f0">&#34;&#34;&#34;
</span><span style="background-color:#fff0f0">sigma.shape = (n_classes, n_features)
</span><span style="background-color:#fff0f0">mu.shape = (n_classes, n_features)
</span><span style="background-color:#fff0f0">&#34;&#34;&#34;</span>

joint_log_likelihood <span style="color:#333">=</span> []
<span style="color:#080;font-weight:bold">for</span> i <span style="color:#000;font-weight:bold">in</span> <span style="color:#007020">range</span>(np<span style="color:#333">.</span>size(classes)):
    <span style="color:#888"># 事前分布の対数</span>
    log_prior <span style="color:#333">=</span> np<span style="color:#333">.</span>log(class_piror[i])
    <span style="color:#888"># log p(x|y)の対数の初項</span>
    log_gauss1 <span style="color:#333">=</span> <span style="color:#333">-</span><span style="color:#60e;font-weight:bold">0.5</span> <span style="color:#333">*</span> np<span style="color:#333">.</span>sum(np<span style="color:#333">.</span>log(<span style="color:#00d;font-weight:bold">2</span> <span style="color:#333">*</span> np<span style="color:#333">.</span>pi <span style="color:#333">*</span> sigma[i, :]))
    <span style="color:#888"># log p(x|y)の対数の第二項</span>
    log_gauss2 <span style="color:#333">=</span> <span style="color:#333">-</span><span style="color:#60e;font-weight:bold">0.5</span> <span style="color:#333">*</span> np<span style="color:#333">.</span>sum((X <span style="color:#333">-</span> mu[i, :]) <span style="color:#333">**</span> <span style="color:#00d;font-weight:bold">2</span> <span style="color:#333">/</span> sigma[i, :])
    <span style="color:#888"># クラスiの尤度のlogを取った値</span>
    joint_log_likelihood<span style="color:#333">.</span>append(log_prior <span style="color:#333">+</span> log_gauss1 <span style="color:#333">+</span> log_gauss2)</code></pre></div>
<br>
となる。と思っていた。ところがscikit-learnのGaussianNBの該当箇所を見て見ると、</p>

<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06b;font-weight:bold">_joint_log_likelihood</span>(self, X):
        X <span style="color:#333">=</span> array2d(X)
        joint_log_likelihood <span style="color:#333">=</span> []
        <span style="color:#080;font-weight:bold">for</span> i <span style="color:#000;font-weight:bold">in</span> <span style="color:#007020">range</span>(np<span style="color:#333">.</span>size(self<span style="color:#333">.</span>classes_)):
            jointi <span style="color:#333">=</span> np<span style="color:#333">.</span>log(self<span style="color:#333">.</span>class_prior_[i])
            n_ij <span style="color:#333">=</span> <span style="color:#333">-</span> <span style="color:#60e;font-weight:bold">0.5</span> <span style="color:#333">*</span> np<span style="color:#333">.</span>sum(np<span style="color:#333">.</span>log(np<span style="color:#333">.</span>pi <span style="color:#333">*</span> self<span style="color:#333">.</span>sigma_[i, :])) <span style="color:#888"># np.piの前に2がない</span>
            n_ij <span style="color:#333">-=</span> <span style="color:#60e;font-weight:bold">0.5</span> <span style="color:#333">*</span> np<span style="color:#333">.</span>sum(((X <span style="color:#333">-</span> self<span style="color:#333">.</span>theta_[i, :]) <span style="color:#333">**</span> <span style="color:#00d;font-weight:bold">2</span>) <span style="color:#333">/</span>
                                 (self<span style="color:#333">.</span>sigma_[i, :]), <span style="color:#00d;font-weight:bold">1</span>)
            joint_log_likelihood<span style="color:#333">.</span>append(jointi <span style="color:#333">+</span> n_ij)</code></pre></div>

<p><br></p>

<p>数式の展開が間違えているのだろうか&hellip;。それとも2は必要ないのだろうか&hellip;。</p>

<h2 id="参考">参考</h2>

<ul>
<li><a href="http://r9y9.github.io/blog/2013/07/28/naive-bayes-formulation/">Naive Bayesの復習（導出編）</a></li>
<li><a href="http://cs.nyu.edu/~dsontag/courses/ml12/slides/lecture17.pdf">Naïve Bayes Lecture17</a></li>
</ul>

		</div>
	</div>
	<div class="row">
		<div class="col-md-12">
			<hr>
		</div>
	</div>	
        <div id="disqus_thread"></div>
<script type="text/javascript">
     
    var disqus_shortname = 'nowisbetterthannever'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


</div>

  <div class="container">
    <div class="row col-md-12">
          <footer>
            <div>
                <p>
                    &copy; 2014  ~ Powered By <a href="http://hugo.spf13.com">Hugo</a>
                </p>
            </div>
            </footer>
        </div>
    </div>

    
    
    <script src="/js/jquery-min-2.1.1.js"></script>
    <script src="/js/bootstrap.min-3.1.1.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }
        });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-20414370-4']);
      _gaq.push(['_trackPageview']);
      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    </body>
</html>

